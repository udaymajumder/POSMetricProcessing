2020-09-03 13:24:36.600 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:24:36.600 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:24:36.600 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:24:36.600 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:24:36.600 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: 61790d7f-0045-4018-bd51-2aeb544a4bd6
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 22901 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 41699
Successfully started service 'sparkDriver' on port 41699.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-5c98938c-a3be-4be0-b6ae-ad0ca75a15db
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @11566ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2875b016
o.s.j.s.ServletContextHandler@23940f86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@66153688,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@87b5b49
o.s.j.s.ServletContextHandler@4a7a965d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@507b79f7,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@226eba67
o.s.j.s.ServletContextHandler@1cb7936c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@35342d2f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-128c502c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@45667d98
o.s.j.s.ServletContextHandler@65eabaab{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7123be6c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1de9d54,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@70331432
o.s.j.s.ServletContextHandler@3bbf9027{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c2064a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-70e13fa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6ff415ad
o.s.j.s.ServletContextHandler@280d9edc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@28fd3dc1,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5432c277
o.s.j.s.ServletContextHandler@15e0fe05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1128620c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6bf13698,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@299270eb
o.s.j.s.ServletContextHandler@3b90a30a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@69fa8e76,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-bdd2027,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@f446158
o.s.j.s.ServletContextHandler@32f0c7f8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@504e1599,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5d1b9c3d
o.s.j.s.ServletContextHandler@69e05f61{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@49a26d19,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-730e5763,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2babf189
o.s.j.s.ServletContextHandler@479f2dc2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@dab48d3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7159a5cd
o.s.j.s.ServletContextHandler@4f966719{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@18ac53e8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c3177d5
o.s.j.s.ServletContextHandler@76f856a8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7c853486,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-174e1b69,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1046498a
o.s.j.s.ServletContextHandler@243f003c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@71cb3139,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1639f93a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@19b047fe
o.s.j.s.ServletContextHandler@22590e3e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53dad875,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f780a86,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446c3920
o.s.j.s.ServletContextHandler@2eaef76d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2b329bbd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34819867,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@72d0f2b4
o.s.j.s.ServletContextHandler@6d2dc9d2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1da4b6b3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e1f584d
o.s.j.s.ServletContextHandler@7dff6d05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45d64d27,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34fe326d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36361ddb
o.s.j.s.ServletContextHandler@41fed14f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d6ee47,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c6da8bb
o.s.j.s.ServletContextHandler@3bae64d0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@8b91134,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1fba386c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36b310aa
o.s.j.s.ServletContextHandler@76c387f9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3874b815,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-1a891add,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@d74bac4
o.s.j.s.ServletContextHandler@5ff90645{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@387bf2d9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c768ada
o.s.j.s.ServletContextHandler@c1fca2a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5533dc72,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-27ace0b1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@58ec7116
o.s.j.s.ServletContextHandler@63bde6c2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ea04618,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-6dd82486,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36fcf6c0
o.s.j.s.ServletContextHandler@1aac188d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7026b7ee,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-2d23faef,POJO}
org.spark_project.jetty.server.Server@3effd4f3 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ErrorHandler@514cd540,AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[],MANAGED}
starting org.spark_project.jetty.server.Server@3effd4f3
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@3effd4f3
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @11774ms SparkUI{STARTED,8<=8<=200,i=6,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STARTED @11774ms org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
STARTED @11774ms org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
Started @11774ms
STARTED @11775ms org.spark_project.jetty.server.Server@3effd4f3
HttpConnectionFactory@5a8cbffe[HTTP/1.1] added {HttpConfiguration@96a75da{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@3effd4f3,UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85,AUTO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@1f44ddab,POJO}
ServerConnector@3d7b1f1c{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@5a8cbffe[HTTP/1.1],AUTO}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@5a8cbffe[HTTP/1.1]
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151,MANAGED}
starting ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STARTED @11809ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
starting HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STARTED @11809ms HttpConnectionFactory@5a8cbffe[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151 added {org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @11815ms org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @11815ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
run org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@103c7fbe execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@103c7fbe produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@103c7fbe producing
Selector loop waiting on select
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@6aba5d30,POJO}
queue acceptor-0@6aba5d30
Started ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
run acceptor-0@6aba5d30
STARTED @11818ms ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@3effd4f3 added {Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 mime types IncludeExclude@2eb917d0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c6b2dd9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@73437222}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 added {o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
STARTED @11876ms org.spark_project.jetty.servlet.ServletHandler@66153688
starting org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11878ms org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7c2b58c0 for org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e
Started o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @11882ms o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @11882ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 mime types IncludeExclude@7bca6fac{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c60b0a0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a2b1eb4}
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 added {o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
STARTED @11886ms org.spark_project.jetty.servlet.ServletHandler@507b79f7
starting org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11887ms org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5833f5cd for org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c
Started o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @11887ms o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @11887ms org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb mime types IncludeExclude@23f3dbf0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31d6f3fe,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@760cf594}
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb added {o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-128c502c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-128c502c=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
STARTED @11890ms org.spark_project.jetty.servlet.ServletHandler@35342d2f
starting org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11890ms org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@aa149ed for org.apache.spark.ui.JettyUtils$$anon$3-128c502c
Started o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @11890ms o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @11891ms org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 mime types IncludeExclude@204e90f7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@20a05b32,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@165e389b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 added {o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1de9d54=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
STARTED @11895ms org.spark_project.jetty.servlet.ServletHandler@7123be6c
starting org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11895ms org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5c73f672 for org.apache.spark.ui.JettyUtils$$anon$3-1de9d54
Started o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @11895ms o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @11895ms org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 mime types IncludeExclude@2ab5afc7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4dc8c0ea,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@e4b6f47}
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 added {o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-70e13fa=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
STARTED @11898ms org.spark_project.jetty.servlet.ServletHandler@10c2064a
starting org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11898ms org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@763cf5b9 for org.apache.spark.ui.JettyUtils$$anon$3-70e13fa
Started o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @11898ms o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @11898ms org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e mime types IncludeExclude@7a34f66a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2f508f3c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3ed03652}
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e added {o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
STARTED @11901ms org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
starting org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11901ms org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4aedaf61 for org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7
Started o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @11902ms o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @11902ms org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 mime types IncludeExclude@3c35c345{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3681037,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2459319c}
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 added {o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6bf13698=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
STARTED @11905ms org.spark_project.jetty.servlet.ServletHandler@1128620c
starting org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11905ms org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ffaaaf0 for org.apache.spark.ui.JettyUtils$$anon$3-6bf13698
Started o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @11906ms o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @11906ms org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 mime types IncludeExclude@69a2b3b6{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4f3e7344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7808f638}
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 added {o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-bdd2027=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
STARTED @11912ms org.spark_project.jetty.servlet.ServletHandler@69fa8e76
starting org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11912ms org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@62d73ead for org.apache.spark.ui.JettyUtils$$anon$3-bdd2027
Started o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @11912ms o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @11912ms org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 mime types IncludeExclude@228cea97{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d0a61c8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@46731692}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 added {o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
STARTED @11917ms org.spark_project.jetty.servlet.ServletHandler@504e1599
starting org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11917ms org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@782bf610 for org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb
Started o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @11918ms o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @11918ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 mime types IncludeExclude@73fc518f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2de50ee4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@ad9e63e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 added {o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-730e5763 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-730e5763=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
STARTED @11922ms org.spark_project.jetty.servlet.ServletHandler@49a26d19
starting org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11922ms org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@47fbc56 for org.apache.spark.ui.JettyUtils$$anon$3-730e5763
Started o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @11922ms o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @11922ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f mime types IncludeExclude@10895b16{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5524b72f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2cc03cd1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f added {o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
STARTED @11926ms org.spark_project.jetty.servlet.ServletHandler@dab48d3
starting org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11926ms org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e17913b for org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c
Started o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @11926ms o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @11926ms org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 mime types IncludeExclude@64f16277{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@497aec8c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3b9632d1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 added {o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
STARTED @11930ms org.spark_project.jetty.servlet.ServletHandler@18ac53e8
starting org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11930ms org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e6f2bb5 for org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa
Started o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @11931ms o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @11931ms org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 mime types IncludeExclude@3f628ce9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@35e8316e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@26d96e5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 added {o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-174e1b69=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
STARTED @11935ms org.spark_project.jetty.servlet.ServletHandler@7c853486
starting org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11935ms org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@336880df for org.apache.spark.ui.JettyUtils$$anon$3-174e1b69
Started o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @11936ms o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @11936ms org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f mime types IncludeExclude@6cd166b8{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2650f79,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75fc1992}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f added {o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1639f93a=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
STARTED @11939ms org.spark_project.jetty.servlet.ServletHandler@71cb3139
starting org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11940ms org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5fac521d for org.apache.spark.ui.JettyUtils$$anon$3-1639f93a
Started o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @11940ms o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @11940ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 mime types IncludeExclude@129bd55d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7be7e15,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3abfe845}
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 added {o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f780a86=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
STARTED @11943ms org.spark_project.jetty.servlet.ServletHandler@53dad875
starting org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11950ms org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a0f244f for org.apache.spark.ui.JettyUtils$$anon$3-5f780a86
Started o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @11950ms o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @11950ms org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e mime types IncludeExclude@4248b963{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7f08caf,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4defd42}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e added {o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34819867 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34819867=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
STARTED @11959ms org.spark_project.jetty.servlet.ServletHandler@2b329bbd
starting org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11959ms org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2330e3e0 for org.apache.spark.ui.JettyUtils$$anon$3-34819867
Started o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @11960ms o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @11960ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 mime types IncludeExclude@27a2a089{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@54657dd2,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@706eab5d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 added {o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
STARTED @11973ms org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
starting org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11973ms org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@72725ee1 for org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece
Started o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @11973ms o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @11973ms org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece mime types IncludeExclude@3f9270ed{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3a230001,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ac6c4f2}
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece added {o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34fe326d=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
STARTED @11984ms org.spark_project.jetty.servlet.ServletHandler@45d64d27
starting org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11984ms org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2aa6311a for org.apache.spark.ui.JettyUtils$$anon$3-34fe326d
Started o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @11984ms o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @11984ms org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb mime types IncludeExclude@249e0271{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4893b344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@53a665ad}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb added {o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
STARTED @11988ms org.spark_project.jetty.servlet.ServletHandler@4d6ee47
starting org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11988ms org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2c0b4c83 for org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3
Started o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @11988ms o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @11988ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 mime types IncludeExclude@2d0ecb24{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4d654825,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3bfc6a5e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 added {o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1fba386c=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
STARTED @11991ms org.spark_project.jetty.servlet.ServletHandler@8b91134
starting org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11991ms org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51b35e4e for org.apache.spark.ui.JettyUtils$$anon$3-1fba386c
Started o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @11991ms o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @11991ms org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 mime types IncludeExclude@6d7cada5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@350a94ce,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7e00ed0f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 added {o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-1a891add from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-1a891add=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
STARTED @11995ms org.spark_project.jetty.servlet.ServletHandler@3874b815
starting org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @11995ms org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@b0fc838 for org.spark_project.jetty.servlet.DefaultServlet-1a891add
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @12008ms o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @12008ms org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff mime types IncludeExclude@57c47a9e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@642505c7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4339e0de}
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff added {o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
STARTED @12011ms org.spark_project.jetty.servlet.ServletHandler@387bf2d9
starting org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @12011ms org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@153cd6bb for org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72
Started o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @12012ms o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @12012ms org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 mime types IncludeExclude@2d9f64c9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21ac5eb4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@52d6cd34}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 added {o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5533dc72
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
STARTED @12016ms org.spark_project.jetty.servlet.ServletHandler@5533dc72
starting org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @12017ms org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @12017ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @12017ms o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @12017ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 mime types IncludeExclude@1abfe081{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2a685eba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c2e3264}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 added {o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-6dd82486=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
STARTED @12021ms org.spark_project.jetty.servlet.ServletHandler@6ea04618
starting org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @12021ms org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@107f4980 for org.apache.spark.ui.JettyUtils$$anon$4-6dd82486
Started o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @12021ms o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @12021ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 mime types IncludeExclude@1d540566{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6014a9ba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@acdcf71}
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 added {o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-2d23faef=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
STARTED @12024ms org.spark_project.jetty.servlet.ServletHandler@7026b7ee
starting org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @12024ms org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@77d680e6 for org.apache.spark.ui.JettyUtils$$anon$4-2d23faef
Started o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @12024ms o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @12024ms org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 40242
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40242.
Server created on quickstart.cloudera:40242
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 40242, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:40242 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 40242, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 40242, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 40242, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7b306b9f
o.s.j.s.ServletContextHandler@142213d5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@934b52f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
STARTED @12848ms org.spark_project.jetty.servlet.ServletHandler@934b52f
starting org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12848ms org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ff23ae7 for org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4
Started o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
STARTED @12849ms o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/').
Warehouse path is 'file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@737d100a
o.s.j.s.ServletContextHandler@12e5da86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6535117e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6fa13e6
o.s.j.s.ServletContextHandler@3af7d855{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@77049094,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
STARTED @13746ms org.spark_project.jetty.servlet.ServletHandler@6535117e
starting org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13746ms org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@59bbe88a for org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f
Started o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
STARTED @13746ms o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
STARTED @13755ms org.spark_project.jetty.servlet.ServletHandler@77049094
starting org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13755ms org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5d8ab698 for org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe
Started o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
STARTED @13755ms o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446626a7
o.s.j.s.ServletContextHandler@429f7919{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4a2929a4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-cda6019,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@797c3c3b
o.s.j.s.ServletContextHandler@4012d5bc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4375b013,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-cda6019 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-cda6019=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
STARTED @13776ms org.spark_project.jetty.servlet.ServletHandler@4a2929a4
starting org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13777ms org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4f5b08d for org.apache.spark.ui.JettyUtils$$anon$3-cda6019
Started o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @13777ms o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
STARTED @13781ms org.spark_project.jetty.servlet.ServletHandler@4375b013
starting org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13781ms org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@529c2a9a for org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc
Started o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @13783ms o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3c98781a
o.s.j.s.ServletContextHandler@3f736a16{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4601203a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-53abfc07,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-53abfc07 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-53abfc07=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
STARTED @13792ms org.spark_project.jetty.servlet.ServletHandler@4601203a
starting org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @13792ms org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@2c8c16c0 for org.spark_project.jetty.servlet.DefaultServlet-53abfc07
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
STARTED @13793ms o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-31136b47-0929-4df1-882b-8a631aaff7cf-1318335073-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-1, groupId=spark-kafka-source-31136b47-0929-4df1-882b-8a631aaff7cf-1318335073-driver-0] Initializing the Kafka consumer
[Consumer clientId=consumer-1, groupId=spark-kafka-source-31136b47-0929-4df1-882b-8a631aaff7cf-1318335073-driver-0] Kafka consumer has been closed
Invoking stop() from shutdown hook
stopping org.spark_project.jetty.server.Server@3effd4f3
doStop org.spark_project.jetty.server.Server@3effd4f3
ran SparkUI-29-acceptor-0@6aba5d30-ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Graceful shutdown org.spark_project.jetty.server.Server@3effd4f3 by 
stopping Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@631af705 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@631af705
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@26cee85 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@26cee85
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@103c7fbe produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@103c7fbe produce exit
ran org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
Stopped org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STOPPED HttpConnectionFactory@5a8cbffe[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
Stopped Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@3effd4f3
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@3effd4f3
Stopped Spark web UI at http://quickstart.cloudera:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory /tmp/temporaryReader-6d30292e-5bd0-4735-9228-ae8f069693bb
Deleting directory /tmp/spark-5732a11c-95de-422f-9f61-a5a5f82e8f3d
2020-09-03 13:26:34.567 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:26:34.567 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:26:34.567 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:26:34.567 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:26:34.567 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: 50a14882-10ea-4319-a894-04194b87d8f0
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 23072 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 38359
Successfully started service 'sparkDriver' on port 38359.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-004b0cd7-a583-4f93-ac52-32112a8789f9
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @10134ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@68c7ef83
o.s.j.s.ServletContextHandler@455824ad{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7318daf8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7318daf8 added {org.apache.spark.ui.JettyUtils$$anon$3-6601cc93@e7c7bda7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7318daf8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6601cc93,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@507b79f7
o.s.j.s.ServletContextHandler@64a9d48c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@365a6a43,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@365a6a43 added {org.apache.spark.ui.JettyUtils$$anon$3-288cdaab@c2774ebb==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@365a6a43 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-288cdaab,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@35342d2f
o.s.j.s.ServletContextHandler@128c502c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45667d98,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45667d98 added {org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45667d98 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-65eabaab,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7123be6c
o.s.j.s.ServletContextHandler@1de9d54{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@77a2aa4a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@77a2aa4a added {org.apache.spark.ui.JettyUtils$$anon$3-47ad69f7@a342b766==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@77a2aa4a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-47ad69f7,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@10c2064a
o.s.j.s.ServletContextHandler@70e13fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ff415ad,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ff415ad added {org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ff415ad added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-280d9edc,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@28fd3dc1
o.s.j.s.ServletContextHandler@5f9b6ae7{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@108d55c4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@108d55c4 added {org.apache.spark.ui.JettyUtils$$anon$3-5432c277@1b460379==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@108d55c4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5432c277,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1128620c
o.s.j.s.ServletContextHandler@6bf13698{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@299270eb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@299270eb added {org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@299270eb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@69fa8e76
o.s.j.s.ServletContextHandler@bdd2027{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@31f20c9f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@31f20c9f added {org.apache.spark.ui.JettyUtils$$anon$3-f446158@4a4c1198==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@31f20c9f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-f446158,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@504e1599
o.s.j.s.ServletContextHandler@71f96dfb{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d added {org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-69e05f61,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@49a26d19
o.s.j.s.ServletContextHandler@730e5763{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7275c74b,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7275c74b added {org.apache.spark.ui.JettyUtils$$anon$3-19058533@7f38b3b6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7275c74b added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-19058533,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@dab48d3
o.s.j.s.ServletContextHandler@58a2b4c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7159a5cd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7159a5cd added {org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7159a5cd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4f966719,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@18ac53e8
o.s.j.s.ServletContextHandler@4ca8dbfa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7063686f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7063686f added {org.apache.spark.ui.JettyUtils$$anon$3-c3177d5@a9bad146==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7063686f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-c3177d5,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7c853486
o.s.j.s.ServletContextHandler@174e1b69{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1046498a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1046498a added {org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1046498a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-243f003c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@71cb3139
o.s.j.s.ServletContextHandler@1639f93a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3491e86e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3491e86e added {org.apache.spark.ui.JettyUtils$$anon$3-68f32020@adbf0e37==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3491e86e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-68f32020,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@53dad875
o.s.j.s.ServletContextHandler@5f780a86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@446c3920,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@446c3920 added {org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@446c3920 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2b329bbd
o.s.j.s.ServletContextHandler@34819867{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@118102ee,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@118102ee added {org.apache.spark.ui.JettyUtils$$anon$3-48cd9a2c@db94910a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@118102ee added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-48cd9a2c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1da4b6b3
o.s.j.s.ServletContextHandler@b2f4ece{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7e1f584d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7e1f584d added {org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7e1f584d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@45d64d27
o.s.j.s.ServletContextHandler@34fe326d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@30a7c98f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@30a7c98f added {org.apache.spark.ui.JettyUtils$$anon$3-36361ddb@b5728503==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@30a7c98f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-36361ddb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4d6ee47
o.s.j.s.ServletContextHandler@a33b4e3{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@c6da8bb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@c6da8bb added {org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@c6da8bb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@8b91134
o.s.j.s.ServletContextHandler@1fba386c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7e736350,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7e736350 added {org.apache.spark.ui.JettyUtils$$anon$3-36b310aa@57b401f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7e736350 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-36b310aa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3874b815
o.s.j.s.ServletContextHandler@5d7835a8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@736048ed,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@736048ed added {org.spark_project.jetty.servlet.DefaultServlet-373f7450@8859bebe==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@736048ed added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-373f7450,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@387bf2d9
o.s.j.s.ServletContextHandler@74aa9c72{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5c20aab9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5c20aab9 added {org.apache.spark.ui.JettyUtils$$anon$4-4b7c4456@327d7966==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5c20aab9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-4b7c4456,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5533dc72
o.s.j.s.ServletContextHandler@7c447c76{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@64fc097e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@64fc097e added {org.glassfish.jersey.servlet.ServletContainer-431f1eaf@d5e8191b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@64fc097e added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-431f1eaf,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6ea04618
o.s.j.s.ServletContextHandler@6dd82486{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@56078cea,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@56078cea added {org.apache.spark.ui.JettyUtils$$anon$4-5a00eb1e@56cec288==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@56078cea added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-5a00eb1e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7026b7ee
o.s.j.s.ServletContextHandler@2d23faef{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7cb8437d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7cb8437d added {org.apache.spark.ui.JettyUtils$$anon$4-62a4417@f274f6e0==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7cb8437d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-62a4417,POJO}
org.spark_project.jetty.server.Server@15f8701f added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@15f8701f added {org.spark_project.jetty.server.handler.ErrorHandler@6f4ade6e,AUTO}
org.spark_project.jetty.server.Server@15f8701f added {org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[],MANAGED}
starting org.spark_project.jetty.server.Server@15f8701f
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@15f8701f
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @10332ms SparkUI{STARTED,8<=8<=200,i=8,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@6f4ade6e
starting org.spark_project.jetty.server.handler.ErrorHandler@6f4ade6e
STARTED @10333ms org.spark_project.jetty.server.handler.ErrorHandler@6f4ade6e
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[]
STARTED @10333ms org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[]
Started @10333ms
STARTED @10333ms org.spark_project.jetty.server.Server@15f8701f
HttpConnectionFactory@61e7bf2f[HTTP/1.1] added {HttpConfiguration@1a28b346{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@1f44ddab{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@15f8701f,UNMANAGED}
ServerConnector@1f44ddab{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@1f44ddab{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5017e1,AUTO}
ServerConnector@1f44ddab{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@65b66b08,POJO}
ServerConnector@1f44ddab{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@61e7bf2f[HTTP/1.1],AUTO}
ServerConnector@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@61e7bf2f[HTTP/1.1]
ServerConnector@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@5cb042da,MANAGED}
starting ServerConnector@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5017e1
STARTED @10364ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5017e1
starting HttpConnectionFactory@61e7bf2f[HTTP/1.1]
STARTED @10364ms HttpConnectionFactory@61e7bf2f[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@5cb042da
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@5cb042da added {org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=0 selected=0
STARTED @10370ms org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=0 selected=0
STARTED @10371ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@5cb042da
run org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@758798a1 execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@758798a1 produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@758798a1 producing
Selector loop waiting on select
ServerConnector@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@588307f7,POJO}
queue acceptor-0@588307f7
run acceptor-0@588307f7
Started ServerConnector@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STARTED @10376ms ServerConnector@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@15f8701f added {Spark@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9 mime types IncludeExclude@73437222{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@ca93621,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6a48a7f3}
org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9 added {o.s.j.s.ServletContextHandler@455824ad{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9
starting o.s.j.s.ServletContextHandler@455824ad{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@455824ad{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7318daf8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6601cc93 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6601cc93@e7c7bda7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6601cc93=org.apache.spark.ui.JettyUtils$$anon$3-6601cc93@e7c7bda7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7318daf8
STARTED @10425ms org.spark_project.jetty.servlet.ServletHandler@7318daf8
starting org.apache.spark.ui.JettyUtils$$anon$3-6601cc93@e7c7bda7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10428ms org.apache.spark.ui.JettyUtils$$anon$3-6601cc93@e7c7bda7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7bca6fac for org.apache.spark.ui.JettyUtils$$anon$3-6601cc93
Started o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}
STARTED @10430ms o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}
STARTED @10431ms org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9
org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0 mime types IncludeExclude@7a2b1eb4{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@702c436b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5833f5cd}
org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0 added {o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0
starting o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@365a6a43
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-288cdaab from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-288cdaab@c2774ebb==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-288cdaab=org.apache.spark.ui.JettyUtils$$anon$3-288cdaab@c2774ebb==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@365a6a43
STARTED @10440ms org.spark_project.jetty.servlet.ServletHandler@365a6a43
starting org.apache.spark.ui.JettyUtils$$anon$3-288cdaab@c2774ebb==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10442ms org.apache.spark.ui.JettyUtils$$anon$3-288cdaab@c2774ebb==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@23f3dbf0 for org.apache.spark.ui.JettyUtils$$anon$3-288cdaab
Started o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}
STARTED @10442ms o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}
STARTED @10442ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0
org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe mime types IncludeExclude@760cf594{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@aa149ed,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@37303f12}
org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe added {o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe
starting o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45667d98
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-65eabaab from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-65eabaab=org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45667d98
STARTED @10447ms org.spark_project.jetty.servlet.ServletHandler@45667d98
starting org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10447ms org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@31ff6309 for org.apache.spark.ui.JettyUtils$$anon$3-65eabaab
Started o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @10449ms o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @10449ms org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe
org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32 mime types IncludeExclude@165e389b{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c73f672,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@8ee0c23}
org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32 added {o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32
starting o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@77a2aa4a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-47ad69f7 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-47ad69f7@a342b766==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-47ad69f7=org.apache.spark.ui.JettyUtils$$anon$3-47ad69f7@a342b766==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@77a2aa4a
STARTED @10460ms org.spark_project.jetty.servlet.ServletHandler@77a2aa4a
starting org.apache.spark.ui.JettyUtils$$anon$3-47ad69f7@a342b766==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10460ms org.apache.spark.ui.JettyUtils$$anon$3-47ad69f7@a342b766==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2ab5afc7 for org.apache.spark.ui.JettyUtils$$anon$3-47ad69f7
Started o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @10460ms o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @10460ms org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32
org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea mime types IncludeExclude@e4b6f47{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@763cf5b9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@71f0b72e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea added {o.s.j.s.ServletContextHandler@70e13fa{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea
starting o.s.j.s.ServletContextHandler@70e13fa{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@70e13fa{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ff415ad
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-280d9edc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-280d9edc=org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ff415ad
STARTED @10463ms org.spark_project.jetty.servlet.ServletHandler@6ff415ad
starting org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10463ms org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a34f66a for org.apache.spark.ui.JettyUtils$$anon$3-280d9edc
Started o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}
STARTED @10463ms o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}
STARTED @10463ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea
org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c mime types IncludeExclude@3ed03652{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4aedaf61,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@173797f0}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c added {o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c
starting o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@108d55c4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5432c277 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5432c277@1b460379==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5432c277=org.apache.spark.ui.JettyUtils$$anon$3-5432c277@1b460379==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@108d55c4
STARTED @10474ms org.spark_project.jetty.servlet.ServletHandler@108d55c4
starting org.apache.spark.ui.JettyUtils$$anon$3-5432c277@1b460379==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10474ms org.apache.spark.ui.JettyUtils$$anon$3-5432c277@1b460379==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3c35c345 for org.apache.spark.ui.JettyUtils$$anon$3-5432c277
Started o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}
STARTED @10476ms o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}
STARTED @10476ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c
org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037 mime types IncludeExclude@2459319c{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@ffaaaf0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1dc76fa1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037 added {o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037
starting o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@299270eb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a=org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@299270eb
STARTED @10480ms org.spark_project.jetty.servlet.ServletHandler@299270eb
starting org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10480ms org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5eed2d86 for org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a
Started o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}
STARTED @10480ms o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}
STARTED @10480ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037
org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344 mime types IncludeExclude@7808f638{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@62d73ead,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1e141e42}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344 added {o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344
starting o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@31f20c9f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-f446158 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-f446158@4a4c1198==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-f446158=org.apache.spark.ui.JettyUtils$$anon$3-f446158@4a4c1198==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@31f20c9f
STARTED @10487ms org.spark_project.jetty.servlet.ServletHandler@31f20c9f
starting org.apache.spark.ui.JettyUtils$$anon$3-f446158@4a4c1198==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10487ms org.apache.spark.ui.JettyUtils$$anon$3-f446158@4a4c1198==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@228cea97 for org.apache.spark.ui.JettyUtils$$anon$3-f446158
Started o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @10488ms o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @10488ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344
org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8 mime types IncludeExclude@46731692{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@782bf610,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3db663d0}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8 added {o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8
starting o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-69e05f61 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-69e05f61=org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d
STARTED @10491ms org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d
starting org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10491ms org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@73fc518f for org.apache.spark.ui.JettyUtils$$anon$3-69e05f61
Started o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}
STARTED @10492ms o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}
STARTED @10492ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8
org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4 mime types IncludeExclude@ad9e63e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@47fbc56,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@151ef57f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4 added {o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4
starting o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7275c74b
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-19058533 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-19058533@7f38b3b6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-19058533=org.apache.spark.ui.JettyUtils$$anon$3-19058533@7f38b3b6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7275c74b
STARTED @10495ms org.spark_project.jetty.servlet.ServletHandler@7275c74b
starting org.apache.spark.ui.JettyUtils$$anon$3-19058533@7f38b3b6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10496ms org.apache.spark.ui.JettyUtils$$anon$3-19058533@7f38b3b6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@10895b16 for org.apache.spark.ui.JettyUtils$$anon$3-19058533
Started o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @10496ms o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @10496ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4
org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f mime types IncludeExclude@2cc03cd1{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4e17913b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@149c3204}
org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f added {o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f
starting o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7159a5cd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4f966719 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4f966719=org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7159a5cd
STARTED @10500ms org.spark_project.jetty.servlet.ServletHandler@7159a5cd
starting org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10500ms org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@64f16277 for org.apache.spark.ui.JettyUtils$$anon$3-4f966719
Started o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}
STARTED @10500ms o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}
STARTED @10500ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f
org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c mime types IncludeExclude@3b9632d1{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4e6f2bb5,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21e20ad5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c added {o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c
starting o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7063686f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-c3177d5 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-c3177d5@a9bad146==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-c3177d5=org.apache.spark.ui.JettyUtils$$anon$3-c3177d5@a9bad146==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7063686f
STARTED @10504ms org.spark_project.jetty.servlet.ServletHandler@7063686f
starting org.apache.spark.ui.JettyUtils$$anon$3-c3177d5@a9bad146==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10504ms org.apache.spark.ui.JettyUtils$$anon$3-c3177d5@a9bad146==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3f628ce9 for org.apache.spark.ui.JettyUtils$$anon$3-c3177d5
Started o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}
STARTED @10504ms o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}
STARTED @10505ms org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c
org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e mime types IncludeExclude@26d96e5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@336880df,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1846579f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e added {o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e
starting o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1046498a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-243f003c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-243f003c=org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1046498a
STARTED @10509ms org.spark_project.jetty.servlet.ServletHandler@1046498a
starting org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10509ms org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6cd166b8 for org.apache.spark.ui.JettyUtils$$anon$3-243f003c
Started o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @10509ms o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @10509ms org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e
org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79 mime types IncludeExclude@75fc1992{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5fac521d,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@38af1bf6}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79 added {o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79
starting o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3491e86e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-68f32020 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-68f32020@adbf0e37==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-68f32020=org.apache.spark.ui.JettyUtils$$anon$3-68f32020@adbf0e37==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3491e86e
STARTED @10514ms org.spark_project.jetty.servlet.ServletHandler@3491e86e
starting org.apache.spark.ui.JettyUtils$$anon$3-68f32020@adbf0e37==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10514ms org.apache.spark.ui.JettyUtils$$anon$3-68f32020@adbf0e37==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@129bd55d for org.apache.spark.ui.JettyUtils$$anon$3-68f32020
Started o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @10514ms o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @10514ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79
org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15 mime types IncludeExclude@3abfe845{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a0f244f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3672276e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15 added {o.s.j.s.ServletContextHandler@5f780a86{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15
starting o.s.j.s.ServletContextHandler@5f780a86{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5f780a86{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@446c3920
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d=org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@446c3920
STARTED @10518ms org.spark_project.jetty.servlet.ServletHandler@446c3920
starting org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10518ms org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4248b963 for org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d
Started o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}
STARTED @10518ms o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}
STARTED @10518ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15
org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf mime types IncludeExclude@4defd42{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2330e3e0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@24b4d544}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf added {o.s.j.s.ServletContextHandler@34819867{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf
starting o.s.j.s.ServletContextHandler@34819867{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@34819867{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@118102ee
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-48cd9a2c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-48cd9a2c@db94910a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-48cd9a2c=org.apache.spark.ui.JettyUtils$$anon$3-48cd9a2c@db94910a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@118102ee
STARTED @10522ms org.spark_project.jetty.servlet.ServletHandler@118102ee
starting org.apache.spark.ui.JettyUtils$$anon$3-48cd9a2c@db94910a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10522ms org.apache.spark.ui.JettyUtils$$anon$3-48cd9a2c@db94910a==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@27a2a089 for org.apache.spark.ui.JettyUtils$$anon$3-48cd9a2c
Started o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}
STARTED @10522ms o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}
STARTED @10522ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf
org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2 mime types IncludeExclude@706eab5d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@72725ee1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@40e60ece}
org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2 added {o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2
starting o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7e1f584d
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05=org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7e1f584d
STARTED @10527ms org.spark_project.jetty.servlet.ServletHandler@7e1f584d
starting org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10527ms org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3f9270ed for org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05
Started o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}
STARTED @10527ms o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}
STARTED @10527ms org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2
org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001 mime types IncludeExclude@5ac6c4f2{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2aa6311a,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@61f39bb}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001 added {o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,[o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001
starting o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@30a7c98f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-36361ddb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-36361ddb@b5728503==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-36361ddb=org.apache.spark.ui.JettyUtils$$anon$3-36361ddb@b5728503==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@30a7c98f
STARTED @10531ms org.spark_project.jetty.servlet.ServletHandler@30a7c98f
starting org.apache.spark.ui.JettyUtils$$anon$3-36361ddb@b5728503==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10531ms org.apache.spark.ui.JettyUtils$$anon$3-36361ddb@b5728503==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@249e0271 for org.apache.spark.ui.JettyUtils$$anon$3-36361ddb
Started o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}
STARTED @10531ms o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}
STARTED @10532ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001
org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344 mime types IncludeExclude@53a665ad{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2c0b4c83,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@78525ef9}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344 added {o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,[o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344
starting o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@c6da8bb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0=org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@c6da8bb
STARTED @10535ms org.spark_project.jetty.servlet.ServletHandler@c6da8bb
starting org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10535ms org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2d0ecb24 for org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0
Started o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @10536ms o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @10536ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344
org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825 mime types IncludeExclude@3bfc6a5e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@51b35e4e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@abff8b7}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825 added {o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,[o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825,[o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825
starting o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7e736350
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-36b310aa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-36b310aa@57b401f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-36b310aa=org.apache.spark.ui.JettyUtils$$anon$3-36b310aa@57b401f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7e736350
STARTED @10539ms org.spark_project.jetty.servlet.ServletHandler@7e736350
starting org.apache.spark.ui.JettyUtils$$anon$3-36b310aa@57b401f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10539ms org.apache.spark.ui.JettyUtils$$anon$3-36b310aa@57b401f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6d7cada5 for org.apache.spark.ui.JettyUtils$$anon$3-36b310aa
Started o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @10539ms o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @10539ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825
org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce mime types IncludeExclude@7e00ed0f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@b0fc838,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3964d79}
org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce added {o.s.j.s.ServletContextHandler@5d7835a8{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825, org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce,[o.s.j.s.ServletContextHandler@5d7835a8{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,[o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825,[o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce
starting o.s.j.s.ServletContextHandler@5d7835a8{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5d7835a8{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@736048ed
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-373f7450 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-373f7450@8859bebe==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-373f7450=org.spark_project.jetty.servlet.DefaultServlet-373f7450@8859bebe==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@736048ed
STARTED @10543ms org.spark_project.jetty.servlet.ServletHandler@736048ed
starting org.spark_project.jetty.servlet.DefaultServlet-373f7450@8859bebe==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @10543ms org.spark_project.jetty.servlet.DefaultServlet-373f7450@8859bebe==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@62db0521 for org.spark_project.jetty.servlet.DefaultServlet-373f7450
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@5d7835a8{/static,null,AVAILABLE,@Spark}
STARTED @10553ms o.s.j.s.ServletContextHandler@5d7835a8{/static,null,AVAILABLE,@Spark}
STARTED @10553ms org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce
org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7 mime types IncludeExclude@4339e0de{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@153cd6bb,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@61d84e08}
org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7 added {o.s.j.s.ServletContextHandler@74aa9c72{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825, org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce, org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7,[o.s.j.s.ServletContextHandler@74aa9c72{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce,[o.s.j.s.ServletContextHandler@5d7835a8{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,[o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825,[o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7
starting o.s.j.s.ServletContextHandler@74aa9c72{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@74aa9c72{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5c20aab9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-4b7c4456 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-4b7c4456@327d7966==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-4b7c4456=org.apache.spark.ui.JettyUtils$$anon$4-4b7c4456@327d7966==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5c20aab9
STARTED @10557ms org.spark_project.jetty.servlet.ServletHandler@5c20aab9
starting org.apache.spark.ui.JettyUtils$$anon$4-4b7c4456@327d7966==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @10557ms org.apache.spark.ui.JettyUtils$$anon$4-4b7c4456@327d7966==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@2d9f64c9 for org.apache.spark.ui.JettyUtils$$anon$4-4b7c4456
Started o.s.j.s.ServletContextHandler@74aa9c72{/,null,AVAILABLE,@Spark}
STARTED @10557ms o.s.j.s.ServletContextHandler@74aa9c72{/,null,AVAILABLE,@Spark}
STARTED @10557ms org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7
org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4 mime types IncludeExclude@52d6cd34{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@715d6168,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@27b2faa6}
org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4 added {o.s.j.s.ServletContextHandler@7c447c76{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825, org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce, org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7, org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7,[o.s.j.s.ServletContextHandler@74aa9c72{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce,[o.s.j.s.ServletContextHandler@5d7835a8{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,[o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825,[o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4,[o.s.j.s.ServletContextHandler@7c447c76{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4
starting o.s.j.s.ServletContextHandler@7c447c76{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7c447c76{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@64fc097e
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-431f1eaf from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-431f1eaf@d5e8191b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-431f1eaf=org.glassfish.jersey.servlet.ServletContainer-431f1eaf@d5e8191b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@64fc097e
org.spark_project.jetty.servlet.ServletHandler@64fc097e added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1abfe081@2dd9dbbc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@64fc097e added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1abfe081,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-431f1eaf from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1abfe081 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-431f1eaf@d5e8191b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1abfe081@2dd9dbbc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-431f1eaf=org.glassfish.jersey.servlet.ServletContainer-431f1eaf@d5e8191b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1abfe081=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1abfe081@2dd9dbbc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@64fc097e
STARTED @10563ms org.spark_project.jetty.servlet.ServletHandler@64fc097e
starting org.glassfish.jersey.servlet.ServletContainer-431f1eaf@d5e8191b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @10563ms org.glassfish.jersey.servlet.ServletContainer-431f1eaf@d5e8191b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1abfe081@2dd9dbbc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @10564ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-1abfe081@2dd9dbbc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@7c447c76{/api,null,AVAILABLE,@Spark}
STARTED @10564ms o.s.j.s.ServletContextHandler@7c447c76{/api,null,AVAILABLE,@Spark}
STARTED @10564ms org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4
org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba mime types IncludeExclude@c2e3264{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@107f4980,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75a118e6}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba added {o.s.j.s.ServletContextHandler@6dd82486{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825, org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce, org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7, org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4, org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7,[o.s.j.s.ServletContextHandler@74aa9c72{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce,[o.s.j.s.ServletContextHandler@5d7835a8{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,[o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825,[o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4,[o.s.j.s.ServletContextHandler@7c447c76{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba,[o.s.j.s.ServletContextHandler@6dd82486{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba
starting o.s.j.s.ServletContextHandler@6dd82486{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6dd82486{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@56078cea
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-5a00eb1e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-5a00eb1e@56cec288==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-5a00eb1e=org.apache.spark.ui.JettyUtils$$anon$4-5a00eb1e@56cec288==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@56078cea
STARTED @10568ms org.spark_project.jetty.servlet.ServletHandler@56078cea
starting org.apache.spark.ui.JettyUtils$$anon$4-5a00eb1e@56cec288==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @10568ms org.apache.spark.ui.JettyUtils$$anon$4-5a00eb1e@56cec288==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@1d540566 for org.apache.spark.ui.JettyUtils$$anon$4-5a00eb1e
Started o.s.j.s.ServletContextHandler@6dd82486{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @10568ms o.s.j.s.ServletContextHandler@6dd82486{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @10568ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba
org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba mime types IncludeExclude@acdcf71{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@77d680e6,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4a14c44f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba added {o.s.j.s.ServletContextHandler@2d23faef{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825, org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce, org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7, org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4, org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba, org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7,[o.s.j.s.ServletContextHandler@74aa9c72{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4,[o.s.j.s.ServletContextHandler@7c447c76{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce,[o.s.j.s.ServletContextHandler@5d7835a8{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,[o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825,[o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba,[o.s.j.s.ServletContextHandler@2d23faef{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba,[o.s.j.s.ServletContextHandler@6dd82486{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba
starting o.s.j.s.ServletContextHandler@2d23faef{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2d23faef{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7cb8437d
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-62a4417 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-62a4417@f274f6e0==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-62a4417=org.apache.spark.ui.JettyUtils$$anon$4-62a4417@f274f6e0==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7cb8437d
STARTED @10573ms org.spark_project.jetty.servlet.ServletHandler@7cb8437d
starting org.apache.spark.ui.JettyUtils$$anon$4-62a4417@f274f6e0==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @10573ms org.apache.spark.ui.JettyUtils$$anon$4-62a4417@f274f6e0==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@f08fdce for org.apache.spark.ui.JettyUtils$$anon$4-62a4417
Started o.s.j.s.ServletContextHandler@2d23faef{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @10574ms o.s.j.s.ServletContextHandler@2d23faef{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @10574ms org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 45957
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45957.
Server created on quickstart.cloudera:45957
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 45957, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:45957 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 45957, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 45957, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 45957, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@934b52f
o.s.j.s.ServletContextHandler@2630dbc4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5ea4300e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5ea4300e added {org.apache.spark.ui.JettyUtils$$anon$3-5a1c3cb4@66f227ac==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5ea4300e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5a1c3cb4,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825, org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce, org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7, org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4, org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba, org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba, o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7,[o.s.j.s.ServletContextHandler@74aa9c72{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f,[o.s.j.s.ServletContextHandler@58a2b4c{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79,[o.s.j.s.ServletContextHandler@1639f93a{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4,[o.s.j.s.ServletContextHandler@7c447c76{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4,[o.s.j.s.ServletContextHandler@730e5763{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0,[o.s.j.s.ServletContextHandler@64a9d48c{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce,[o.s.j.s.ServletContextHandler@5d7835a8{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001,[o.s.j.s.ServletContextHandler@34fe326d{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344,[o.s.j.s.ServletContextHandler@bdd2027{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825,[o.s.j.s.ServletContextHandler@1fba386c{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf,[o.s.j.s.ServletContextHandler@34819867{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32,[o.s.j.s.ServletContextHandler@1de9d54{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9,[o.s.j.s.ServletContextHandler@455824ad{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c,[o.s.j.s.ServletContextHandler@5f9b6ae7{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c,[o.s.j.s.ServletContextHandler@4ca8dbfa{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba,[o.s.j.s.ServletContextHandler@2d23faef{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15,[o.s.j.s.ServletContextHandler@5f780a86{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea,[o.s.j.s.ServletContextHandler@70e13fa{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2,[o.s.j.s.ServletContextHandler@b2f4ece{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba,[o.s.j.s.ServletContextHandler@6dd82486{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5ea4300e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5a1c3cb4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5a1c3cb4@66f227ac==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5a1c3cb4=org.apache.spark.ui.JettyUtils$$anon$3-5a1c3cb4@66f227ac==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5ea4300e
STARTED @11387ms org.spark_project.jetty.servlet.ServletHandler@5ea4300e
starting org.apache.spark.ui.JettyUtils$$anon$3-5a1c3cb4@66f227ac==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11387ms org.apache.spark.ui.JettyUtils$$anon$3-5a1c3cb4@66f227ac==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2b7962a2 for org.apache.spark.ui.JettyUtils$$anon$3-5a1c3cb4
Started o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,AVAILABLE,@Spark}
STARTED @11387ms o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Invoking stop() from shutdown hook
stopping org.spark_project.jetty.server.Server@15f8701f
doStop org.spark_project.jetty.server.Server@15f8701f
ran SparkUI-27-acceptor-0@588307f7-ServerConnector@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Graceful shutdown org.spark_project.jetty.server.Server@15f8701f by 
stopping Spark@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@5cb042da
stopping org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@ffc6c26 on org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@ffc6c26
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@60e92c9b on org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@60e92c9b
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@758798a1 produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@758798a1 produce exit
ran org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=-1 selected=-1
Stopped org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@3bd3d05e id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@5cb042da
stopping HttpConnectionFactory@61e7bf2f[HTTP/1.1]
STOPPED HttpConnectionFactory@61e7bf2f[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5017e1
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5017e1
Stopped Spark@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@1f44ddab{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@15f8701f
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825, org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce, org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7, org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4, org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba, org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba, o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825, org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce, org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7, org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4, org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba, org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba, o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@440eaa07[org.spark_project.jetty.server.handler.gzip.GzipHandler@c6b2dd9, org.spark_project.jetty.server.handler.gzip.GzipHandler@5c60b0a0, org.spark_project.jetty.server.handler.gzip.GzipHandler@31d6f3fe, org.spark_project.jetty.server.handler.gzip.GzipHandler@20a05b32, org.spark_project.jetty.server.handler.gzip.GzipHandler@4dc8c0ea, org.spark_project.jetty.server.handler.gzip.GzipHandler@2f508f3c, org.spark_project.jetty.server.handler.gzip.GzipHandler@3681037, org.spark_project.jetty.server.handler.gzip.GzipHandler@4f3e7344, org.spark_project.jetty.server.handler.gzip.GzipHandler@1d0a61c8, org.spark_project.jetty.server.handler.gzip.GzipHandler@2de50ee4, org.spark_project.jetty.server.handler.gzip.GzipHandler@5524b72f, org.spark_project.jetty.server.handler.gzip.GzipHandler@497aec8c, org.spark_project.jetty.server.handler.gzip.GzipHandler@35e8316e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2650f79, org.spark_project.jetty.server.handler.gzip.GzipHandler@7be7e15, org.spark_project.jetty.server.handler.gzip.GzipHandler@7f08caf, org.spark_project.jetty.server.handler.gzip.GzipHandler@54657dd2, org.spark_project.jetty.server.handler.gzip.GzipHandler@3a230001, org.spark_project.jetty.server.handler.gzip.GzipHandler@4893b344, org.spark_project.jetty.server.handler.gzip.GzipHandler@4d654825, org.spark_project.jetty.server.handler.gzip.GzipHandler@350a94ce, org.spark_project.jetty.server.handler.gzip.GzipHandler@642505c7, org.spark_project.jetty.server.handler.gzip.GzipHandler@21ac5eb4, org.spark_project.jetty.server.handler.gzip.GzipHandler@2a685eba, org.spark_project.jetty.server.handler.gzip.GzipHandler@6014a9ba, o.s.j.s.ServletContextHandler@2630dbc4{/metrics/json,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@6f4ade6e
stopping org.spark_project.jetty.server.handler.ErrorHandler@6f4ade6e
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@6f4ade6e
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@15f8701f
Stopped Spark web UI at http://quickstart.cloudera:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory /tmp/spark-20f3856d-2ce2-4314-a4b4-dff59014abfc
2020-09-03 13:30:03.337 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:30:03.337 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:30:03.337 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:30:03.337 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:30:03.337 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: c6066fab-e2a2-46ea-bc6c-068491fa7b63
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 23298 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 33146
Successfully started service 'sparkDriver' on port 33146.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-eeda4e23-455c-4c2d-930b-3a311392920c
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @9660ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2875b016
o.s.j.s.ServletContextHandler@23940f86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@66153688,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@87b5b49
o.s.j.s.ServletContextHandler@4a7a965d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@507b79f7,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@226eba67
o.s.j.s.ServletContextHandler@1cb7936c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@35342d2f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-128c502c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@45667d98
o.s.j.s.ServletContextHandler@65eabaab{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7123be6c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1de9d54,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@70331432
o.s.j.s.ServletContextHandler@3bbf9027{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c2064a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-70e13fa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6ff415ad
o.s.j.s.ServletContextHandler@280d9edc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@28fd3dc1,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5432c277
o.s.j.s.ServletContextHandler@15e0fe05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1128620c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6bf13698,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@299270eb
o.s.j.s.ServletContextHandler@3b90a30a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@69fa8e76,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-bdd2027,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@f446158
o.s.j.s.ServletContextHandler@32f0c7f8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@504e1599,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5d1b9c3d
o.s.j.s.ServletContextHandler@69e05f61{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@49a26d19,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-730e5763,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2babf189
o.s.j.s.ServletContextHandler@479f2dc2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@dab48d3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7159a5cd
o.s.j.s.ServletContextHandler@4f966719{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@18ac53e8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c3177d5
o.s.j.s.ServletContextHandler@76f856a8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7c853486,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-174e1b69,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1046498a
o.s.j.s.ServletContextHandler@243f003c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@71cb3139,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1639f93a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@19b047fe
o.s.j.s.ServletContextHandler@22590e3e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53dad875,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f780a86,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446c3920
o.s.j.s.ServletContextHandler@2eaef76d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2b329bbd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34819867,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@72d0f2b4
o.s.j.s.ServletContextHandler@6d2dc9d2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1da4b6b3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e1f584d
o.s.j.s.ServletContextHandler@7dff6d05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45d64d27,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34fe326d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36361ddb
o.s.j.s.ServletContextHandler@41fed14f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d6ee47,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c6da8bb
o.s.j.s.ServletContextHandler@3bae64d0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@8b91134,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1fba386c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36b310aa
o.s.j.s.ServletContextHandler@76c387f9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3874b815,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-1a891add,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@d74bac4
o.s.j.s.ServletContextHandler@5ff90645{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@387bf2d9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c768ada
o.s.j.s.ServletContextHandler@c1fca2a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5533dc72,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-27ace0b1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@58ec7116
o.s.j.s.ServletContextHandler@63bde6c2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ea04618,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-6dd82486,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36fcf6c0
o.s.j.s.ServletContextHandler@1aac188d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7026b7ee,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-2d23faef,POJO}
org.spark_project.jetty.server.Server@3effd4f3 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ErrorHandler@514cd540,AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[],MANAGED}
starting org.spark_project.jetty.server.Server@3effd4f3
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@3effd4f3
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @9860ms SparkUI{STARTED,8<=8<=200,i=5,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STARTED @9861ms org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
STARTED @9861ms org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
Started @9861ms
STARTED @9862ms org.spark_project.jetty.server.Server@3effd4f3
HttpConnectionFactory@5a8cbffe[HTTP/1.1] added {HttpConfiguration@96a75da{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@3effd4f3,UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85,AUTO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@1f44ddab,POJO}
ServerConnector@3d7b1f1c{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@5a8cbffe[HTTP/1.1],AUTO}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@5a8cbffe[HTTP/1.1]
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151,MANAGED}
starting ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STARTED @9892ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
starting HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STARTED @9893ms HttpConnectionFactory@5a8cbffe[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151 added {org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @9900ms org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
run org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @9901ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6e3cad90 execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6e3cad90 produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6e3cad90 producing
Selector loop waiting on select
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@6aba5d30,POJO}
queue acceptor-0@6aba5d30
run acceptor-0@6aba5d30
Started ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STARTED @9906ms ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@3effd4f3 added {Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 mime types IncludeExclude@2eb917d0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c6b2dd9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@73437222}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 added {o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
STARTED @9963ms org.spark_project.jetty.servlet.ServletHandler@66153688
starting org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9966ms org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7c2b58c0 for org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e
Started o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @9969ms o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @9969ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 mime types IncludeExclude@7bca6fac{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c60b0a0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a2b1eb4}
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 added {o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
STARTED @9973ms org.spark_project.jetty.servlet.ServletHandler@507b79f7
starting org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9974ms org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5833f5cd for org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c
Started o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @9974ms o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @9974ms org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb mime types IncludeExclude@23f3dbf0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31d6f3fe,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@760cf594}
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb added {o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-128c502c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-128c502c=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
STARTED @9978ms org.spark_project.jetty.servlet.ServletHandler@35342d2f
starting org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9978ms org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@aa149ed for org.apache.spark.ui.JettyUtils$$anon$3-128c502c
Started o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @9979ms o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @9979ms org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 mime types IncludeExclude@204e90f7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@20a05b32,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@165e389b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 added {o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1de9d54=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
STARTED @9984ms org.spark_project.jetty.servlet.ServletHandler@7123be6c
starting org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9984ms org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5c73f672 for org.apache.spark.ui.JettyUtils$$anon$3-1de9d54
Started o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @9984ms o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @9985ms org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 mime types IncludeExclude@2ab5afc7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4dc8c0ea,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@e4b6f47}
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 added {o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-70e13fa=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
STARTED @9988ms org.spark_project.jetty.servlet.ServletHandler@10c2064a
starting org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9988ms org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@763cf5b9 for org.apache.spark.ui.JettyUtils$$anon$3-70e13fa
Started o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @9989ms o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @9989ms org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e mime types IncludeExclude@7a34f66a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2f508f3c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3ed03652}
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e added {o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
STARTED @9992ms org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
starting org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9992ms org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4aedaf61 for org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7
Started o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @9993ms o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @9993ms org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 mime types IncludeExclude@3c35c345{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3681037,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2459319c}
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 added {o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6bf13698=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
STARTED @9996ms org.spark_project.jetty.servlet.ServletHandler@1128620c
starting org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9996ms org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ffaaaf0 for org.apache.spark.ui.JettyUtils$$anon$3-6bf13698
Started o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @9996ms o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @9996ms org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 mime types IncludeExclude@69a2b3b6{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4f3e7344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7808f638}
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 added {o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-bdd2027=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
STARTED @10001ms org.spark_project.jetty.servlet.ServletHandler@69fa8e76
starting org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10002ms org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@62d73ead for org.apache.spark.ui.JettyUtils$$anon$3-bdd2027
Started o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @10002ms o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @10002ms org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 mime types IncludeExclude@228cea97{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d0a61c8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@46731692}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 added {o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
STARTED @10005ms org.spark_project.jetty.servlet.ServletHandler@504e1599
starting org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10005ms org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@782bf610 for org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb
Started o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @10005ms o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @10005ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 mime types IncludeExclude@73fc518f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2de50ee4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@ad9e63e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 added {o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-730e5763 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-730e5763=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
STARTED @10014ms org.spark_project.jetty.servlet.ServletHandler@49a26d19
starting org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10014ms org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@47fbc56 for org.apache.spark.ui.JettyUtils$$anon$3-730e5763
Started o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @10015ms o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @10015ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f mime types IncludeExclude@10895b16{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5524b72f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2cc03cd1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f added {o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
STARTED @10018ms org.spark_project.jetty.servlet.ServletHandler@dab48d3
starting org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10018ms org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e17913b for org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c
Started o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @10018ms o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @10018ms org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 mime types IncludeExclude@64f16277{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@497aec8c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3b9632d1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 added {o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
STARTED @10021ms org.spark_project.jetty.servlet.ServletHandler@18ac53e8
starting org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10022ms org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e6f2bb5 for org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa
Started o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @10022ms o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @10022ms org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 mime types IncludeExclude@3f628ce9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@35e8316e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@26d96e5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 added {o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-174e1b69=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
STARTED @10025ms org.spark_project.jetty.servlet.ServletHandler@7c853486
starting org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10025ms org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@336880df for org.apache.spark.ui.JettyUtils$$anon$3-174e1b69
Started o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @10025ms o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @10026ms org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f mime types IncludeExclude@6cd166b8{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2650f79,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75fc1992}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f added {o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1639f93a=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
STARTED @10029ms org.spark_project.jetty.servlet.ServletHandler@71cb3139
starting org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10029ms org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5fac521d for org.apache.spark.ui.JettyUtils$$anon$3-1639f93a
Started o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @10029ms o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @10029ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 mime types IncludeExclude@129bd55d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7be7e15,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3abfe845}
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 added {o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f780a86=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
STARTED @10034ms org.spark_project.jetty.servlet.ServletHandler@53dad875
starting org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10034ms org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a0f244f for org.apache.spark.ui.JettyUtils$$anon$3-5f780a86
Started o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @10034ms o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @10034ms org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e mime types IncludeExclude@4248b963{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7f08caf,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4defd42}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e added {o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34819867 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34819867=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
STARTED @10039ms org.spark_project.jetty.servlet.ServletHandler@2b329bbd
starting org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10040ms org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2330e3e0 for org.apache.spark.ui.JettyUtils$$anon$3-34819867
Started o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @10040ms o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @10040ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 mime types IncludeExclude@27a2a089{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@54657dd2,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@706eab5d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 added {o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
STARTED @10045ms org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
starting org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10046ms org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@72725ee1 for org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece
Started o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @10046ms o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @10046ms org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece mime types IncludeExclude@3f9270ed{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3a230001,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ac6c4f2}
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece added {o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34fe326d=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
STARTED @10051ms org.spark_project.jetty.servlet.ServletHandler@45d64d27
starting org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10052ms org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2aa6311a for org.apache.spark.ui.JettyUtils$$anon$3-34fe326d
Started o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @10052ms o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @10052ms org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb mime types IncludeExclude@249e0271{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4893b344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@53a665ad}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb added {o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
STARTED @10057ms org.spark_project.jetty.servlet.ServletHandler@4d6ee47
starting org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10057ms org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2c0b4c83 for org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3
Started o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @10057ms o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @10057ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 mime types IncludeExclude@2d0ecb24{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4d654825,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3bfc6a5e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 added {o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1fba386c=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
STARTED @10061ms org.spark_project.jetty.servlet.ServletHandler@8b91134
starting org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10061ms org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51b35e4e for org.apache.spark.ui.JettyUtils$$anon$3-1fba386c
Started o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @10061ms o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @10061ms org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 mime types IncludeExclude@6d7cada5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@350a94ce,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7e00ed0f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 added {o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-1a891add from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-1a891add=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
STARTED @10067ms org.spark_project.jetty.servlet.ServletHandler@3874b815
starting org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @10067ms org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@b0fc838 for org.spark_project.jetty.servlet.DefaultServlet-1a891add
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @10080ms o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @10080ms org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff mime types IncludeExclude@57c47a9e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@642505c7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4339e0de}
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff added {o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
STARTED @10084ms org.spark_project.jetty.servlet.ServletHandler@387bf2d9
starting org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @10084ms org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@153cd6bb for org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72
Started o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @10084ms o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @10084ms org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 mime types IncludeExclude@2d9f64c9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21ac5eb4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@52d6cd34}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 added {o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5533dc72
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
STARTED @10090ms org.spark_project.jetty.servlet.ServletHandler@5533dc72
starting org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @10090ms org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @10091ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @10091ms o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @10091ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 mime types IncludeExclude@1abfe081{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2a685eba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c2e3264}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 added {o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-6dd82486=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
STARTED @10096ms org.spark_project.jetty.servlet.ServletHandler@6ea04618
starting org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @10096ms org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@107f4980 for org.apache.spark.ui.JettyUtils$$anon$4-6dd82486
Started o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @10096ms o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @10097ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 mime types IncludeExclude@1d540566{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6014a9ba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@acdcf71}
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 added {o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-2d23faef=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
STARTED @10103ms org.spark_project.jetty.servlet.ServletHandler@7026b7ee
starting org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @10104ms org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@77d680e6 for org.apache.spark.ui.JettyUtils$$anon$4-2d23faef
Started o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @10104ms o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @10104ms org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 38004
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38004.
Server created on quickstart.cloudera:38004
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 38004, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:38004 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 38004, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 38004, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 38004, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6c0e13b7
o.s.j.s.ServletContextHandler@22eaa86e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@561b7d53,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@561b7d53 added {org.apache.spark.ui.JettyUtils$$anon$3-1cc680e@a96bfcdc==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@561b7d53 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1cc680e,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@561b7d53
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1cc680e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1cc680e@a96bfcdc==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1cc680e=org.apache.spark.ui.JettyUtils$$anon$3-1cc680e@a96bfcdc==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@561b7d53
STARTED @10798ms org.spark_project.jetty.servlet.ServletHandler@561b7d53
starting org.apache.spark.ui.JettyUtils$$anon$3-1cc680e@a96bfcdc==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10799ms org.apache.spark.ui.JettyUtils$$anon$3-1cc680e@a96bfcdc==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@6f94fb9d for org.apache.spark.ui.JettyUtils$$anon$3-1cc680e
Started o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}
STARTED @10799ms o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/').
Warehouse path is 'file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6f1a16fe
o.s.j.s.ServletContextHandler@2373ad99{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@33634f04,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@33634f04 added {org.apache.spark.ui.JettyUtils$$anon$3-4993febc@c6314c0b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@33634f04 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4993febc,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7601bc96
o.s.j.s.ServletContextHandler@48a0c8aa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6192a5d5,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6192a5d5 added {org.apache.spark.ui.JettyUtils$$anon$3-3722c145@e8817ebf==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6192a5d5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3722c145,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@33634f04
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4993febc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4993febc@c6314c0b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4993febc=org.apache.spark.ui.JettyUtils$$anon$3-4993febc@c6314c0b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@33634f04
STARTED @11045ms org.spark_project.jetty.servlet.ServletHandler@33634f04
starting org.apache.spark.ui.JettyUtils$$anon$3-4993febc@c6314c0b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11045ms org.apache.spark.ui.JettyUtils$$anon$3-4993febc@c6314c0b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4cbc2e3b for org.apache.spark.ui.JettyUtils$$anon$3-4993febc
Started o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}
STARTED @11045ms o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6192a5d5
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3722c145 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3722c145@e8817ebf==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3722c145=org.apache.spark.ui.JettyUtils$$anon$3-3722c145@e8817ebf==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6192a5d5
STARTED @11049ms org.spark_project.jetty.servlet.ServletHandler@6192a5d5
starting org.apache.spark.ui.JettyUtils$$anon$3-3722c145@e8817ebf==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11049ms org.apache.spark.ui.JettyUtils$$anon$3-3722c145@e8817ebf==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2975a9e for org.apache.spark.ui.JettyUtils$$anon$3-3722c145
Started o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark}
STARTED @11050ms o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@57562473
o.s.j.s.ServletContextHandler@7a360554{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@424de326,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@424de326 added {org.apache.spark.ui.JettyUtils$$anon$3-4bc33720@86a471ec==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@424de326 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4bc33720,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2dd0f797
o.s.j.s.ServletContextHandler@67064bdc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4a7fd0c9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4a7fd0c9 added {org.apache.spark.ui.JettyUtils$$anon$3-18578491@52f6df89==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4a7fd0c9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-18578491,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@424de326
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4bc33720 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4bc33720@86a471ec==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4bc33720=org.apache.spark.ui.JettyUtils$$anon$3-4bc33720@86a471ec==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@424de326
STARTED @11054ms org.spark_project.jetty.servlet.ServletHandler@424de326
starting org.apache.spark.ui.JettyUtils$$anon$3-4bc33720@86a471ec==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11055ms org.apache.spark.ui.JettyUtils$$anon$3-4bc33720@86a471ec==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3291b443 for org.apache.spark.ui.JettyUtils$$anon$3-4bc33720
Started o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @11055ms o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4a7fd0c9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-18578491 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-18578491@52f6df89==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-18578491=org.apache.spark.ui.JettyUtils$$anon$3-18578491@52f6df89==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4a7fd0c9
STARTED @11059ms org.spark_project.jetty.servlet.ServletHandler@4a7fd0c9
starting org.apache.spark.ui.JettyUtils$$anon$3-18578491@52f6df89==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11059ms org.apache.spark.ui.JettyUtils$$anon$3-18578491@52f6df89==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@671c4166 for org.apache.spark.ui.JettyUtils$$anon$3-18578491
Started o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @11059ms o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4d18b73a
o.s.j.s.ServletContextHandler@177515d1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@52ff99cd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@52ff99cd added {org.spark_project.jetty.servlet.DefaultServlet-4c2af006@5e71a7d==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@52ff99cd added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-4c2af006,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@52ff99cd
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-4c2af006 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-4c2af006@5e71a7d==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-4c2af006=org.spark_project.jetty.servlet.DefaultServlet-4c2af006@5e71a7d==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@52ff99cd
STARTED @11064ms org.spark_project.jetty.servlet.ServletHandler@52ff99cd
starting org.spark_project.jetty.servlet.DefaultServlet-4c2af006@5e71a7d==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @11064ms org.spark_project.jetty.servlet.DefaultServlet-4c2af006@5e71a7d==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@44032fde for org.spark_project.jetty.servlet.DefaultServlet-4c2af006
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,AVAILABLE,@Spark}
STARTED @11065ms o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-382c0024-6f77-44b7-aceb-62ba8bbe0073--1842065126-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-1, groupId=spark-kafka-source-382c0024-6f77-44b7-aceb-62ba8bbe0073--1842065126-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599165009418
[Consumer clientId=consumer-1, groupId=spark-kafka-source-382c0024-6f77-44b7-aceb-62ba8bbe0073--1842065126-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-1, groupId=spark-kafka-source-382c0024-6f77-44b7-aceb-62ba8bbe0073--1842065126-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-382c0024-6f77-44b7-aceb-62ba8bbe0073--1842065126-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Resolving 'invoiceNum to 'invoiceNum
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'merchant to 'merchant
Resolving 'merchant to 'merchant
Resolving 'merchant to 'merchant
Resolving 'merchant to 'merchant
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'productPurchased to 'productPurchased
Resolving 'productPurchased to 'productPurchased
Resolving 'productPurchased to 'productPurchased

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(newInstance(class org.example.spark.POSmetricProcessing.POJO.EntityMapper$Invoice)), obj#26: org.example.spark.POSmetricProcessing.POJO.EntityMapper$Invoice   'DeserializeToObject newInstance(class org.example.spark.POSmetricProcessing.POJO.EntityMapper$Invoice), obj#26: org.example.spark.POSmetricProcessing.POJO.EntityMapper$Invoice
 +- LocalRelation <empty>, [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]                                                                                              +- LocalRelation <empty>, [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13]
          
Invoking stop() from shutdown hook
stopping org.spark_project.jetty.server.Server@3effd4f3
doStop org.spark_project.jetty.server.Server@3effd4f3
ran SparkUI-30-acceptor-0@6aba5d30-ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Graceful shutdown org.spark_project.jetty.server.Server@3effd4f3 by 
stopping Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@6692d001 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@6692d001
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@446f95b2 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@446f95b2
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6e3cad90 produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@6e3cad90 produce exit
ran org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
Stopped org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STOPPED HttpConnectionFactory@5a8cbffe[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
Stopped Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@3effd4f3
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@22eaa86e{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@2373ad99{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@48a0c8aa{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@7a360554{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@67064bdc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@177515d1{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@3effd4f3
Stopped Spark web UI at http://quickstart.cloudera:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory /tmp/temporaryReader-5eb9d6e8-9407-4981-a7e6-eaf7764e9434
Deleting directory /tmp/spark-098f77d6-507a-41ec-8a5f-bde7781b4365
2020-09-03 13:31:46.843 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:31:46.843 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:31:46.843 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:31:46.843 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:31:46.843 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: a5888dfc-02ab-487f-a8dd-9c875bce58cd
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 23468 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 32925
Successfully started service 'sparkDriver' on port 32925.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-95d57162-cfa2-44e0-bc99-2afd9e8870a7
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @8300ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2875b016
o.s.j.s.ServletContextHandler@23940f86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@66153688,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@87b5b49
o.s.j.s.ServletContextHandler@4a7a965d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@507b79f7,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@226eba67
o.s.j.s.ServletContextHandler@1cb7936c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@35342d2f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-128c502c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@45667d98
o.s.j.s.ServletContextHandler@65eabaab{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7123be6c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1de9d54,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@70331432
o.s.j.s.ServletContextHandler@3bbf9027{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c2064a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-70e13fa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6ff415ad
o.s.j.s.ServletContextHandler@280d9edc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@28fd3dc1,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5432c277
o.s.j.s.ServletContextHandler@15e0fe05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1128620c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6bf13698,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@299270eb
o.s.j.s.ServletContextHandler@3b90a30a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@69fa8e76,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-bdd2027,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@f446158
o.s.j.s.ServletContextHandler@32f0c7f8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@504e1599,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5d1b9c3d
o.s.j.s.ServletContextHandler@69e05f61{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@49a26d19,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-730e5763,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2babf189
o.s.j.s.ServletContextHandler@479f2dc2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@dab48d3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7159a5cd
o.s.j.s.ServletContextHandler@4f966719{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@18ac53e8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c3177d5
o.s.j.s.ServletContextHandler@76f856a8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7c853486,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-174e1b69,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1046498a
o.s.j.s.ServletContextHandler@243f003c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@71cb3139,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1639f93a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@19b047fe
o.s.j.s.ServletContextHandler@22590e3e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53dad875,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f780a86,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446c3920
o.s.j.s.ServletContextHandler@2eaef76d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2b329bbd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34819867,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@72d0f2b4
o.s.j.s.ServletContextHandler@6d2dc9d2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1da4b6b3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e1f584d
o.s.j.s.ServletContextHandler@7dff6d05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45d64d27,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34fe326d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36361ddb
o.s.j.s.ServletContextHandler@41fed14f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d6ee47,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c6da8bb
o.s.j.s.ServletContextHandler@3bae64d0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@8b91134,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1fba386c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36b310aa
o.s.j.s.ServletContextHandler@76c387f9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3874b815,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-1a891add,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@d74bac4
o.s.j.s.ServletContextHandler@5ff90645{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@387bf2d9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c768ada
o.s.j.s.ServletContextHandler@c1fca2a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5533dc72,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-27ace0b1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@58ec7116
o.s.j.s.ServletContextHandler@63bde6c2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ea04618,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-6dd82486,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36fcf6c0
o.s.j.s.ServletContextHandler@1aac188d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7026b7ee,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-2d23faef,POJO}
org.spark_project.jetty.server.Server@3effd4f3 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ErrorHandler@514cd540,AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[],MANAGED}
starting org.spark_project.jetty.server.Server@3effd4f3
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@3effd4f3
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @8600ms SparkUI{STARTED,8<=8<=200,i=7,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STARTED @8601ms org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
STARTED @8601ms org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
Started @8601ms
STARTED @8602ms org.spark_project.jetty.server.Server@3effd4f3
HttpConnectionFactory@5a8cbffe[HTTP/1.1] added {HttpConfiguration@96a75da{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@3effd4f3,UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85,AUTO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@1f44ddab,POJO}
ServerConnector@3d7b1f1c{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@5a8cbffe[HTTP/1.1],AUTO}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@5a8cbffe[HTTP/1.1]
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151,MANAGED}
starting ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STARTED @8666ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
starting HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STARTED @8669ms HttpConnectionFactory@5a8cbffe[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151 added {org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @8682ms org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
run org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @8684ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4eb2a0a9 execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4eb2a0a9 produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4eb2a0a9 producing
Selector loop waiting on select
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@6aba5d30,POJO}
queue acceptor-0@6aba5d30
run acceptor-0@6aba5d30
Started ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STARTED @8689ms ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@3effd4f3 added {Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 mime types IncludeExclude@2eb917d0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c6b2dd9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@73437222}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 added {o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
STARTED @8788ms org.spark_project.jetty.servlet.ServletHandler@66153688
starting org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8791ms org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7c2b58c0 for org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e
Started o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @8794ms o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @8794ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 mime types IncludeExclude@7bca6fac{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c60b0a0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a2b1eb4}
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 added {o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
STARTED @8802ms org.spark_project.jetty.servlet.ServletHandler@507b79f7
starting org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8803ms org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5833f5cd for org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c
Started o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @8804ms o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @8804ms org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb mime types IncludeExclude@23f3dbf0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31d6f3fe,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@760cf594}
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb added {o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-128c502c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-128c502c=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
STARTED @8807ms org.spark_project.jetty.servlet.ServletHandler@35342d2f
starting org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8808ms org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@aa149ed for org.apache.spark.ui.JettyUtils$$anon$3-128c502c
Started o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @8809ms o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @8809ms org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 mime types IncludeExclude@204e90f7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@20a05b32,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@165e389b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 added {o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1de9d54=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
STARTED @8816ms org.spark_project.jetty.servlet.ServletHandler@7123be6c
starting org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8816ms org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5c73f672 for org.apache.spark.ui.JettyUtils$$anon$3-1de9d54
Started o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @8819ms o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @8819ms org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 mime types IncludeExclude@2ab5afc7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4dc8c0ea,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@e4b6f47}
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 added {o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-70e13fa=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
STARTED @8829ms org.spark_project.jetty.servlet.ServletHandler@10c2064a
starting org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8830ms org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@763cf5b9 for org.apache.spark.ui.JettyUtils$$anon$3-70e13fa
Started o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @8830ms o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @8831ms org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e mime types IncludeExclude@7a34f66a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2f508f3c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3ed03652}
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e added {o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
STARTED @8837ms org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
starting org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8838ms org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4aedaf61 for org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7
Started o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @8838ms o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @8838ms org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 mime types IncludeExclude@3c35c345{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3681037,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2459319c}
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 added {o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6bf13698=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
STARTED @8851ms org.spark_project.jetty.servlet.ServletHandler@1128620c
starting org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8851ms org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ffaaaf0 for org.apache.spark.ui.JettyUtils$$anon$3-6bf13698
Started o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @8852ms o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @8852ms org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 mime types IncludeExclude@69a2b3b6{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4f3e7344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7808f638}
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 added {o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-bdd2027=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
STARTED @8857ms org.spark_project.jetty.servlet.ServletHandler@69fa8e76
starting org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8858ms org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@62d73ead for org.apache.spark.ui.JettyUtils$$anon$3-bdd2027
Started o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @8858ms o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @8858ms org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 mime types IncludeExclude@228cea97{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d0a61c8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@46731692}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 added {o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
STARTED @8861ms org.spark_project.jetty.servlet.ServletHandler@504e1599
starting org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8861ms org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@782bf610 for org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb
Started o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @8861ms o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @8861ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 mime types IncludeExclude@73fc518f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2de50ee4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@ad9e63e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 added {o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-730e5763 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-730e5763=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
STARTED @8864ms org.spark_project.jetty.servlet.ServletHandler@49a26d19
starting org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8865ms org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@47fbc56 for org.apache.spark.ui.JettyUtils$$anon$3-730e5763
Started o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @8865ms o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @8865ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f mime types IncludeExclude@10895b16{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5524b72f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2cc03cd1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f added {o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
STARTED @8868ms org.spark_project.jetty.servlet.ServletHandler@dab48d3
starting org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8869ms org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e17913b for org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c
Started o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @8869ms o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @8869ms org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 mime types IncludeExclude@64f16277{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@497aec8c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3b9632d1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 added {o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
STARTED @8872ms org.spark_project.jetty.servlet.ServletHandler@18ac53e8
starting org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8872ms org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e6f2bb5 for org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa
Started o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @8872ms o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @8872ms org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 mime types IncludeExclude@3f628ce9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@35e8316e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@26d96e5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 added {o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-174e1b69=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
STARTED @8876ms org.spark_project.jetty.servlet.ServletHandler@7c853486
starting org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8876ms org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@336880df for org.apache.spark.ui.JettyUtils$$anon$3-174e1b69
Started o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @8876ms o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @8876ms org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f mime types IncludeExclude@6cd166b8{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2650f79,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75fc1992}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f added {o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1639f93a=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
STARTED @8881ms org.spark_project.jetty.servlet.ServletHandler@71cb3139
starting org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8881ms org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5fac521d for org.apache.spark.ui.JettyUtils$$anon$3-1639f93a
Started o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @8882ms o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @8882ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 mime types IncludeExclude@129bd55d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7be7e15,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3abfe845}
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 added {o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f780a86=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
STARTED @8886ms org.spark_project.jetty.servlet.ServletHandler@53dad875
starting org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8887ms org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a0f244f for org.apache.spark.ui.JettyUtils$$anon$3-5f780a86
Started o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @8887ms o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @8887ms org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e mime types IncludeExclude@4248b963{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7f08caf,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4defd42}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e added {o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34819867 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34819867=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
STARTED @8893ms org.spark_project.jetty.servlet.ServletHandler@2b329bbd
starting org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8893ms org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2330e3e0 for org.apache.spark.ui.JettyUtils$$anon$3-34819867
Started o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @8893ms o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @8893ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 mime types IncludeExclude@27a2a089{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@54657dd2,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@706eab5d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 added {o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
STARTED @8897ms org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
starting org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8898ms org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@72725ee1 for org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece
Started o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @8898ms o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @8898ms org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece mime types IncludeExclude@3f9270ed{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3a230001,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ac6c4f2}
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece added {o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34fe326d=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
STARTED @8903ms org.spark_project.jetty.servlet.ServletHandler@45d64d27
starting org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8903ms org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2aa6311a for org.apache.spark.ui.JettyUtils$$anon$3-34fe326d
Started o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @8903ms o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @8903ms org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb mime types IncludeExclude@249e0271{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4893b344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@53a665ad}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb added {o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
STARTED @8908ms org.spark_project.jetty.servlet.ServletHandler@4d6ee47
starting org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8908ms org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2c0b4c83 for org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3
Started o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @8908ms o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @8909ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 mime types IncludeExclude@2d0ecb24{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4d654825,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3bfc6a5e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 added {o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1fba386c=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
STARTED @8912ms org.spark_project.jetty.servlet.ServletHandler@8b91134
starting org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8913ms org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51b35e4e for org.apache.spark.ui.JettyUtils$$anon$3-1fba386c
Started o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @8914ms o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @8914ms org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 mime types IncludeExclude@6d7cada5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@350a94ce,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7e00ed0f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 added {o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-1a891add from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-1a891add=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
STARTED @8917ms org.spark_project.jetty.servlet.ServletHandler@3874b815
starting org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @8917ms org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@b0fc838 for org.spark_project.jetty.servlet.DefaultServlet-1a891add
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @8937ms o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @8937ms org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff mime types IncludeExclude@57c47a9e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@642505c7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4339e0de}
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff added {o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
STARTED @8943ms org.spark_project.jetty.servlet.ServletHandler@387bf2d9
starting org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @8946ms org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@153cd6bb for org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72
Started o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @8946ms o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @8946ms org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 mime types IncludeExclude@2d9f64c9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21ac5eb4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@52d6cd34}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 added {o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5533dc72
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
STARTED @8953ms org.spark_project.jetty.servlet.ServletHandler@5533dc72
starting org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @8953ms org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @8953ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @8954ms o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @8954ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 mime types IncludeExclude@1abfe081{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2a685eba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c2e3264}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 added {o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-6dd82486=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
STARTED @8959ms org.spark_project.jetty.servlet.ServletHandler@6ea04618
starting org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @8960ms org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@107f4980 for org.apache.spark.ui.JettyUtils$$anon$4-6dd82486
Started o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @8960ms o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @8960ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 mime types IncludeExclude@1d540566{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6014a9ba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@acdcf71}
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 added {o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-2d23faef=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
STARTED @8963ms org.spark_project.jetty.servlet.ServletHandler@7026b7ee
starting org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @8963ms org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@77d680e6 for org.apache.spark.ui.JettyUtils$$anon$4-2d23faef
Started o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @8963ms o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @8963ms org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 46114
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46114.
Server created on quickstart.cloudera:46114
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 46114, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:46114 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 46114, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 46114, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 46114, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7b306b9f
o.s.j.s.ServletContextHandler@142213d5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@934b52f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
STARTED @9749ms org.spark_project.jetty.servlet.ServletHandler@934b52f
starting org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9749ms org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ff23ae7 for org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4
Started o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
STARTED @9749ms o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/').
Warehouse path is 'file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6fa13e6
o.s.j.s.ServletContextHandler@3af7d855{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@77049094,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@59bbe88a
o.s.j.s.ServletContextHandler@5d8ab698{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@ed91d8d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@ed91d8d added {org.apache.spark.ui.JettyUtils$$anon$3-446626a7@b8a58c66==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@ed91d8d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-446626a7,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
STARTED @9986ms org.spark_project.jetty.servlet.ServletHandler@77049094
starting org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9986ms org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@429f7919 for org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe
Started o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}
STARTED @9986ms o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@ed91d8d
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-446626a7 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-446626a7@b8a58c66==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-446626a7=org.apache.spark.ui.JettyUtils$$anon$3-446626a7@b8a58c66==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@ed91d8d
STARTED @9988ms org.spark_project.jetty.servlet.ServletHandler@ed91d8d
starting org.apache.spark.ui.JettyUtils$$anon$3-446626a7@b8a58c66==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9988ms org.apache.spark.ui.JettyUtils$$anon$3-446626a7@b8a58c66==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4a2929a4 for org.apache.spark.ui.JettyUtils$$anon$3-446626a7
Started o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark}
STARTED @9988ms o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@797c3c3b
o.s.j.s.ServletContextHandler@4012d5bc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4375b013,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4f5b08d
o.s.j.s.ServletContextHandler@529c2a9a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3c87fdf2,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3c87fdf2 added {org.apache.spark.ui.JettyUtils$$anon$3-26bbe604@a04817a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3c87fdf2 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-26bbe604,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
STARTED @9991ms org.spark_project.jetty.servlet.ServletHandler@4375b013
starting org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9991ms org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@fe34b86 for org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc
Started o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @9991ms o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3c87fdf2
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-26bbe604 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-26bbe604@a04817a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-26bbe604=org.apache.spark.ui.JettyUtils$$anon$3-26bbe604@a04817a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3c87fdf2
STARTED @9994ms org.spark_project.jetty.servlet.ServletHandler@3c87fdf2
starting org.apache.spark.ui.JettyUtils$$anon$3-26bbe604@a04817a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9994ms org.apache.spark.ui.JettyUtils$$anon$3-26bbe604@a04817a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3c98781a for org.apache.spark.ui.JettyUtils$$anon$3-26bbe604
Started o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @9994ms o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c8c16c0
o.s.j.s.ServletContextHandler@80bfa9d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@47c40b56,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@47c40b56 added {org.spark_project.jetty.servlet.DefaultServlet-4b039c6d@cafb4078==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@47c40b56 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-4b039c6d,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@47c40b56
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-4b039c6d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-4b039c6d@cafb4078==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-4b039c6d=org.spark_project.jetty.servlet.DefaultServlet-4b039c6d@cafb4078==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@47c40b56
STARTED @9999ms org.spark_project.jetty.servlet.ServletHandler@47c40b56
starting org.spark_project.jetty.servlet.DefaultServlet-4b039c6d@cafb4078==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @9999ms org.spark_project.jetty.servlet.DefaultServlet-4b039c6d@cafb4078==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@7f5b9db for org.spark_project.jetty.servlet.DefaultServlet-4b039c6d
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,AVAILABLE,@Spark}
STARTED @9999ms o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-02e7dbce-f26b-48c2-b10f-0a53340521f1-567617023-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-1, groupId=spark-kafka-source-02e7dbce-f26b-48c2-b10f-0a53340521f1-567617023-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599165112329
[Consumer clientId=consumer-1, groupId=spark-kafka-source-02e7dbce-f26b-48c2-b10f-0a53340521f1-567617023-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-1, groupId=spark-kafka-source-02e7dbce-f26b-48c2-b10f-0a53340521f1-567617023-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-02e7dbce-f26b-48c2-b10f-0a53340521f1-567617023-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Parsing command: CAST(value AS STRING)
Resolving 'value to value#8

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast('value as string), None)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@101330ad, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@79e10fb4,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@101330ad, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@79e10fb4,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Cleanup ===
 Project [cast(value#8 as string) AS value#21]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@101330ad, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@79e10fb4,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@101330ad, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@79e10fb4,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          
Resolving 'invoiceNum to 'invoiceNum
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'consumerDetails to 'consumerDetails
Resolving 'merchant to 'merchant
Resolving 'merchant to 'merchant
Resolving 'merchant to 'merchant
Resolving 'merchant to 'merchant
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'location to 'location
Resolving 'productPurchased to 'productPurchased
Resolving 'productPurchased to 'productPurchased
Resolving 'productPurchased to 'productPurchased

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(newInstance(class org.example.spark.POSmetricProcessing.POJO.EntityMapper$Invoice)), obj#28: org.example.spark.POSmetricProcessing.POJO.EntityMapper$Invoice   'DeserializeToObject newInstance(class org.example.spark.POSmetricProcessing.POJO.EntityMapper$Invoice), obj#28: org.example.spark.POSmetricProcessing.POJO.EntityMapper$Invoice
 +- LocalRelation <empty>, [value#21]                                                                                                                                                                       +- LocalRelation <empty>, [value#21]
          
Invoking stop() from shutdown hook
stopping org.spark_project.jetty.server.Server@3effd4f3
doStop org.spark_project.jetty.server.Server@3effd4f3
ran SparkUI-29-acceptor-0@6aba5d30-ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Graceful shutdown org.spark_project.jetty.server.Server@3effd4f3 by 
stopping Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@429197a on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@429197a
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@23d4fc13 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@23d4fc13
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4eb2a0a9 produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4eb2a0a9 produce exit
ran org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
Stopped org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STOPPED HttpConnectionFactory@5a8cbffe[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
Stopped Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@3effd4f3
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@5d8ab698{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@529c2a9a{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@80bfa9d{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@3effd4f3
Stopped Spark web UI at http://quickstart.cloudera:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory /tmp/temporaryReader-b4624f30-cd32-4971-abb5-5e03cd0db3ec
Deleting directory /tmp/spark-ed90609a-691c-4755-968f-ab9868dc5ea1
2020-09-03 13:35:10.369 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:35:10.369 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:35:10.369 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:35:10.369 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:35:10.369 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: 47b7e5af-0a28-4537-92ce-b86746d3f4e4
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 23731 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 39432
Successfully started service 'sparkDriver' on port 39432.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-2eb26a8d-eaea-4174-955b-9866337d7dfe
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @7544ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2875b016
o.s.j.s.ServletContextHandler@23940f86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@66153688,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@87b5b49
o.s.j.s.ServletContextHandler@4a7a965d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@507b79f7,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@226eba67
o.s.j.s.ServletContextHandler@1cb7936c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@35342d2f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-128c502c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@45667d98
o.s.j.s.ServletContextHandler@65eabaab{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7123be6c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1de9d54,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@70331432
o.s.j.s.ServletContextHandler@3bbf9027{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c2064a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-70e13fa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6ff415ad
o.s.j.s.ServletContextHandler@280d9edc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@28fd3dc1,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5432c277
o.s.j.s.ServletContextHandler@15e0fe05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1128620c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6bf13698,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@299270eb
o.s.j.s.ServletContextHandler@3b90a30a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@69fa8e76,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-bdd2027,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@f446158
o.s.j.s.ServletContextHandler@32f0c7f8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@504e1599,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5d1b9c3d
o.s.j.s.ServletContextHandler@69e05f61{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@49a26d19,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-730e5763,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2babf189
o.s.j.s.ServletContextHandler@479f2dc2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@dab48d3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7159a5cd
o.s.j.s.ServletContextHandler@4f966719{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@18ac53e8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c3177d5
o.s.j.s.ServletContextHandler@76f856a8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7c853486,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-174e1b69,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1046498a
o.s.j.s.ServletContextHandler@243f003c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@71cb3139,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1639f93a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@19b047fe
o.s.j.s.ServletContextHandler@22590e3e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53dad875,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f780a86,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446c3920
o.s.j.s.ServletContextHandler@2eaef76d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2b329bbd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34819867,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@72d0f2b4
o.s.j.s.ServletContextHandler@6d2dc9d2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1da4b6b3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e1f584d
o.s.j.s.ServletContextHandler@7dff6d05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45d64d27,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34fe326d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36361ddb
o.s.j.s.ServletContextHandler@41fed14f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d6ee47,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c6da8bb
o.s.j.s.ServletContextHandler@3bae64d0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@8b91134,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1fba386c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36b310aa
o.s.j.s.ServletContextHandler@76c387f9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3874b815,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-1a891add,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@d74bac4
o.s.j.s.ServletContextHandler@5ff90645{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@387bf2d9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c768ada
o.s.j.s.ServletContextHandler@c1fca2a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5533dc72,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-27ace0b1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@58ec7116
o.s.j.s.ServletContextHandler@63bde6c2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ea04618,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-6dd82486,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36fcf6c0
o.s.j.s.ServletContextHandler@1aac188d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7026b7ee,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-2d23faef,POJO}
org.spark_project.jetty.server.Server@3effd4f3 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ErrorHandler@514cd540,AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[],MANAGED}
starting org.spark_project.jetty.server.Server@3effd4f3
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@3effd4f3
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @8317ms SparkUI{STARTED,8<=8<=200,i=6,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STARTED @8317ms org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
STARTED @8318ms org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
Started @8318ms
STARTED @8318ms org.spark_project.jetty.server.Server@3effd4f3
HttpConnectionFactory@5a8cbffe[HTTP/1.1] added {HttpConfiguration@96a75da{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@3effd4f3,UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85,AUTO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@1f44ddab,POJO}
ServerConnector@3d7b1f1c{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@5a8cbffe[HTTP/1.1],AUTO}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@5a8cbffe[HTTP/1.1]
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151,MANAGED}
starting ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STARTED @8357ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
starting HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STARTED @8358ms HttpConnectionFactory@5a8cbffe[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151 added {org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @8367ms org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
run org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @8368ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7b3cbd2a execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7b3cbd2a produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7b3cbd2a producing
Selector loop waiting on select
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@6aba5d30,POJO}
queue acceptor-0@6aba5d30
run acceptor-0@6aba5d30
Started ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STARTED @8378ms ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@3effd4f3 added {Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 mime types IncludeExclude@2eb917d0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c6b2dd9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@73437222}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 added {o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
STARTED @8460ms org.spark_project.jetty.servlet.ServletHandler@66153688
starting org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8462ms org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7c2b58c0 for org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e
Started o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @8465ms o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @8465ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 mime types IncludeExclude@7bca6fac{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c60b0a0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a2b1eb4}
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 added {o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
STARTED @8468ms org.spark_project.jetty.servlet.ServletHandler@507b79f7
starting org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8468ms org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5833f5cd for org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c
Started o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @8469ms o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @8469ms org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb mime types IncludeExclude@23f3dbf0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31d6f3fe,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@760cf594}
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb added {o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-128c502c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-128c502c=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
STARTED @8471ms org.spark_project.jetty.servlet.ServletHandler@35342d2f
starting org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8471ms org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@aa149ed for org.apache.spark.ui.JettyUtils$$anon$3-128c502c
Started o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @8471ms o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @8471ms org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 mime types IncludeExclude@204e90f7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@20a05b32,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@165e389b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 added {o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1de9d54=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
STARTED @8475ms org.spark_project.jetty.servlet.ServletHandler@7123be6c
starting org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8476ms org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5c73f672 for org.apache.spark.ui.JettyUtils$$anon$3-1de9d54
Started o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @8476ms o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @8476ms org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 mime types IncludeExclude@2ab5afc7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4dc8c0ea,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@e4b6f47}
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 added {o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-70e13fa=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
STARTED @8479ms org.spark_project.jetty.servlet.ServletHandler@10c2064a
starting org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8479ms org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@763cf5b9 for org.apache.spark.ui.JettyUtils$$anon$3-70e13fa
Started o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @8480ms o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @8480ms org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e mime types IncludeExclude@7a34f66a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2f508f3c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3ed03652}
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e added {o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
STARTED @8483ms org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
starting org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8483ms org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4aedaf61 for org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7
Started o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @8483ms o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @8483ms org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 mime types IncludeExclude@3c35c345{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3681037,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2459319c}
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 added {o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6bf13698=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
STARTED @8487ms org.spark_project.jetty.servlet.ServletHandler@1128620c
starting org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8487ms org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ffaaaf0 for org.apache.spark.ui.JettyUtils$$anon$3-6bf13698
Started o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @8487ms o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @8487ms org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 mime types IncludeExclude@69a2b3b6{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4f3e7344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7808f638}
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 added {o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-bdd2027=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
STARTED @8493ms org.spark_project.jetty.servlet.ServletHandler@69fa8e76
starting org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8493ms org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@62d73ead for org.apache.spark.ui.JettyUtils$$anon$3-bdd2027
Started o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @8493ms o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @8493ms org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 mime types IncludeExclude@228cea97{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d0a61c8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@46731692}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 added {o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
STARTED @8496ms org.spark_project.jetty.servlet.ServletHandler@504e1599
starting org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8497ms org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@782bf610 for org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb
Started o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @8497ms o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @8497ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 mime types IncludeExclude@73fc518f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2de50ee4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@ad9e63e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 added {o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-730e5763 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-730e5763=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
STARTED @8501ms org.spark_project.jetty.servlet.ServletHandler@49a26d19
starting org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8502ms org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@47fbc56 for org.apache.spark.ui.JettyUtils$$anon$3-730e5763
Started o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @8502ms o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @8502ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f mime types IncludeExclude@10895b16{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5524b72f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2cc03cd1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f added {o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
STARTED @8506ms org.spark_project.jetty.servlet.ServletHandler@dab48d3
starting org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8506ms org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e17913b for org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c
Started o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @8506ms o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @8507ms org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 mime types IncludeExclude@64f16277{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@497aec8c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3b9632d1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 added {o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
STARTED @8510ms org.spark_project.jetty.servlet.ServletHandler@18ac53e8
starting org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8510ms org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e6f2bb5 for org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa
Started o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @8511ms o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @8511ms org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 mime types IncludeExclude@3f628ce9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@35e8316e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@26d96e5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 added {o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-174e1b69=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
STARTED @8514ms org.spark_project.jetty.servlet.ServletHandler@7c853486
starting org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8515ms org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@336880df for org.apache.spark.ui.JettyUtils$$anon$3-174e1b69
Started o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @8515ms o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @8515ms org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f mime types IncludeExclude@6cd166b8{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2650f79,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75fc1992}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f added {o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1639f93a=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
STARTED @8519ms org.spark_project.jetty.servlet.ServletHandler@71cb3139
starting org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8519ms org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5fac521d for org.apache.spark.ui.JettyUtils$$anon$3-1639f93a
Started o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @8519ms o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @8519ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 mime types IncludeExclude@129bd55d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7be7e15,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3abfe845}
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 added {o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f780a86=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
STARTED @8523ms org.spark_project.jetty.servlet.ServletHandler@53dad875
starting org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8523ms org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a0f244f for org.apache.spark.ui.JettyUtils$$anon$3-5f780a86
Started o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @8524ms o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @8524ms org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e mime types IncludeExclude@4248b963{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7f08caf,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4defd42}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e added {o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34819867 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34819867=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
STARTED @8527ms org.spark_project.jetty.servlet.ServletHandler@2b329bbd
starting org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8528ms org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2330e3e0 for org.apache.spark.ui.JettyUtils$$anon$3-34819867
Started o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @8528ms o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @8528ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 mime types IncludeExclude@27a2a089{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@54657dd2,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@706eab5d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 added {o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
STARTED @8532ms org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
starting org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8532ms org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@72725ee1 for org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece
Started o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @8532ms o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @8532ms org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece mime types IncludeExclude@3f9270ed{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3a230001,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ac6c4f2}
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece added {o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34fe326d=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
STARTED @8536ms org.spark_project.jetty.servlet.ServletHandler@45d64d27
starting org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8537ms org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2aa6311a for org.apache.spark.ui.JettyUtils$$anon$3-34fe326d
Started o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @8537ms o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @8537ms org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb mime types IncludeExclude@249e0271{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4893b344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@53a665ad}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb added {o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
STARTED @8541ms org.spark_project.jetty.servlet.ServletHandler@4d6ee47
starting org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8541ms org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2c0b4c83 for org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3
Started o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @8541ms o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @8541ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 mime types IncludeExclude@2d0ecb24{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4d654825,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3bfc6a5e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 added {o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1fba386c=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
STARTED @8546ms org.spark_project.jetty.servlet.ServletHandler@8b91134
starting org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8546ms org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51b35e4e for org.apache.spark.ui.JettyUtils$$anon$3-1fba386c
Started o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @8546ms o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @8546ms org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 mime types IncludeExclude@6d7cada5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@350a94ce,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7e00ed0f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 added {o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-1a891add from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-1a891add=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
STARTED @8551ms org.spark_project.jetty.servlet.ServletHandler@3874b815
starting org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @8551ms org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@b0fc838 for org.spark_project.jetty.servlet.DefaultServlet-1a891add
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @8564ms o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @8564ms org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff mime types IncludeExclude@57c47a9e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@642505c7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4339e0de}
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff added {o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
STARTED @8567ms org.spark_project.jetty.servlet.ServletHandler@387bf2d9
starting org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @8567ms org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@153cd6bb for org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72
Started o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @8567ms o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @8567ms org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 mime types IncludeExclude@2d9f64c9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21ac5eb4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@52d6cd34}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 added {o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5533dc72
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
STARTED @8571ms org.spark_project.jetty.servlet.ServletHandler@5533dc72
starting org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @8571ms org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @8571ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @8572ms o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @8572ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 mime types IncludeExclude@1abfe081{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2a685eba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c2e3264}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 added {o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-6dd82486=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
STARTED @8575ms org.spark_project.jetty.servlet.ServletHandler@6ea04618
starting org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @8575ms org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@107f4980 for org.apache.spark.ui.JettyUtils$$anon$4-6dd82486
Started o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @8576ms o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @8576ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 mime types IncludeExclude@1d540566{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6014a9ba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@acdcf71}
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 added {o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-2d23faef=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
STARTED @8578ms org.spark_project.jetty.servlet.ServletHandler@7026b7ee
starting org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @8578ms org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@77d680e6 for org.apache.spark.ui.JettyUtils$$anon$4-2d23faef
Started o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @8578ms o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @8579ms org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 34273
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34273.
Server created on quickstart.cloudera:34273
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 34273, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:34273 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 34273, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 34273, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 34273, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7b306b9f
o.s.j.s.ServletContextHandler@142213d5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@934b52f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
STARTED @9252ms org.spark_project.jetty.servlet.ServletHandler@934b52f
starting org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @9252ms org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ff23ae7 for org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4
Started o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
STARTED @9252ms o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/').
Warehouse path is 'file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@737d100a
o.s.j.s.ServletContextHandler@12e5da86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6535117e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6fa13e6
o.s.j.s.ServletContextHandler@3af7d855{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@77049094,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
STARTED @10005ms org.spark_project.jetty.servlet.ServletHandler@6535117e
starting org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10005ms org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@59bbe88a for org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f
Started o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
STARTED @10006ms o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
STARTED @10010ms org.spark_project.jetty.servlet.ServletHandler@77049094
starting org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10010ms org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5d8ab698 for org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe
Started o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
STARTED @10010ms o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446626a7
o.s.j.s.ServletContextHandler@429f7919{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4a2929a4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-cda6019,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@797c3c3b
o.s.j.s.ServletContextHandler@4012d5bc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4375b013,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-cda6019 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-cda6019=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
STARTED @10012ms org.spark_project.jetty.servlet.ServletHandler@4a2929a4
starting org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10012ms org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4f5b08d for org.apache.spark.ui.JettyUtils$$anon$3-cda6019
Started o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @10013ms o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
STARTED @10015ms org.spark_project.jetty.servlet.ServletHandler@4375b013
starting org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @10015ms org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@529c2a9a for org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc
Started o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @10016ms o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3c98781a
o.s.j.s.ServletContextHandler@3f736a16{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4601203a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-53abfc07,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-53abfc07 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-53abfc07=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
STARTED @10020ms org.spark_project.jetty.servlet.ServletHandler@4601203a
starting org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @10020ms org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@2c8c16c0 for org.spark_project.jetty.servlet.DefaultServlet-53abfc07
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
STARTED @10021ms o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-a72a8c03-6764-425c-82ec-9d65f6fa5a67-1044768959-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-1, groupId=spark-kafka-source-a72a8c03-6764-425c-82ec-9d65f6fa5a67-1044768959-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599165316386
[Consumer clientId=consumer-1, groupId=spark-kafka-source-a72a8c03-6764-425c-82ec-9d65f6fa5a67-1044768959-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-1, groupId=spark-kafka-source-a72a8c03-6764-425c-82ec-9d65f6fa5a67-1044768959-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-a72a8c03-6764-425c-82ec-9d65f6fa5a67-1044768959-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Parsing command: CAST(value AS STRING)
Resolving 'value to value#8

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast('value as string), None)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Cleanup ===
 Project [cast(value#8 as string) AS value#21]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#24: java.lang.String   DeserializeToObject cast(value#21 as string).toString, obj#24: java.lang.String
 +- LocalRelation <empty>, [value#21]                                                                                                                                      +- LocalRelation <empty>, [value#21]
          
Expected a closure; got org.example.spark.POSmetricProcessing.hbaseUtils.invoiceWriter
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Starting [id = 4ab4a87b-3036-484b-aa24-9be40ce77a63, runId = 23983dae-e631-4001-9f69-044e254db211]. Use file:///tmp/temporary-21a46ae8-ada8-4b5e-881c-b5846e3199b6 to store the query checkpoint.
Invoking stop() from shutdown hook
stopping org.spark_project.jetty.server.Server@3effd4f3
doStop org.spark_project.jetty.server.Server@3effd4f3
ran SparkUI-28-acceptor-0@6aba5d30-ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Graceful shutdown org.spark_project.jetty.server.Server@3effd4f3 by 
stopping Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@5f63fea1 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@5f63fea1
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@3b2843c4 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@3b2843c4
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7b3cbd2a produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7b3cbd2a produce exit
ran org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
Stopped org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STOPPED HttpConnectionFactory@5a8cbffe[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
Stopped Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@3effd4f3
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@3effd4f3
Stopped Spark web UI at http://quickstart.cloudera:4040
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-dab285de-de1c-47c5-8e2d-2843092d8ae8-1636247617-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-2, groupId=spark-kafka-source-dab285de-de1c-47c5-8e2d-2843092d8ae8-1636247617-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
MapOutputTrackerMasterEndpoint stopped!
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599165319612
[Consumer clientId=consumer-2, groupId=spark-kafka-source-dab285de-de1c-47c5-8e2d-2843092d8ae8-1636247617-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-2, groupId=spark-kafka-source-dab285de-de1c-47c5-8e2d-2843092d8ae8-1636247617-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-dab285de-de1c-47c5-8e2d-2843092d8ae8-1636247617-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
MemoryStore cleared
BlockManager stopped
Query [id = 4ab4a87b-3036-484b-aa24-9be40ce77a63, runId = 23983dae-e631-4001-9f69-044e254db211] terminated with error
java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:99)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:88)
	at org.apache.spark.sql.SparkSession.cloneSession(SparkSession.scala:252)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:268)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:189)
BlockManagerMaster stopped
Removed sensor with name connections-closed:
Removed sensor with name connections-created:
OutputCommitCoordinator stopped!
Removed sensor with name successful-authentication:
Removed sensor with name successful-reauthentication:
Removed sensor with name successful-authentication-no-reauth:
Successfully stopped SparkContext
Removed sensor with name failed-authentication:
Removed sensor with name failed-reauthentication:
Removed sensor with name reauthentication-latency:
Removed sensor with name bytes-sent-received:
Removed sensor with name bytes-sent:
Removed sensor with name bytes-received:
Removed sensor with name select-time:
Removed sensor with name io-time:
[Consumer clientId=consumer-2, groupId=spark-kafka-source-dab285de-de1c-47c5-8e2d-2843092d8ae8-1636247617-driver-0] Kafka consumer has been closed
Shutdown hook called
Deleting directory /tmp/temporary-21a46ae8-ada8-4b5e-881c-b5846e3199b6
Deleting directory /tmp/temporaryReader-8776f7ee-5ebe-4b38-a8c1-4ae0560e419c
Deleting directory /tmp/spark-93a6546b-7fea-4022-ae51-ff250437b588
2020-09-03 13:41:05.809 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:41:05.809 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:41:05.809 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:41:05.809 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-03 13:41:05.809 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, about=, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: 3d20a071-ba88-4211-ba96-db3a6ed2851c
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 24035 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 45176
Successfully started service 'sparkDriver' on port 45176.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-0c19fee8-db81-4352-975e-d53059d0b4f7
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @7280ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2875b016
o.s.j.s.ServletContextHandler@23940f86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@66153688,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@87b5b49
o.s.j.s.ServletContextHandler@4a7a965d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@507b79f7,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@226eba67
o.s.j.s.ServletContextHandler@1cb7936c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@35342d2f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-128c502c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@45667d98
o.s.j.s.ServletContextHandler@65eabaab{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7123be6c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1de9d54,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@70331432
o.s.j.s.ServletContextHandler@3bbf9027{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c2064a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-70e13fa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6ff415ad
o.s.j.s.ServletContextHandler@280d9edc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@28fd3dc1,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5432c277
o.s.j.s.ServletContextHandler@15e0fe05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1128620c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6bf13698,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@299270eb
o.s.j.s.ServletContextHandler@3b90a30a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@69fa8e76,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-bdd2027,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@f446158
o.s.j.s.ServletContextHandler@32f0c7f8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@504e1599,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5d1b9c3d
o.s.j.s.ServletContextHandler@69e05f61{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@49a26d19,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-730e5763,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2babf189
o.s.j.s.ServletContextHandler@479f2dc2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@dab48d3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7159a5cd
o.s.j.s.ServletContextHandler@4f966719{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@18ac53e8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c3177d5
o.s.j.s.ServletContextHandler@76f856a8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7c853486,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-174e1b69,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1046498a
o.s.j.s.ServletContextHandler@243f003c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@71cb3139,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1639f93a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@19b047fe
o.s.j.s.ServletContextHandler@22590e3e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53dad875,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f780a86,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446c3920
o.s.j.s.ServletContextHandler@2eaef76d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2b329bbd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34819867,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@72d0f2b4
o.s.j.s.ServletContextHandler@6d2dc9d2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1da4b6b3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e1f584d
o.s.j.s.ServletContextHandler@7dff6d05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45d64d27,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34fe326d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36361ddb
o.s.j.s.ServletContextHandler@41fed14f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d6ee47,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c6da8bb
o.s.j.s.ServletContextHandler@3bae64d0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@8b91134,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1fba386c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36b310aa
o.s.j.s.ServletContextHandler@76c387f9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3874b815,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-1a891add,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@d74bac4
o.s.j.s.ServletContextHandler@5ff90645{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@387bf2d9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c768ada
o.s.j.s.ServletContextHandler@c1fca2a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5533dc72,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-27ace0b1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@58ec7116
o.s.j.s.ServletContextHandler@63bde6c2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ea04618,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-6dd82486,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36fcf6c0
o.s.j.s.ServletContextHandler@1aac188d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7026b7ee,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-2d23faef,POJO}
org.spark_project.jetty.server.Server@3effd4f3 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ErrorHandler@514cd540,AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[],MANAGED}
starting org.spark_project.jetty.server.Server@3effd4f3
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@3effd4f3
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @7460ms SparkUI{STARTED,8<=8<=200,i=7,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STARTED @7461ms org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
STARTED @7461ms org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
Started @7461ms
STARTED @7461ms org.spark_project.jetty.server.Server@3effd4f3
HttpConnectionFactory@5a8cbffe[HTTP/1.1] added {HttpConfiguration@96a75da{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@3effd4f3,UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85,AUTO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@1f44ddab,POJO}
ServerConnector@3d7b1f1c{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@5a8cbffe[HTTP/1.1],AUTO}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@5a8cbffe[HTTP/1.1]
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151,MANAGED}
starting ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STARTED @7504ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
starting HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STARTED @7504ms HttpConnectionFactory@5a8cbffe[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151 added {org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
run org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@689b78aa execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@689b78aa produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@689b78aa producing
Selector loop waiting on select
STARTED @7513ms org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @7513ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@6aba5d30,POJO}
queue acceptor-0@6aba5d30
Started ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
run acceptor-0@6aba5d30
STARTED @7516ms ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@3effd4f3 added {Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 mime types IncludeExclude@2eb917d0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c6b2dd9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@73437222}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 added {o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
STARTED @7596ms org.spark_project.jetty.servlet.ServletHandler@66153688
starting org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7600ms org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7c2b58c0 for org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e
Started o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @7608ms o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @7608ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 mime types IncludeExclude@7bca6fac{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c60b0a0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a2b1eb4}
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 added {o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
STARTED @7613ms org.spark_project.jetty.servlet.ServletHandler@507b79f7
starting org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7613ms org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5833f5cd for org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c
Started o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @7619ms o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @7619ms org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb mime types IncludeExclude@23f3dbf0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31d6f3fe,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@760cf594}
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb added {o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-128c502c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-128c502c=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
STARTED @7622ms org.spark_project.jetty.servlet.ServletHandler@35342d2f
starting org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7623ms org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@aa149ed for org.apache.spark.ui.JettyUtils$$anon$3-128c502c
Started o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @7623ms o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @7623ms org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 mime types IncludeExclude@204e90f7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@20a05b32,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@165e389b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 added {o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1de9d54=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
STARTED @7627ms org.spark_project.jetty.servlet.ServletHandler@7123be6c
starting org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7627ms org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5c73f672 for org.apache.spark.ui.JettyUtils$$anon$3-1de9d54
Started o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @7627ms o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @7627ms org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 mime types IncludeExclude@2ab5afc7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4dc8c0ea,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@e4b6f47}
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 added {o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-70e13fa=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
STARTED @7630ms org.spark_project.jetty.servlet.ServletHandler@10c2064a
starting org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7630ms org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@763cf5b9 for org.apache.spark.ui.JettyUtils$$anon$3-70e13fa
Started o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @7631ms o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @7631ms org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e mime types IncludeExclude@7a34f66a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2f508f3c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3ed03652}
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e added {o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
STARTED @7633ms org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
starting org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7633ms org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4aedaf61 for org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7
Started o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @7634ms o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @7634ms org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 mime types IncludeExclude@3c35c345{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3681037,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2459319c}
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 added {o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6bf13698=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
STARTED @7637ms org.spark_project.jetty.servlet.ServletHandler@1128620c
starting org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7637ms org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ffaaaf0 for org.apache.spark.ui.JettyUtils$$anon$3-6bf13698
Started o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @7637ms o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @7637ms org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 mime types IncludeExclude@69a2b3b6{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4f3e7344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7808f638}
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 added {o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-bdd2027=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
STARTED @7643ms org.spark_project.jetty.servlet.ServletHandler@69fa8e76
starting org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7643ms org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@62d73ead for org.apache.spark.ui.JettyUtils$$anon$3-bdd2027
Started o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @7644ms o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @7644ms org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 mime types IncludeExclude@228cea97{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d0a61c8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@46731692}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 added {o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
STARTED @7647ms org.spark_project.jetty.servlet.ServletHandler@504e1599
starting org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7647ms org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@782bf610 for org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb
Started o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @7648ms o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @7648ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 mime types IncludeExclude@73fc518f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2de50ee4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@ad9e63e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 added {o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-730e5763 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-730e5763=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
STARTED @7651ms org.spark_project.jetty.servlet.ServletHandler@49a26d19
starting org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7652ms org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@47fbc56 for org.apache.spark.ui.JettyUtils$$anon$3-730e5763
Started o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @7652ms o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @7652ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f mime types IncludeExclude@10895b16{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5524b72f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2cc03cd1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f added {o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
STARTED @7656ms org.spark_project.jetty.servlet.ServletHandler@dab48d3
starting org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7656ms org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e17913b for org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c
Started o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @7656ms o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @7656ms org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 mime types IncludeExclude@64f16277{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@497aec8c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3b9632d1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 added {o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
STARTED @7660ms org.spark_project.jetty.servlet.ServletHandler@18ac53e8
starting org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7660ms org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e6f2bb5 for org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa
Started o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @7660ms o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @7660ms org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 mime types IncludeExclude@3f628ce9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@35e8316e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@26d96e5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 added {o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-174e1b69=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
STARTED @7664ms org.spark_project.jetty.servlet.ServletHandler@7c853486
starting org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7664ms org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@336880df for org.apache.spark.ui.JettyUtils$$anon$3-174e1b69
Started o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @7664ms o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @7664ms org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f mime types IncludeExclude@6cd166b8{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2650f79,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75fc1992}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f added {o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1639f93a=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
STARTED @7669ms org.spark_project.jetty.servlet.ServletHandler@71cb3139
starting org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7669ms org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5fac521d for org.apache.spark.ui.JettyUtils$$anon$3-1639f93a
Started o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @7669ms o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @7669ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 mime types IncludeExclude@129bd55d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7be7e15,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3abfe845}
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 added {o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f780a86=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
STARTED @7674ms org.spark_project.jetty.servlet.ServletHandler@53dad875
starting org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7674ms org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a0f244f for org.apache.spark.ui.JettyUtils$$anon$3-5f780a86
Started o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @7674ms o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @7674ms org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e mime types IncludeExclude@4248b963{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7f08caf,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4defd42}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e added {o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34819867 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34819867=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
STARTED @7677ms org.spark_project.jetty.servlet.ServletHandler@2b329bbd
starting org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7678ms org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2330e3e0 for org.apache.spark.ui.JettyUtils$$anon$3-34819867
Started o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @7678ms o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @7678ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 mime types IncludeExclude@27a2a089{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@54657dd2,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@706eab5d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 added {o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
STARTED @7681ms org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
starting org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7682ms org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@72725ee1 for org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece
Started o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @7682ms o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @7682ms org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece mime types IncludeExclude@3f9270ed{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3a230001,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ac6c4f2}
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece added {o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34fe326d=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
STARTED @7686ms org.spark_project.jetty.servlet.ServletHandler@45d64d27
starting org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7686ms org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2aa6311a for org.apache.spark.ui.JettyUtils$$anon$3-34fe326d
Started o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @7686ms o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @7686ms org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb mime types IncludeExclude@249e0271{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4893b344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@53a665ad}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb added {o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
STARTED @7690ms org.spark_project.jetty.servlet.ServletHandler@4d6ee47
starting org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7690ms org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2c0b4c83 for org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3
Started o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @7690ms o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @7690ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 mime types IncludeExclude@2d0ecb24{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4d654825,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3bfc6a5e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 added {o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1fba386c=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
STARTED @7694ms org.spark_project.jetty.servlet.ServletHandler@8b91134
starting org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @7694ms org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51b35e4e for org.apache.spark.ui.JettyUtils$$anon$3-1fba386c
Started o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @7695ms o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @7695ms org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 mime types IncludeExclude@6d7cada5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@350a94ce,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7e00ed0f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 added {o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-1a891add from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-1a891add=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
STARTED @7699ms org.spark_project.jetty.servlet.ServletHandler@3874b815
starting org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @7699ms org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@b0fc838 for org.spark_project.jetty.servlet.DefaultServlet-1a891add
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @7709ms o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @7709ms org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff mime types IncludeExclude@57c47a9e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@642505c7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4339e0de}
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff added {o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
STARTED @7713ms org.spark_project.jetty.servlet.ServletHandler@387bf2d9
starting org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @7713ms org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@153cd6bb for org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72
Started o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @7713ms o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @7713ms org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 mime types IncludeExclude@2d9f64c9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21ac5eb4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@52d6cd34}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 added {o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5533dc72
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
STARTED @7718ms org.spark_project.jetty.servlet.ServletHandler@5533dc72
starting org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @7719ms org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @7719ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @7719ms o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @7719ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 mime types IncludeExclude@1abfe081{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2a685eba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c2e3264}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 added {o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-6dd82486=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
STARTED @7723ms org.spark_project.jetty.servlet.ServletHandler@6ea04618
starting org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @7723ms org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@107f4980 for org.apache.spark.ui.JettyUtils$$anon$4-6dd82486
Started o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @7723ms o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @7723ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 mime types IncludeExclude@1d540566{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6014a9ba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@acdcf71}
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 added {o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-2d23faef=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
STARTED @7727ms org.spark_project.jetty.servlet.ServletHandler@7026b7ee
starting org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @7728ms org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@77d680e6 for org.apache.spark.ui.JettyUtils$$anon$4-2d23faef
Started o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @7728ms o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @7728ms org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 36918
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36918.
Server created on quickstart.cloudera:36918
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 36918, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:36918 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 36918, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 36918, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 36918, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7b306b9f
o.s.j.s.ServletContextHandler@142213d5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@934b52f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
STARTED @8440ms org.spark_project.jetty.servlet.ServletHandler@934b52f
starting org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8440ms org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ff23ae7 for org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4
Started o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
STARTED @8440ms o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/').
Warehouse path is 'file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@737d100a
o.s.j.s.ServletContextHandler@12e5da86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6535117e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6fa13e6
o.s.j.s.ServletContextHandler@3af7d855{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@77049094,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
STARTED @8651ms org.spark_project.jetty.servlet.ServletHandler@6535117e
starting org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8651ms org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@59bbe88a for org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f
Started o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
STARTED @8651ms o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
STARTED @8653ms org.spark_project.jetty.servlet.ServletHandler@77049094
starting org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8654ms org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5d8ab698 for org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe
Started o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
STARTED @8654ms o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446626a7
o.s.j.s.ServletContextHandler@429f7919{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4a2929a4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-cda6019,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@797c3c3b
o.s.j.s.ServletContextHandler@4012d5bc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4375b013,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-cda6019 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-cda6019=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
STARTED @8656ms org.spark_project.jetty.servlet.ServletHandler@4a2929a4
starting org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8657ms org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4f5b08d for org.apache.spark.ui.JettyUtils$$anon$3-cda6019
Started o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @8657ms o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
STARTED @8659ms org.spark_project.jetty.servlet.ServletHandler@4375b013
starting org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @8659ms org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@529c2a9a for org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc
Started o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @8659ms o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3c98781a
o.s.j.s.ServletContextHandler@3f736a16{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4601203a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-53abfc07,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-53abfc07 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-53abfc07=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
STARTED @8663ms org.spark_project.jetty.servlet.ServletHandler@4601203a
starting org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @8663ms org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@2c8c16c0 for org.spark_project.jetty.servlet.DefaultServlet-53abfc07
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
STARTED @8664ms o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-f3548d51-c52f-4943-8075-8b27e4e80dbc-1949323540-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-1, groupId=spark-kafka-source-f3548d51-c52f-4943-8075-8b27e4e80dbc-1949323540-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599165670640
[Consumer clientId=consumer-1, groupId=spark-kafka-source-f3548d51-c52f-4943-8075-8b27e4e80dbc-1949323540-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-1, groupId=spark-kafka-source-f3548d51-c52f-4943-8075-8b27e4e80dbc-1949323540-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-f3548d51-c52f-4943-8075-8b27e4e80dbc-1949323540-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Parsing command: CAST(value AS STRING)
Resolving 'value to value#8

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast('value as string), None)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Cleanup ===
 Project [cast(value#8 as string) AS value#21]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#24: java.lang.String   DeserializeToObject cast(value#21 as string).toString, obj#24: java.lang.String
 +- LocalRelation <empty>, [value#21]                                                                                                                                      +- LocalRelation <empty>, [value#21]
          
Expected a closure; got org.example.spark.POSmetricProcessing.hbaseUtils.invoiceWriter
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Starting [id = ab6740d1-e3e1-43c1-a3c9-f6f902c9831d, runId = e1748cdd-c949-4f88-a777-81a25baa86c2]. Use file:///tmp/temporary-b2bc303b-fb30-4c4b-a735-130983044ef7 to store the query checkpoint.
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-b2c2419d-a3cc-4488-a13f-5cdc9b82b16e--1803367484-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

Invoking stop() from shutdown hook
[Consumer clientId=consumer-2, groupId=spark-kafka-source-b2c2419d-a3cc-4488-a13f-5cdc9b82b16e--1803367484-driver-0] Initializing the Kafka consumer
stopping org.spark_project.jetty.server.Server@3effd4f3
doStop org.spark_project.jetty.server.Server@3effd4f3
ran SparkUI-28-acceptor-0@6aba5d30-ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Graceful shutdown org.spark_project.jetty.server.Server@3effd4f3 by 
stopping Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@7985dcc6 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@7985dcc6
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@78fccb9d on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@78fccb9d
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@689b78aa produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@689b78aa produce exit
ran org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
Stopped org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STOPPED HttpConnectionFactory@5a8cbffe[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Stopped Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@3effd4f3
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599165673020
[Consumer clientId=consumer-2, groupId=spark-kafka-source-b2c2419d-a3cc-4488-a13f-5cdc9b82b16e--1803367484-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-2, groupId=spark-kafka-source-b2c2419d-a3cc-4488-a13f-5cdc9b82b16e--1803367484-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@3effd4f3
Stopped Spark web UI at http://quickstart.cloudera:4040
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-b2c2419d-a3cc-4488-a13f-5cdc9b82b16e--1803367484-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
MapOutputTrackerMasterEndpoint stopped!
Query [id = ab6740d1-e3e1-43c1-a3c9-f6f902c9831d, runId = e1748cdd-c949-4f88-a777-81a25baa86c2] terminated with error
java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:99)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:88)
	at org.apache.spark.sql.SparkSession.cloneSession(SparkSession.scala:252)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:268)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:189)
Removed sensor with name connections-closed:
Removed sensor with name connections-created:
Removed sensor with name successful-authentication:
Removed sensor with name successful-reauthentication:
Removed sensor with name successful-authentication-no-reauth:
Removed sensor with name failed-authentication:
Removed sensor with name failed-reauthentication:
Removed sensor with name reauthentication-latency:
Removed sensor with name bytes-sent-received:
Removed sensor with name bytes-sent:
Removed sensor with name bytes-received:
Removed sensor with name select-time:
Removed sensor with name io-time:
[Consumer clientId=consumer-2, groupId=spark-kafka-source-b2c2419d-a3cc-4488-a13f-5cdc9b82b16e--1803367484-driver-0] Kafka consumer has been closed
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory /tmp/temporary-b2bc303b-fb30-4c4b-a735-130983044ef7
Deleting directory /tmp/temporaryReader-3260b071-f84f-4341-b6a0-00b376322cec
Deleting directory /tmp/spark-dcdb908c-3312-4bd5-af77-28820fd747e3
2020-09-05 04:56:01.467 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 04:56:01.467 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 04:56:01.467 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 04:56:01.467 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 04:56:01.467 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: 6cd6470a-7a2a-4f27-b7f3-1f3651681244
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 16235 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 33383
Successfully started service 'sparkDriver' on port 33383.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-be84d10b-2e11-4052-8dd4-c1a2974641df
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @28149ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2875b016
o.s.j.s.ServletContextHandler@23940f86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@66153688,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@87b5b49
o.s.j.s.ServletContextHandler@4a7a965d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@507b79f7,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@226eba67
o.s.j.s.ServletContextHandler@1cb7936c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@35342d2f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-128c502c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@45667d98
o.s.j.s.ServletContextHandler@65eabaab{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7123be6c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1de9d54,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@70331432
o.s.j.s.ServletContextHandler@3bbf9027{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c2064a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-70e13fa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6ff415ad
o.s.j.s.ServletContextHandler@280d9edc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@28fd3dc1,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5432c277
o.s.j.s.ServletContextHandler@15e0fe05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1128620c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6bf13698,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@299270eb
o.s.j.s.ServletContextHandler@3b90a30a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@69fa8e76,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-bdd2027,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@f446158
o.s.j.s.ServletContextHandler@32f0c7f8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@504e1599,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5d1b9c3d
o.s.j.s.ServletContextHandler@69e05f61{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@49a26d19,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-730e5763,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2babf189
o.s.j.s.ServletContextHandler@479f2dc2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@dab48d3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7159a5cd
o.s.j.s.ServletContextHandler@4f966719{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@18ac53e8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c3177d5
o.s.j.s.ServletContextHandler@76f856a8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7c853486,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-174e1b69,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1046498a
o.s.j.s.ServletContextHandler@243f003c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@71cb3139,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1639f93a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@19b047fe
o.s.j.s.ServletContextHandler@22590e3e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53dad875,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f780a86,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446c3920
o.s.j.s.ServletContextHandler@2eaef76d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2b329bbd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34819867,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@72d0f2b4
o.s.j.s.ServletContextHandler@6d2dc9d2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1da4b6b3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e1f584d
o.s.j.s.ServletContextHandler@7dff6d05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45d64d27,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34fe326d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36361ddb
o.s.j.s.ServletContextHandler@41fed14f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d6ee47,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c6da8bb
o.s.j.s.ServletContextHandler@3bae64d0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@8b91134,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1fba386c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36b310aa
o.s.j.s.ServletContextHandler@76c387f9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3874b815,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-1a891add,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@d74bac4
o.s.j.s.ServletContextHandler@5ff90645{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@387bf2d9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c768ada
o.s.j.s.ServletContextHandler@c1fca2a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5533dc72,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-27ace0b1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@58ec7116
o.s.j.s.ServletContextHandler@63bde6c2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ea04618,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-6dd82486,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36fcf6c0
o.s.j.s.ServletContextHandler@1aac188d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7026b7ee,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-2d23faef,POJO}
org.spark_project.jetty.server.Server@3effd4f3 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ErrorHandler@514cd540,AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[],MANAGED}
starting org.spark_project.jetty.server.Server@3effd4f3
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@3effd4f3
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @29463ms SparkUI{STARTED,8<=8<=200,i=6,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STARTED @29464ms org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
STARTED @29464ms org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
Started @29464ms
STARTED @29464ms org.spark_project.jetty.server.Server@3effd4f3
HttpConnectionFactory@5a8cbffe[HTTP/1.1] added {HttpConfiguration@96a75da{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@3effd4f3,UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85,AUTO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@1f44ddab,POJO}
ServerConnector@3d7b1f1c{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@5a8cbffe[HTTP/1.1],AUTO}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@5a8cbffe[HTTP/1.1]
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151,MANAGED}
starting ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STARTED @29588ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
starting HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STARTED @29588ms HttpConnectionFactory@5a8cbffe[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151 added {org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @29600ms org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @29600ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
run org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4d8cb0d5 execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4d8cb0d5 produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4d8cb0d5 producing
Selector loop waiting on select
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@6aba5d30,POJO}
queue acceptor-0@6aba5d30
run acceptor-0@6aba5d30
Started ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STARTED @29612ms ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@3effd4f3 added {Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 mime types IncludeExclude@2eb917d0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c6b2dd9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@73437222}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 added {o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
STARTED @29722ms org.spark_project.jetty.servlet.ServletHandler@66153688
starting org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29726ms org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7c2b58c0 for org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e
Started o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @29730ms o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @29731ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 mime types IncludeExclude@7bca6fac{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c60b0a0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a2b1eb4}
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 added {o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
STARTED @29737ms org.spark_project.jetty.servlet.ServletHandler@507b79f7
starting org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29738ms org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5833f5cd for org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c
Started o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @29739ms o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @29739ms org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb mime types IncludeExclude@23f3dbf0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31d6f3fe,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@760cf594}
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb added {o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-128c502c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-128c502c=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
STARTED @29743ms org.spark_project.jetty.servlet.ServletHandler@35342d2f
starting org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29744ms org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@aa149ed for org.apache.spark.ui.JettyUtils$$anon$3-128c502c
Started o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @29744ms o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @29744ms org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 mime types IncludeExclude@204e90f7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@20a05b32,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@165e389b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 added {o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1de9d54=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
STARTED @29758ms org.spark_project.jetty.servlet.ServletHandler@7123be6c
starting org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29759ms org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5c73f672 for org.apache.spark.ui.JettyUtils$$anon$3-1de9d54
Started o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @29760ms o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @29760ms org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 mime types IncludeExclude@2ab5afc7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4dc8c0ea,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@e4b6f47}
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 added {o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-70e13fa=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
STARTED @29771ms org.spark_project.jetty.servlet.ServletHandler@10c2064a
starting org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29772ms org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@763cf5b9 for org.apache.spark.ui.JettyUtils$$anon$3-70e13fa
Started o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @29772ms o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @29772ms org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e mime types IncludeExclude@7a34f66a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2f508f3c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3ed03652}
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e added {o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
STARTED @29780ms org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
starting org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29780ms org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4aedaf61 for org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7
Started o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @29780ms o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @29780ms org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 mime types IncludeExclude@3c35c345{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3681037,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2459319c}
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 added {o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6bf13698=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
STARTED @29787ms org.spark_project.jetty.servlet.ServletHandler@1128620c
starting org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29787ms org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ffaaaf0 for org.apache.spark.ui.JettyUtils$$anon$3-6bf13698
Started o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @29788ms o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @29788ms org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 mime types IncludeExclude@69a2b3b6{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4f3e7344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7808f638}
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 added {o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-bdd2027=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
STARTED @29809ms org.spark_project.jetty.servlet.ServletHandler@69fa8e76
starting org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29809ms org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@62d73ead for org.apache.spark.ui.JettyUtils$$anon$3-bdd2027
Started o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @29809ms o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @29809ms org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 mime types IncludeExclude@228cea97{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d0a61c8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@46731692}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 added {o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
STARTED @29828ms org.spark_project.jetty.servlet.ServletHandler@504e1599
starting org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29828ms org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@782bf610 for org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb
Started o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @29829ms o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @29829ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 mime types IncludeExclude@73fc518f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2de50ee4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@ad9e63e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 added {o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-730e5763 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-730e5763=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
STARTED @29852ms org.spark_project.jetty.servlet.ServletHandler@49a26d19
starting org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29852ms org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@47fbc56 for org.apache.spark.ui.JettyUtils$$anon$3-730e5763
Started o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @29852ms o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @29853ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f mime types IncludeExclude@10895b16{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5524b72f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2cc03cd1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f added {o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
STARTED @29866ms org.spark_project.jetty.servlet.ServletHandler@dab48d3
starting org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29866ms org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e17913b for org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c
Started o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @29867ms o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @29867ms org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 mime types IncludeExclude@64f16277{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@497aec8c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3b9632d1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 added {o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
STARTED @29881ms org.spark_project.jetty.servlet.ServletHandler@18ac53e8
starting org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29881ms org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e6f2bb5 for org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa
Started o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @29881ms o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @29885ms org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 mime types IncludeExclude@3f628ce9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@35e8316e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@26d96e5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 added {o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-174e1b69=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
STARTED @29892ms org.spark_project.jetty.servlet.ServletHandler@7c853486
starting org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29893ms org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@336880df for org.apache.spark.ui.JettyUtils$$anon$3-174e1b69
Started o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @29893ms o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @29893ms org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f mime types IncludeExclude@6cd166b8{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2650f79,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75fc1992}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f added {o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1639f93a=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
STARTED @29905ms org.spark_project.jetty.servlet.ServletHandler@71cb3139
starting org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29905ms org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5fac521d for org.apache.spark.ui.JettyUtils$$anon$3-1639f93a
Started o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @29906ms o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @29906ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 mime types IncludeExclude@129bd55d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7be7e15,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3abfe845}
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 added {o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f780a86=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
STARTED @29917ms org.spark_project.jetty.servlet.ServletHandler@53dad875
starting org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29918ms org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a0f244f for org.apache.spark.ui.JettyUtils$$anon$3-5f780a86
Started o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @29918ms o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @29918ms org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e mime types IncludeExclude@4248b963{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7f08caf,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4defd42}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e added {o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34819867 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34819867=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
STARTED @29924ms org.spark_project.jetty.servlet.ServletHandler@2b329bbd
starting org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29926ms org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2330e3e0 for org.apache.spark.ui.JettyUtils$$anon$3-34819867
Started o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @29926ms o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @29926ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 mime types IncludeExclude@27a2a089{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@54657dd2,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@706eab5d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 added {o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
STARTED @29936ms org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
starting org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29936ms org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@72725ee1 for org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece
Started o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @29937ms o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @29937ms org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece mime types IncludeExclude@3f9270ed{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3a230001,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ac6c4f2}
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece added {o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34fe326d=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
STARTED @29947ms org.spark_project.jetty.servlet.ServletHandler@45d64d27
starting org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29948ms org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2aa6311a for org.apache.spark.ui.JettyUtils$$anon$3-34fe326d
Started o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @29948ms o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @29948ms org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb mime types IncludeExclude@249e0271{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4893b344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@53a665ad}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb added {o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
STARTED @29953ms org.spark_project.jetty.servlet.ServletHandler@4d6ee47
starting org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29953ms org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2c0b4c83 for org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3
Started o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @29954ms o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @29954ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 mime types IncludeExclude@2d0ecb24{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4d654825,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3bfc6a5e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 added {o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1fba386c=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
STARTED @29958ms org.spark_project.jetty.servlet.ServletHandler@8b91134
starting org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @29958ms org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51b35e4e for org.apache.spark.ui.JettyUtils$$anon$3-1fba386c
Started o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @29958ms o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @29958ms org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 mime types IncludeExclude@6d7cada5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@350a94ce,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7e00ed0f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 added {o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-1a891add from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-1a891add=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
STARTED @29963ms org.spark_project.jetty.servlet.ServletHandler@3874b815
starting org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @29963ms org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@b0fc838 for org.spark_project.jetty.servlet.DefaultServlet-1a891add
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @29999ms o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @29999ms org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff mime types IncludeExclude@57c47a9e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@642505c7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4339e0de}
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff added {o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
STARTED @30003ms org.spark_project.jetty.servlet.ServletHandler@387bf2d9
starting org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @30004ms org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@153cd6bb for org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72
Started o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @30004ms o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @30004ms org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 mime types IncludeExclude@2d9f64c9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21ac5eb4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@52d6cd34}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 added {o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5533dc72
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
STARTED @30011ms org.spark_project.jetty.servlet.ServletHandler@5533dc72
starting org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @30011ms org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @30011ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @30012ms o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @30012ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 mime types IncludeExclude@1abfe081{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2a685eba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c2e3264}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 added {o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-6dd82486=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
STARTED @30016ms org.spark_project.jetty.servlet.ServletHandler@6ea04618
starting org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @30016ms org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@107f4980 for org.apache.spark.ui.JettyUtils$$anon$4-6dd82486
Started o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @30017ms o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @30017ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 mime types IncludeExclude@1d540566{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6014a9ba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@acdcf71}
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 added {o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-2d23faef=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
STARTED @30022ms org.spark_project.jetty.servlet.ServletHandler@7026b7ee
starting org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @30022ms org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@77d680e6 for org.apache.spark.ui.JettyUtils$$anon$4-2d23faef
Started o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @30023ms o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @30023ms org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 36004
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36004.
Server created on quickstart.cloudera:36004
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 36004, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:36004 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 36004, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 36004, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 36004, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7b306b9f
o.s.j.s.ServletContextHandler@142213d5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@934b52f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
STARTED @31999ms org.spark_project.jetty.servlet.ServletHandler@934b52f
starting org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @32001ms org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ff23ae7 for org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4
Started o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
STARTED @32002ms o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/').
Warehouse path is 'file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@737d100a
o.s.j.s.ServletContextHandler@12e5da86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6535117e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6fa13e6
o.s.j.s.ServletContextHandler@3af7d855{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@77049094,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
STARTED @34098ms org.spark_project.jetty.servlet.ServletHandler@6535117e
starting org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @34099ms org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@59bbe88a for org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f
Started o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
STARTED @34100ms o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
STARTED @34118ms org.spark_project.jetty.servlet.ServletHandler@77049094
starting org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @34119ms org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5d8ab698 for org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe
Started o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
STARTED @34120ms o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446626a7
o.s.j.s.ServletContextHandler@429f7919{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4a2929a4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-cda6019,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@797c3c3b
o.s.j.s.ServletContextHandler@4012d5bc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4375b013,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-cda6019 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-cda6019=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
STARTED @34130ms org.spark_project.jetty.servlet.ServletHandler@4a2929a4
starting org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @34131ms org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4f5b08d for org.apache.spark.ui.JettyUtils$$anon$3-cda6019
Started o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @34131ms o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
STARTED @34135ms org.spark_project.jetty.servlet.ServletHandler@4375b013
starting org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @34136ms org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@529c2a9a for org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc
Started o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @34136ms o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3c98781a
o.s.j.s.ServletContextHandler@3f736a16{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4601203a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-53abfc07,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-53abfc07 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-53abfc07=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
STARTED @34175ms org.spark_project.jetty.servlet.ServletHandler@4601203a
starting org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @34175ms org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@2c8c16c0 for org.spark_project.jetty.servlet.DefaultServlet-53abfc07
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
STARTED @34175ms o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-3b5148ed-c612-40b7-87e1-5c4825aa61f0--2023221694-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-1, groupId=spark-kafka-source-3b5148ed-c612-40b7-87e1-5c4825aa61f0--2023221694-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599306997104
[Consumer clientId=consumer-1, groupId=spark-kafka-source-3b5148ed-c612-40b7-87e1-5c4825aa61f0--2023221694-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-1, groupId=spark-kafka-source-3b5148ed-c612-40b7-87e1-5c4825aa61f0--2023221694-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-3b5148ed-c612-40b7-87e1-5c4825aa61f0--2023221694-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Parsing command: CAST(value AS STRING)
Resolving 'value to value#8

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast('value as string), None)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Cleanup ===
 Project [cast(value#8 as string) AS value#21]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#24: java.lang.String   DeserializeToObject cast(value#21 as string).toString, obj#24: java.lang.String
 +- LocalRelation <empty>, [value#21]                                                                                                                                      +- LocalRelation <empty>, [value#21]
          

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast(value#21 as string), None)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Project [cast(value#21 as string) AS value#26]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 +- AnalysisBarrier
       +- Project [cast(value#8 as string) AS value#21]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   +- Project [cast(value#8 as string) AS value#21]
          +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]            +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Cleanup ===
 Project [cast(value#21 as string) AS value#26]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Project [cast(value#21 as string) AS value#26]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 +- AnalysisBarrier
       +- Project [cast(value#8 as string) AS value#21]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   +- Project [cast(value#8 as string) AS value#21]
          +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]            +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, StructField(value,StringType,true))), obj#28: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(value#26.toString, StructField(value,StringType,true)), obj#28: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [value#26]                                                                                                                                               +- LocalRelation <empty>, [value#26]
          
Invoking stop() from shutdown hook
stopping org.spark_project.jetty.server.Server@3effd4f3
doStop org.spark_project.jetty.server.Server@3effd4f3
ran SparkUI-31-acceptor-0@6aba5d30-ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Graceful shutdown org.spark_project.jetty.server.Server@3effd4f3 by 
stopping Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@768f92 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@768f92
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@255cf951 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@255cf951
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4d8cb0d5 produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@4d8cb0d5 produce exit
Stopped org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
ran org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STOPPED HttpConnectionFactory@5a8cbffe[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
Stopped Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@3effd4f3
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@3effd4f3
Stopped Spark web UI at http://quickstart.cloudera:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory /tmp/spark-de9c6d7d-b5f4-4ccd-bd2c-9f293dc7d380
Deleting directory /tmp/temporaryReader-23697035-74d6-4411-b8b0-e0f97949bd5d
2020-09-05 04:58:22.819 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 04:58:22.819 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 04:58:22.819 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 04:58:22.819 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 04:58:22.819 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: 7ee405e3-6986-461e-8101-29a96b4d04a5
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 16441 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 42180
Successfully started service 'sparkDriver' on port 42180.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-1b66c128-6ab3-4519-adb5-031df6f2fe3d
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @12473ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@778db7c5
o.s.j.s.ServletContextHandler@552ed807{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3971f0fe,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3971f0fe added {org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3971f0fe added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@23f72d88
o.s.j.s.ServletContextHandler@4bafe935{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@87b5b49,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@87b5b49 added {org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@87b5b49 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@99407c2
o.s.j.s.ServletContextHandler@6c796cc1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@226eba67,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@226eba67 added {org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@226eba67 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@35342d2f
o.s.j.s.ServletContextHandler@128c502c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45667d98,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45667d98 added {org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45667d98 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-65eabaab,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6a282fdd
o.s.j.s.ServletContextHandler@743c6ce4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@70331432,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@70331432 added {org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@70331432 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@10c2064a
o.s.j.s.ServletContextHandler@70e13fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ff415ad,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ff415ad added {org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ff415ad added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-280d9edc,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5f9b6ae7
o.s.j.s.ServletContextHandler@108d55c4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5432c277,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5432c277 added {org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5432c277 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1128620c
o.s.j.s.ServletContextHandler@6bf13698{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@299270eb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@299270eb added {org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@299270eb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@bdd2027
o.s.j.s.ServletContextHandler@31f20c9f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@f446158,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@f446158 added {org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@f446158 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@504e1599
o.s.j.s.ServletContextHandler@71f96dfb{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d added {org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-69e05f61,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@42210be1
o.s.j.s.ServletContextHandler@1eb2d371{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2babf189,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2babf189 added {org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2babf189 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@dab48d3
o.s.j.s.ServletContextHandler@58a2b4c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7159a5cd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7159a5cd added {org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7159a5cd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4f966719,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4ca8dbfa
o.s.j.s.ServletContextHandler@7063686f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@c3177d5,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@c3177d5 added {org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@c3177d5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-76f856a8,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7c853486
o.s.j.s.ServletContextHandler@174e1b69{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1046498a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1046498a added {org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1046498a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-243f003c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@68f32020
o.s.j.s.ServletContextHandler@409986fe{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@19b047fe,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@19b047fe added {org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@19b047fe added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-22590e3e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@53dad875
o.s.j.s.ServletContextHandler@5f780a86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@446c3920,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@446c3920 added {org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@446c3920 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4f67e3df
o.s.j.s.ServletContextHandler@56681eaf{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@72d0f2b4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@72d0f2b4 added {org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@72d0f2b4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1da4b6b3
o.s.j.s.ServletContextHandler@b2f4ece{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7e1f584d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7e1f584d added {org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7e1f584d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@34fe326d
o.s.j.s.ServletContextHandler@30a7c98f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@36361ddb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@36361ddb added {org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@36361ddb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-41fed14f,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4d6ee47
o.s.j.s.ServletContextHandler@a33b4e3{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@c6da8bb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@c6da8bb added {org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@c6da8bb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1fba386c
o.s.j.s.ServletContextHandler@7e736350{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@36b310aa,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@36b310aa added {org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@36b310aa added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-7fb33394,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5176d279
o.s.j.s.ServletContextHandler@373f7450{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@d74bac4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@d74bac4 added {org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@d74bac4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-5ff90645,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5c20aab9
o.s.j.s.ServletContextHandler@4b7c4456{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2c768ada,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2c768ada added {org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2c768ada added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-6869a3b3,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@cb03411
o.s.j.s.ServletContextHandler@4c59e45e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@58ec7116,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@58ec7116 added {org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@58ec7116 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@56078cea
o.s.j.s.ServletContextHandler@5a00eb1e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@36fcf6c0,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@36fcf6c0 added {org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@36fcf6c0 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-1aac188d,POJO}
org.spark_project.jetty.server.Server@4bbb49b0 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@4bbb49b0 added {org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5,AUTO}
org.spark_project.jetty.server.Server@4bbb49b0 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[],MANAGED}
starting org.spark_project.jetty.server.Server@4bbb49b0
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@4bbb49b0
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @12866ms SparkUI{STARTED,8<=8<=200,i=7,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
starting org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
STARTED @12867ms org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[]
STARTED @12868ms org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[]
Started @12868ms
STARTED @12868ms org.spark_project.jetty.server.Server@4bbb49b0
HttpConnectionFactory@7c129ef6[HTTP/1.1] added {HttpConfiguration@42d73c61{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@77e7246b{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@4bbb49b0,UNMANAGED}
ServerConnector@77e7246b{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@77e7246b{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260,AUTO}
ServerConnector@77e7246b{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@3d7b1f1c,POJO}
ServerConnector@77e7246b{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@7c129ef6[HTTP/1.1],AUTO}
ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@7c129ef6[HTTP/1.1]
ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a,MANAGED}
starting ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260
STARTED @12958ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260
starting HttpConnectionFactory@7c129ef6[HTTP/1.1]
STARTED @12958ms HttpConnectionFactory@7c129ef6[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a added {org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
STARTED @12969ms org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
STARTED @12969ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a
run org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3cc9cc30 execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3cc9cc30 produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3cc9cc30 producing
Selector loop waiting on select
ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@211febf3,POJO}
queue acceptor-0@211febf3
run acceptor-0@211febf3
Started ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STARTED @12977ms ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@4bbb49b0 added {Spark@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791 mime types IncludeExclude@1c5c616f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1c6c6f24,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2eb917d0}
org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791 added {o.s.j.s.ServletContextHandler@552ed807{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791
starting o.s.j.s.ServletContextHandler@552ed807{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@552ed807{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3971f0fe
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c=org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3971f0fe
STARTED @13073ms org.spark_project.jetty.servlet.ServletHandler@3971f0fe
starting org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13078ms org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@23592946 for org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c
Started o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}
STARTED @13082ms o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}
STARTED @13082ms org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791
org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38 mime types IncludeExclude@7c2b58c0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@11b377c5,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7bca6fac}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38 added {o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38
starting o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@87b5b49
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d=org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@87b5b49
STARTED @13099ms org.spark_project.jetty.servlet.ServletHandler@87b5b49
starting org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13100ms org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a2b1eb4 for org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d
Started o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}
STARTED @13100ms o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}
STARTED @13100ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38
org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b mime types IncludeExclude@5833f5cd{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@10fbbdb,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@23f3dbf0}
org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b added {o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b
starting o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@226eba67
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c=org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@226eba67
STARTED @13103ms org.spark_project.jetty.servlet.ServletHandler@226eba67
starting org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13104ms org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@31d6f3fe for org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c
Started o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}
STARTED @13104ms o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}
STARTED @13105ms org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b
org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed mime types IncludeExclude@37303f12{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31ff6309,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@204e90f7}
org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed added {o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed
starting o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45667d98
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-65eabaab from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-65eabaab=org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45667d98
STARTED @13112ms org.spark_project.jetty.servlet.ServletHandler@45667d98
starting org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13112ms org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@20a05b32 for org.apache.spark.ui.JettyUtils$$anon$3-65eabaab
Started o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @13113ms o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @13113ms org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed
org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b mime types IncludeExclude@5c73f672{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@8ee0c23,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2ab5afc7}
org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b added {o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b
starting o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@70331432
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027=org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@70331432
STARTED @13119ms org.spark_project.jetty.servlet.ServletHandler@70331432
starting org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13119ms org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4dc8c0ea for org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027
Started o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}
STARTED @13120ms o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}
STARTED @13120ms org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b
org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47 mime types IncludeExclude@763cf5b9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@71f0b72e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a34f66a}
org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47 added {o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47
starting o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ff415ad
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-280d9edc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-280d9edc=org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ff415ad
STARTED @13127ms org.spark_project.jetty.servlet.ServletHandler@6ff415ad
starting org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13128ms org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2f508f3c for org.apache.spark.ui.JettyUtils$$anon$3-280d9edc
Started o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}
STARTED @13129ms o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}
STARTED @13129ms org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47
org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652 mime types IncludeExclude@4aedaf61{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@173797f0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3c35c345}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652 added {o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652
starting o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5432c277
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05=org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5432c277
STARTED @13134ms org.spark_project.jetty.servlet.ServletHandler@5432c277
starting org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13134ms org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3681037 for org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05
Started o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}
STARTED @13134ms o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}
STARTED @13134ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652
org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1 mime types IncludeExclude@5eed2d86{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@33d53216,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@69a2b3b6}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1 added {o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1
starting o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@299270eb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a=org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@299270eb
STARTED @13141ms org.spark_project.jetty.servlet.ServletHandler@299270eb
starting org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13141ms org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4f3e7344 for org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a
Started o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @13141ms o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @13141ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1
org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638 mime types IncludeExclude@62d73ead{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1e141e42,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@228cea97}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638 added {o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638
starting o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@f446158
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8=org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@f446158
STARTED @13178ms org.spark_project.jetty.servlet.ServletHandler@f446158
starting org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13178ms org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1d0a61c8 for org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8
Started o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}
STARTED @13178ms o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}
STARTED @13178ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638
org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692 mime types IncludeExclude@782bf610{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3db663d0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@73fc518f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692 added {o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692
starting o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-69e05f61 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-69e05f61=org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d
STARTED @13184ms org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d
starting org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13185ms org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2de50ee4 for org.apache.spark.ui.JettyUtils$$anon$3-69e05f61
Started o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @13185ms o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @13185ms org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692
org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e mime types IncludeExclude@47fbc56{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@151ef57f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@10895b16}
org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e added {o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e
starting o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2babf189
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2=org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2babf189
STARTED @13191ms org.spark_project.jetty.servlet.ServletHandler@2babf189
starting org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13191ms org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5524b72f for org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2
Started o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}
STARTED @13191ms o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}
STARTED @13191ms org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e
org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1 mime types IncludeExclude@4e17913b{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@149c3204,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@64f16277}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1 added {o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1
starting o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7159a5cd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4f966719 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4f966719=org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7159a5cd
STARTED @13201ms org.spark_project.jetty.servlet.ServletHandler@7159a5cd
starting org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13201ms org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@497aec8c for org.apache.spark.ui.JettyUtils$$anon$3-4f966719
Started o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}
STARTED @13202ms o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}
STARTED @13202ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1
org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1 mime types IncludeExclude@4e6f2bb5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21e20ad5,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3f628ce9}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1 added {o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1
starting o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@c3177d5
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-76f856a8 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-76f856a8=org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@c3177d5
STARTED @13209ms org.spark_project.jetty.servlet.ServletHandler@c3177d5
starting org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13209ms org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@35e8316e for org.apache.spark.ui.JettyUtils$$anon$3-76f856a8
Started o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @13209ms o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @13210ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1
org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5 mime types IncludeExclude@336880df{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1846579f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6cd166b8}
org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5 added {o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5
starting o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1046498a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-243f003c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-243f003c=org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1046498a
STARTED @13217ms org.spark_project.jetty.servlet.ServletHandler@1046498a
starting org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13217ms org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2650f79 for org.apache.spark.ui.JettyUtils$$anon$3-243f003c
Started o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @13218ms o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @13218ms org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5
org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992 mime types IncludeExclude@5fac521d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@38af1bf6,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@129bd55d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992 added {o.s.j.s.ServletContextHandler@409986fe{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992
starting o.s.j.s.ServletContextHandler@409986fe{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@409986fe{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@19b047fe
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-22590e3e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-22590e3e=org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@19b047fe
STARTED @13226ms org.spark_project.jetty.servlet.ServletHandler@19b047fe
starting org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13226ms org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7be7e15 for org.apache.spark.ui.JettyUtils$$anon$3-22590e3e
Started o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}
STARTED @13227ms o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}
STARTED @13227ms org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992
org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845 mime types IncludeExclude@7a0f244f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3672276e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4248b963}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845 added {o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845
starting o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@446c3920
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d=org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@446c3920
STARTED @13236ms org.spark_project.jetty.servlet.ServletHandler@446c3920
starting org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13236ms org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7f08caf for org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d
Started o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}
STARTED @13237ms o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}
STARTED @13237ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845
org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42 mime types IncludeExclude@2330e3e0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@24b4d544,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@27a2a089}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42 added {o.s.j.s.ServletContextHandler@56681eaf{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42
starting o.s.j.s.ServletContextHandler@56681eaf{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@56681eaf{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@72d0f2b4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2=org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@72d0f2b4
STARTED @13243ms org.spark_project.jetty.servlet.ServletHandler@72d0f2b4
starting org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13243ms org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@54657dd2 for org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2
Started o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}
STARTED @13244ms o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}
STARTED @13244ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42
org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d mime types IncludeExclude@72725ee1{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@40e60ece,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3f9270ed}
org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d added {o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d
starting o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7e1f584d
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05=org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7e1f584d
STARTED @13252ms org.spark_project.jetty.servlet.ServletHandler@7e1f584d
starting org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13252ms org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3a230001 for org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05
Started o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}
STARTED @13253ms o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}
STARTED @13253ms org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d
org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2 mime types IncludeExclude@2aa6311a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@61f39bb,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@249e0271}
org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2 added {o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2
starting o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@36361ddb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-41fed14f from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-41fed14f=org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@36361ddb
STARTED @13263ms org.spark_project.jetty.servlet.ServletHandler@36361ddb
starting org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13263ms org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4893b344 for org.apache.spark.ui.JettyUtils$$anon$3-41fed14f
Started o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @13264ms o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @13264ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2
org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad mime types IncludeExclude@2c0b4c83{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@78525ef9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2d0ecb24}
org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad added {o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad
starting o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@c6da8bb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0=org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@c6da8bb
STARTED @13271ms org.spark_project.jetty.servlet.ServletHandler@c6da8bb
starting org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13272ms org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4d654825 for org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0
Started o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @13272ms o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @13272ms org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad
org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e mime types IncludeExclude@51b35e4e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@abff8b7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6d7cada5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e added {o.s.j.s.ServletContextHandler@7e736350{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e
starting o.s.j.s.ServletContextHandler@7e736350{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7e736350{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@36b310aa
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-7fb33394 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-7fb33394=org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@36b310aa
STARTED @13278ms org.spark_project.jetty.servlet.ServletHandler@36b310aa
starting org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @13279ms org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@350a94ce for org.spark_project.jetty.servlet.DefaultServlet-7fb33394
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}
STARTED @13295ms o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}
STARTED @13295ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e
org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796 mime types IncludeExclude@4eed2acf{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@36fc05ff,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@57c47a9e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796 added {o.s.j.s.ServletContextHandler@373f7450{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796
starting o.s.j.s.ServletContextHandler@373f7450{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@373f7450{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@d74bac4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-5ff90645 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-5ff90645=org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@d74bac4
STARTED @13302ms org.spark_project.jetty.servlet.ServletHandler@d74bac4
starting org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @13302ms org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@642505c7 for org.apache.spark.ui.JettyUtils$$anon$4-5ff90645
Started o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}
STARTED @13302ms o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}
STARTED @13302ms org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796
org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de mime types IncludeExclude@153cd6bb{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@61d84e08,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2d9f64c9}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de added {o.s.j.s.ServletContextHandler@4b7c4456{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de
starting o.s.j.s.ServletContextHandler@4b7c4456{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4b7c4456{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2c768ada
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-6869a3b3 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-6869a3b3=org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@2c768ada
org.spark_project.jetty.servlet.ServletHandler@2c768ada added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2c768ada added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-6869a3b3 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false, org.glassfish.jersey.servlet.ServletContainer-6869a3b3=org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@2c768ada
STARTED @13311ms org.spark_project.jetty.servlet.ServletHandler@2c768ada
starting org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @13311ms org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @13311ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}
STARTED @13312ms o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}
STARTED @13312ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de
org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6 mime types IncludeExclude@6428591a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7397c6,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1abfe081}
org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6 added {o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6
starting o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@58ec7116
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2=org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@58ec7116
STARTED @13318ms org.spark_project.jetty.servlet.ServletHandler@58ec7116
starting org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @13319ms org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@2a685eba for org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2
Started o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @13319ms o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @13319ms org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6
org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264 mime types IncludeExclude@107f4980{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75a118e6,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d540566}
org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264 added {o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264
starting o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@36fcf6c0
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-1aac188d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-1aac188d=org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@36fcf6c0
STARTED @13333ms org.spark_project.jetty.servlet.ServletHandler@36fcf6c0
starting org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @13334ms org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@6014a9ba for org.apache.spark.ui.JettyUtils$$anon$4-1aac188d
Started o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @13335ms o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @13335ms org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 37199
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37199.
Server created on quickstart.cloudera:37199
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 37199, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:37199 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 37199, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 37199, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 37199, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@10b1a751
o.s.j.s.ServletContextHandler@53cf9c99{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7b306b9f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7b306b9f added {org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7b306b9f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-142213d5,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7b306b9f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-142213d5 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-142213d5=org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7b306b9f
STARTED @14572ms org.spark_project.jetty.servlet.ServletHandler@7b306b9f
starting org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @14572ms org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2938127d for org.apache.spark.ui.JettyUtils$$anon$3-142213d5
Started o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}
STARTED @14575ms o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/').
Warehouse path is 'file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5ad5be4a
o.s.j.s.ServletContextHandler@3ad85136{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@737d100a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@737d100a added {org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@737d100a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-12e5da86,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6535117e
o.s.j.s.ServletContextHandler@1d1cbd0f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6fa13e6,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6fa13e6 added {org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6fa13e6 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3af7d855,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@737d100a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-12e5da86 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-12e5da86=org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@737d100a
STARTED @15031ms org.spark_project.jetty.servlet.ServletHandler@737d100a
starting org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15032ms org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@77049094 for org.apache.spark.ui.JettyUtils$$anon$3-12e5da86
Started o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}
STARTED @15032ms o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6fa13e6
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3af7d855 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3af7d855=org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6fa13e6
STARTED @15036ms org.spark_project.jetty.servlet.ServletHandler@6fa13e6
starting org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15037ms org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@f88bfbe for org.apache.spark.ui.JettyUtils$$anon$3-3af7d855
Started o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}
STARTED @15037ms o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5d8ab698
o.s.j.s.ServletContextHandler@ed91d8d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@446626a7,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@446626a7 added {org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@446626a7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-429f7919,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4a2929a4
o.s.j.s.ServletContextHandler@cda6019{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@797c3c3b,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@797c3c3b added {org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@797c3c3b added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@446626a7
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-429f7919 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-429f7919=org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@446626a7
STARTED @15042ms org.spark_project.jetty.servlet.ServletHandler@446626a7
starting org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15042ms org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4375b013 for org.apache.spark.ui.JettyUtils$$anon$3-429f7919
Started o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @15042ms o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@797c3c3b
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc=org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@797c3c3b
STARTED @15047ms org.spark_project.jetty.servlet.ServletHandler@797c3c3b
starting org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15047ms org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1cf0cacc for org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc
Started o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @15047ms o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@26bbe604
o.s.j.s.ServletContextHandler@fe34b86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3c98781a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3c98781a added {org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3c98781a added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-3f736a16,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3c98781a
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-3f736a16 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-3f736a16=org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3c98781a
STARTED @15070ms org.spark_project.jetty.servlet.ServletHandler@3c98781a
starting org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @15071ms org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@4601203a for org.spark_project.jetty.servlet.DefaultServlet-3f736a16
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,AVAILABLE,@Spark}
STARTED @15072ms o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-72e9593d-4a52-4102-855d-ba17ea0e505d-619941395-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-1, groupId=spark-kafka-source-72e9593d-4a52-4102-855d-ba17ea0e505d-619941395-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599307111644
[Consumer clientId=consumer-1, groupId=spark-kafka-source-72e9593d-4a52-4102-855d-ba17ea0e505d-619941395-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-1, groupId=spark-kafka-source-72e9593d-4a52-4102-855d-ba17ea0e505d-619941395-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-72e9593d-4a52-4102-855d-ba17ea0e505d-619941395-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Parsing command: CAST(value AS STRING)
Resolving 'value to value#8

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast('value as string), None)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@38811103, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c71c889,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@38811103, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c71c889,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Cleanup ===
 Project [cast(value#8 as string) AS value#21]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@38811103, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c71c889,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@38811103, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c71c889,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#24: java.lang.String   DeserializeToObject cast(value#21 as string).toString, obj#24: java.lang.String
 +- LocalRelation <empty>, [value#21]                                                                                                                                      +- LocalRelation <empty>, [value#21]
          
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Starting [id = 4bfe7f99-274d-40e7-8487-cd7ef0ba1cec, runId = 2c56e52c-8ef5-4b97-b5fe-ce39f0fa5e7c]. Use file:///tmp/temporary-44f19f44-2632-40f8-9375-8ae78f8dd2fa to store the query checkpoint.
Invoking stop() from shutdown hook
stopping org.spark_project.jetty.server.Server@4bbb49b0
doStop org.spark_project.jetty.server.Server@4bbb49b0
ran SparkUI-29-acceptor-0@211febf3-ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Graceful shutdown org.spark_project.jetty.server.Server@4bbb49b0 by 
stopping Spark@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a
stopping org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@12f94957 on org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@12f94957
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@3133ee21 on org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@3133ee21
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3cc9cc30 produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@3cc9cc30 produce exit
ran org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1
Stopped org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a
stopping HttpConnectionFactory@7c129ef6[HTTP/1.1]
STOPPED HttpConnectionFactory@7c129ef6[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260
Stopped Spark@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@4bbb49b0
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
stopping org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@4bbb49b0
Stopped Spark web UI at http://quickstart.cloudera:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-845e73ba-8f88-4244-91ea-241c4f1d2786-358794488-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-2, groupId=spark-kafka-source-845e73ba-8f88-4244-91ea-241c4f1d2786-358794488-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
BlockManagerMaster stopped
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599307117497
[Consumer clientId=consumer-2, groupId=spark-kafka-source-845e73ba-8f88-4244-91ea-241c4f1d2786-358794488-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-2, groupId=spark-kafka-source-845e73ba-8f88-4244-91ea-241c4f1d2786-358794488-driver-0] Subscribed to topic(s): invoice
OutputCommitCoordinator stopped!
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-845e73ba-8f88-4244-91ea-241c4f1d2786-358794488-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Query [id = 4bfe7f99-274d-40e7-8487-cd7ef0ba1cec, runId = 2c56e52c-8ef5-4b97-b5fe-ce39f0fa5e7c] terminated with error
java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)

The currently active SparkContext was created at:

org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:99)
	at org.apache.spark.sql.SparkSession.<init>(SparkSession.scala:88)
	at org.apache.spark.sql.SparkSession.cloneSession(SparkSession.scala:252)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:268)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:189)
Successfully stopped SparkContext
Shutdown hook called
Removed sensor with name connections-closed:
Deleting directory /tmp/spark-afd82324-59e9-4b3f-b69e-751d41ac439e
Removed sensor with name connections-created:
Deleting directory /tmp/temporary-44f19f44-2632-40f8-9375-8ae78f8dd2fa
Removed sensor with name successful-authentication:
Removed sensor with name successful-reauthentication:
Removed sensor with name successful-authentication-no-reauth:
Deleting directory /tmp/temporaryReader-f286cc73-903b-426d-9d61-fd61259a779b
Removed sensor with name failed-authentication:
Removed sensor with name failed-reauthentication:
2020-09-05 05:00:26.637 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 05:00:26.637 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 05:00:26.637 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 05:00:26.637 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 05:00:26.637 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: 790d3e4b-cd66-452b-b5c5-c9a8a3e2003e
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 16727 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 44018
Successfully started service 'sparkDriver' on port 44018.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-7f046799-55cd-4687-9823-21aee558d8ee
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @12434ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@778db7c5
o.s.j.s.ServletContextHandler@552ed807{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3971f0fe,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3971f0fe added {org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3971f0fe added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@23f72d88
o.s.j.s.ServletContextHandler@4bafe935{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@87b5b49,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@87b5b49 added {org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@87b5b49 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@99407c2
o.s.j.s.ServletContextHandler@6c796cc1{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@226eba67,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@226eba67 added {org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@226eba67 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@35342d2f
o.s.j.s.ServletContextHandler@128c502c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45667d98,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45667d98 added {org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45667d98 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-65eabaab,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6a282fdd
o.s.j.s.ServletContextHandler@743c6ce4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@70331432,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@70331432 added {org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@70331432 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@10c2064a
o.s.j.s.ServletContextHandler@70e13fa{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ff415ad,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ff415ad added {org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ff415ad added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-280d9edc,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5f9b6ae7
o.s.j.s.ServletContextHandler@108d55c4{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5432c277,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5432c277 added {org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5432c277 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1128620c
o.s.j.s.ServletContextHandler@6bf13698{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@299270eb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@299270eb added {org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@299270eb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@bdd2027
o.s.j.s.ServletContextHandler@31f20c9f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@f446158,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@f446158 added {org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@f446158 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@504e1599
o.s.j.s.ServletContextHandler@71f96dfb{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d added {org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-69e05f61,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@42210be1
o.s.j.s.ServletContextHandler@1eb2d371{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2babf189,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2babf189 added {org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2babf189 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@dab48d3
o.s.j.s.ServletContextHandler@58a2b4c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7159a5cd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7159a5cd added {org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7159a5cd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4f966719,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4ca8dbfa
o.s.j.s.ServletContextHandler@7063686f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@c3177d5,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@c3177d5 added {org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@c3177d5 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-76f856a8,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7c853486
o.s.j.s.ServletContextHandler@174e1b69{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1046498a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1046498a added {org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1046498a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-243f003c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@68f32020
o.s.j.s.ServletContextHandler@409986fe{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@19b047fe,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@19b047fe added {org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@19b047fe added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-22590e3e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@53dad875
o.s.j.s.ServletContextHandler@5f780a86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@446c3920,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@446c3920 added {org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@446c3920 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4f67e3df
o.s.j.s.ServletContextHandler@56681eaf{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@72d0f2b4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@72d0f2b4 added {org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@72d0f2b4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1da4b6b3
o.s.j.s.ServletContextHandler@b2f4ece{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7e1f584d,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7e1f584d added {org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7e1f584d added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@34fe326d
o.s.j.s.ServletContextHandler@30a7c98f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@36361ddb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@36361ddb added {org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@36361ddb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-41fed14f,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4d6ee47
o.s.j.s.ServletContextHandler@a33b4e3{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@c6da8bb,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@c6da8bb added {org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@c6da8bb added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1fba386c
o.s.j.s.ServletContextHandler@7e736350{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@36b310aa,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@36b310aa added {org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@36b310aa added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-7fb33394,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5176d279
o.s.j.s.ServletContextHandler@373f7450{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@d74bac4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@d74bac4 added {org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@d74bac4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-5ff90645,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5c20aab9
o.s.j.s.ServletContextHandler@4b7c4456{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2c768ada,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2c768ada added {org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2c768ada added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-6869a3b3,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@cb03411
o.s.j.s.ServletContextHandler@4c59e45e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@58ec7116,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@58ec7116 added {org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@58ec7116 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@56078cea
o.s.j.s.ServletContextHandler@5a00eb1e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@36fcf6c0,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@36fcf6c0 added {org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@36fcf6c0 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-1aac188d,POJO}
org.spark_project.jetty.server.Server@4bbb49b0 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@4bbb49b0 added {org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5,AUTO}
org.spark_project.jetty.server.Server@4bbb49b0 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[],MANAGED}
starting org.spark_project.jetty.server.Server@4bbb49b0
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@4bbb49b0
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @12881ms SparkUI{STARTED,8<=8<=200,i=7,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
starting org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
STARTED @12881ms org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[]
STARTED @12882ms org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[]
Started @12882ms
STARTED @12883ms org.spark_project.jetty.server.Server@4bbb49b0
HttpConnectionFactory@7c129ef6[HTTP/1.1] added {HttpConfiguration@42d73c61{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@77e7246b{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@4bbb49b0,UNMANAGED}
ServerConnector@77e7246b{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@77e7246b{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260,AUTO}
ServerConnector@77e7246b{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@3d7b1f1c,POJO}
ServerConnector@77e7246b{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@7c129ef6[HTTP/1.1],AUTO}
ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@7c129ef6[HTTP/1.1]
ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a,MANAGED}
starting ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260
STARTED @12971ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260
starting HttpConnectionFactory@7c129ef6[HTTP/1.1]
STARTED @12972ms HttpConnectionFactory@7c129ef6[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a added {org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
STARTED @12988ms org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
STARTED @12988ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a
run org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@2d84671c execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@2d84671c produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@2d84671c producing
Selector loop waiting on select
ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@211febf3,POJO}
queue acceptor-0@211febf3
run acceptor-0@211febf3
Started ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STARTED @13015ms ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@4bbb49b0 added {Spark@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791 mime types IncludeExclude@1c5c616f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1c6c6f24,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2eb917d0}
org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791 added {o.s.j.s.ServletContextHandler@552ed807{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791
starting o.s.j.s.ServletContextHandler@552ed807{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@552ed807{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3971f0fe
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c=org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3971f0fe
STARTED @13148ms org.spark_project.jetty.servlet.ServletHandler@3971f0fe
starting org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13152ms org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c@d74a19f4==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@23592946 for org.apache.spark.ui.JettyUtils$$anon$3-3b95d13c
Started o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}
STARTED @13176ms o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}
STARTED @13177ms org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791
org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38 mime types IncludeExclude@7c2b58c0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@11b377c5,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7bca6fac}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38 added {o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38
starting o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@87b5b49
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d=org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@87b5b49
STARTED @13185ms org.spark_project.jetty.servlet.ServletHandler@87b5b49
starting org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13186ms org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d@933eb8f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a2b1eb4 for org.apache.spark.ui.JettyUtils$$anon$3-4a7a965d
Started o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}
STARTED @13187ms o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}
STARTED @13187ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38
org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b mime types IncludeExclude@5833f5cd{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@10fbbdb,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@23f3dbf0}
org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b added {o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b
starting o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@226eba67
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c=org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@226eba67
STARTED @13192ms org.spark_project.jetty.servlet.ServletHandler@226eba67
starting org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13192ms org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c@826d57da==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@31d6f3fe for org.apache.spark.ui.JettyUtils$$anon$3-1cb7936c
Started o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}
STARTED @13193ms o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}
STARTED @13193ms org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b
org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed mime types IncludeExclude@37303f12{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31ff6309,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@204e90f7}
org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed added {o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed
starting o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45667d98
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-65eabaab from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-65eabaab=org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45667d98
STARTED @13201ms org.spark_project.jetty.servlet.ServletHandler@45667d98
starting org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13201ms org.apache.spark.ui.JettyUtils$$anon$3-65eabaab@ff64ca7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@20a05b32 for org.apache.spark.ui.JettyUtils$$anon$3-65eabaab
Started o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @13202ms o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @13202ms org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed
org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b mime types IncludeExclude@5c73f672{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@8ee0c23,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2ab5afc7}
org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b added {o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b
starting o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@70331432
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027=org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@70331432
STARTED @13208ms org.spark_project.jetty.servlet.ServletHandler@70331432
starting org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13208ms org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027@1fdfbb1b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4dc8c0ea for org.apache.spark.ui.JettyUtils$$anon$3-3bbf9027
Started o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}
STARTED @13208ms o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}
STARTED @13209ms org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b
org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47 mime types IncludeExclude@763cf5b9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@71f0b72e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a34f66a}
org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47 added {o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47
starting o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ff415ad
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-280d9edc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-280d9edc=org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ff415ad
STARTED @13214ms org.spark_project.jetty.servlet.ServletHandler@6ff415ad
starting org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13214ms org.apache.spark.ui.JettyUtils$$anon$3-280d9edc@b4cb24b1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2f508f3c for org.apache.spark.ui.JettyUtils$$anon$3-280d9edc
Started o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}
STARTED @13214ms o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}
STARTED @13214ms org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47
org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652 mime types IncludeExclude@4aedaf61{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@173797f0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3c35c345}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652 added {o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652
starting o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5432c277
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05=org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5432c277
STARTED @13220ms org.spark_project.jetty.servlet.ServletHandler@5432c277
starting org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13220ms org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05@5dfc6ff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3681037 for org.apache.spark.ui.JettyUtils$$anon$3-15e0fe05
Started o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}
STARTED @13220ms o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}
STARTED @13220ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652
org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1 mime types IncludeExclude@5eed2d86{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@33d53216,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@69a2b3b6}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1 added {o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1
starting o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@299270eb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a=org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@299270eb
STARTED @13230ms org.spark_project.jetty.servlet.ServletHandler@299270eb
starting org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13230ms org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a@d7024e75==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4f3e7344 for org.apache.spark.ui.JettyUtils$$anon$3-3b90a30a
Started o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @13231ms o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @13231ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1
org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638 mime types IncludeExclude@62d73ead{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1e141e42,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@228cea97}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638 added {o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638
starting o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@f446158
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8=org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@f446158
STARTED @13236ms org.spark_project.jetty.servlet.ServletHandler@f446158
starting org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13237ms org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8@38a2445b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1d0a61c8 for org.apache.spark.ui.JettyUtils$$anon$3-32f0c7f8
Started o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}
STARTED @13237ms o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}
STARTED @13237ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638
org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692 mime types IncludeExclude@782bf610{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3db663d0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@73fc518f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692 added {o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692
starting o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-69e05f61 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-69e05f61=org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d
STARTED @13242ms org.spark_project.jetty.servlet.ServletHandler@5d1b9c3d
starting org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13243ms org.apache.spark.ui.JettyUtils$$anon$3-69e05f61@e0c852a6==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2de50ee4 for org.apache.spark.ui.JettyUtils$$anon$3-69e05f61
Started o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @13243ms o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @13243ms org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692
org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e mime types IncludeExclude@47fbc56{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@151ef57f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@10895b16}
org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e added {o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e
starting o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2babf189
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2=org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2babf189
STARTED @13248ms org.spark_project.jetty.servlet.ServletHandler@2babf189
starting org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13253ms org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2@5f1bdd1d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5524b72f for org.apache.spark.ui.JettyUtils$$anon$3-479f2dc2
Started o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}
STARTED @13253ms o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}
STARTED @13253ms org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e
org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1 mime types IncludeExclude@4e17913b{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@149c3204,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@64f16277}
org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1 added {o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1
starting o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7159a5cd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4f966719 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4f966719=org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7159a5cd
STARTED @13258ms org.spark_project.jetty.servlet.ServletHandler@7159a5cd
starting org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13259ms org.apache.spark.ui.JettyUtils$$anon$3-4f966719@12bd7864==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@497aec8c for org.apache.spark.ui.JettyUtils$$anon$3-4f966719
Started o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}
STARTED @13259ms o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}
STARTED @13259ms org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1
org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1 mime types IncludeExclude@4e6f2bb5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21e20ad5,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3f628ce9}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1 added {o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1
starting o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@c3177d5
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-76f856a8 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-76f856a8=org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@c3177d5
STARTED @13283ms org.spark_project.jetty.servlet.ServletHandler@c3177d5
starting org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13283ms org.apache.spark.ui.JettyUtils$$anon$3-76f856a8@ac1bb375==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@35e8316e for org.apache.spark.ui.JettyUtils$$anon$3-76f856a8
Started o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @13284ms o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @13284ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1
org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5 mime types IncludeExclude@336880df{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1846579f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6cd166b8}
org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5 added {o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5
starting o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1046498a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-243f003c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-243f003c=org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1046498a
STARTED @13288ms org.spark_project.jetty.servlet.ServletHandler@1046498a
starting org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13289ms org.apache.spark.ui.JettyUtils$$anon$3-243f003c@e6680c51==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2650f79 for org.apache.spark.ui.JettyUtils$$anon$3-243f003c
Started o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @13289ms o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @13289ms org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5
org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992 mime types IncludeExclude@5fac521d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@38af1bf6,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@129bd55d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992 added {o.s.j.s.ServletContextHandler@409986fe{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992
starting o.s.j.s.ServletContextHandler@409986fe{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@409986fe{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@19b047fe
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-22590e3e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-22590e3e=org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@19b047fe
STARTED @13293ms org.spark_project.jetty.servlet.ServletHandler@19b047fe
starting org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13294ms org.apache.spark.ui.JettyUtils$$anon$3-22590e3e@7d8bec57==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7be7e15 for org.apache.spark.ui.JettyUtils$$anon$3-22590e3e
Started o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}
STARTED @13294ms o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}
STARTED @13294ms org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992
org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845 mime types IncludeExclude@7a0f244f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3672276e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4248b963}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845 added {o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845
starting o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@446c3920
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d=org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@446c3920
STARTED @13302ms org.spark_project.jetty.servlet.ServletHandler@446c3920
starting org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13303ms org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d@5502df82==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7f08caf for org.apache.spark.ui.JettyUtils$$anon$3-2eaef76d
Started o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}
STARTED @13303ms o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}
STARTED @13303ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845
org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42 mime types IncludeExclude@2330e3e0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@24b4d544,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@27a2a089}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42 added {o.s.j.s.ServletContextHandler@56681eaf{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42
starting o.s.j.s.ServletContextHandler@56681eaf{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@56681eaf{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@72d0f2b4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2=org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@72d0f2b4
STARTED @13309ms org.spark_project.jetty.servlet.ServletHandler@72d0f2b4
starting org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13309ms org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2@6f5e2ad0==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@54657dd2 for org.apache.spark.ui.JettyUtils$$anon$3-6d2dc9d2
Started o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}
STARTED @13310ms o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}
STARTED @13310ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42
org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d mime types IncludeExclude@72725ee1{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@40e60ece,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3f9270ed}
org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d added {o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d
starting o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7e1f584d
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05=org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7e1f584d
STARTED @13316ms org.spark_project.jetty.servlet.ServletHandler@7e1f584d
starting org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13316ms org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05@3003ad6c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@3a230001 for org.apache.spark.ui.JettyUtils$$anon$3-7dff6d05
Started o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}
STARTED @13317ms o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}
STARTED @13317ms org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d
org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2 mime types IncludeExclude@2aa6311a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@61f39bb,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@249e0271}
org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2 added {o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2
starting o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@36361ddb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-41fed14f from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-41fed14f=org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@36361ddb
STARTED @13322ms org.spark_project.jetty.servlet.ServletHandler@36361ddb
starting org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13322ms org.apache.spark.ui.JettyUtils$$anon$3-41fed14f@6e886ba7==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4893b344 for org.apache.spark.ui.JettyUtils$$anon$3-41fed14f
Started o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @13323ms o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @13323ms org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2
org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad mime types IncludeExclude@2c0b4c83{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@78525ef9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2d0ecb24}
org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad added {o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad
starting o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@c6da8bb
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0=org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@c6da8bb
STARTED @13328ms org.spark_project.jetty.servlet.ServletHandler@c6da8bb
starting org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @13329ms org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0@1e1b82e9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4d654825 for org.apache.spark.ui.JettyUtils$$anon$3-3bae64d0
Started o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @13329ms o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @13329ms org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad
org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e mime types IncludeExclude@51b35e4e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@abff8b7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6d7cada5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e added {o.s.j.s.ServletContextHandler@7e736350{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e
starting o.s.j.s.ServletContextHandler@7e736350{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7e736350{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@36b310aa
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-7fb33394 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-7fb33394=org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@36b310aa
STARTED @13337ms org.spark_project.jetty.servlet.ServletHandler@36b310aa
starting org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @13337ms org.spark_project.jetty.servlet.DefaultServlet-7fb33394@2b8694ea==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@350a94ce for org.spark_project.jetty.servlet.DefaultServlet-7fb33394
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}
STARTED @13356ms o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}
STARTED @13356ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e
org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796 mime types IncludeExclude@4eed2acf{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@36fc05ff,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@57c47a9e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796 added {o.s.j.s.ServletContextHandler@373f7450{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796
starting o.s.j.s.ServletContextHandler@373f7450{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@373f7450{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@d74bac4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-5ff90645 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-5ff90645=org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@d74bac4
STARTED @13361ms org.spark_project.jetty.servlet.ServletHandler@d74bac4
starting org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @13361ms org.apache.spark.ui.JettyUtils$$anon$4-5ff90645@bbd9b336==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@642505c7 for org.apache.spark.ui.JettyUtils$$anon$4-5ff90645
Started o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}
STARTED @13362ms o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}
STARTED @13362ms org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796
org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de mime types IncludeExclude@153cd6bb{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@61d84e08,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2d9f64c9}
org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de added {o.s.j.s.ServletContextHandler@4b7c4456{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de
starting o.s.j.s.ServletContextHandler@4b7c4456{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4b7c4456{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2c768ada
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-6869a3b3 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-6869a3b3=org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@2c768ada
org.spark_project.jetty.servlet.ServletHandler@2c768ada added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2c768ada added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-6869a3b3 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false, org.glassfish.jersey.servlet.ServletContainer-6869a3b3=org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@2c768ada
STARTED @13369ms org.spark_project.jetty.servlet.ServletHandler@2c768ada
starting org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @13370ms org.glassfish.jersey.servlet.ServletContainer-6869a3b3@b44cca96==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @13370ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-715d6168@64fa2fea==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}
STARTED @13370ms o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}
STARTED @13370ms org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de
org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6 mime types IncludeExclude@6428591a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7397c6,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1abfe081}
org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6 added {o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6
starting o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@58ec7116
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2=org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@58ec7116
STARTED @13374ms org.spark_project.jetty.servlet.ServletHandler@58ec7116
starting org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @13375ms org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2@957fbfaa==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@2a685eba for org.apache.spark.ui.JettyUtils$$anon$4-63bde6c2
Started o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @13375ms o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @13375ms org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6
org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264 mime types IncludeExclude@107f4980{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75a118e6,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d540566}
org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264 added {o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264
starting o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@36fcf6c0
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-1aac188d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-1aac188d=org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@36fcf6c0
STARTED @13397ms org.spark_project.jetty.servlet.ServletHandler@36fcf6c0
starting org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @13397ms org.apache.spark.ui.JettyUtils$$anon$4-1aac188d@d9df410==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@6014a9ba for org.apache.spark.ui.JettyUtils$$anon$4-1aac188d
Started o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @13397ms o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @13397ms org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 38057
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38057.
Server created on quickstart.cloudera:38057
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 38057, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:38057 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 38057, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 38057, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 38057, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@10b1a751
o.s.j.s.ServletContextHandler@53cf9c99{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7b306b9f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7b306b9f added {org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7b306b9f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-142213d5,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7b306b9f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-142213d5 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-142213d5=org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7b306b9f
STARTED @14630ms org.spark_project.jetty.servlet.ServletHandler@7b306b9f
starting org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @14631ms org.apache.spark.ui.JettyUtils$$anon$3-142213d5@79f5c602==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2938127d for org.apache.spark.ui.JettyUtils$$anon$3-142213d5
Started o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}
STARTED @14631ms o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/').
Warehouse path is 'file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5ad5be4a
o.s.j.s.ServletContextHandler@3ad85136{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@737d100a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@737d100a added {org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@737d100a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-12e5da86,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6535117e
o.s.j.s.ServletContextHandler@1d1cbd0f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6fa13e6,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6fa13e6 added {org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6fa13e6 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3af7d855,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@737d100a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-12e5da86 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-12e5da86=org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@737d100a
STARTED @15091ms org.spark_project.jetty.servlet.ServletHandler@737d100a
starting org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15091ms org.apache.spark.ui.JettyUtils$$anon$3-12e5da86@677293f8==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@77049094 for org.apache.spark.ui.JettyUtils$$anon$3-12e5da86
Started o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}
STARTED @15092ms o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6fa13e6
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3af7d855 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3af7d855=org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6fa13e6
STARTED @15102ms org.spark_project.jetty.servlet.ServletHandler@6fa13e6
starting org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15102ms org.apache.spark.ui.JettyUtils$$anon$3-3af7d855@ef4a3bff==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@f88bfbe for org.apache.spark.ui.JettyUtils$$anon$3-3af7d855
Started o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}
STARTED @15103ms o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5d8ab698
o.s.j.s.ServletContextHandler@ed91d8d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@446626a7,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@446626a7 added {org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@446626a7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-429f7919,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4a2929a4
o.s.j.s.ServletContextHandler@cda6019{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@797c3c3b,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@797c3c3b added {org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@797c3c3b added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@446626a7
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-429f7919 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-429f7919=org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@446626a7
STARTED @15107ms org.spark_project.jetty.servlet.ServletHandler@446626a7
starting org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15107ms org.apache.spark.ui.JettyUtils$$anon$3-429f7919@569e5341==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4375b013 for org.apache.spark.ui.JettyUtils$$anon$3-429f7919
Started o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @15107ms o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@797c3c3b
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc=org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@797c3c3b
STARTED @15111ms org.spark_project.jetty.servlet.ServletHandler@797c3c3b
starting org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15111ms org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc@dc62bd5b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@1cf0cacc for org.apache.spark.ui.JettyUtils$$anon$3-4012d5bc
Started o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @15111ms o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@26bbe604
o.s.j.s.ServletContextHandler@fe34b86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3c98781a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@3c98781a added {org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3c98781a added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-3f736a16,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796,[o.s.j.s.ServletContextHandler@373f7450{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1,[o.s.j.s.ServletContextHandler@7063686f{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e,[o.s.j.s.ServletContextHandler@1eb2d371{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5,[o.s.j.s.ServletContextHandler@174e1b69{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de,[o.s.j.s.ServletContextHandler@4b7c4456{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692,[o.s.j.s.ServletContextHandler@71f96dfb{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638,[o.s.j.s.ServletContextHandler@31f20c9f{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38,[o.s.j.s.ServletContextHandler@4bafe935{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e,[o.s.j.s.ServletContextHandler@7e736350{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d,[o.s.j.s.ServletContextHandler@b2f4ece{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1,[o.s.j.s.ServletContextHandler@6bf13698{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad,[o.s.j.s.ServletContextHandler@a33b4e3{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845,[o.s.j.s.ServletContextHandler@5f780a86{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed,[o.s.j.s.ServletContextHandler@128c502c{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791,[o.s.j.s.ServletContextHandler@552ed807{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47,[o.s.j.s.ServletContextHandler@70e13fa{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652,[o.s.j.s.ServletContextHandler@108d55c4{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1,[o.s.j.s.ServletContextHandler@58a2b4c{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264,[o.s.j.s.ServletContextHandler@5a00eb1e{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b,[o.s.j.s.ServletContextHandler@6c796cc1{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992,[o.s.j.s.ServletContextHandler@409986fe{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b,[o.s.j.s.ServletContextHandler@743c6ce4{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42,[o.s.j.s.ServletContextHandler@56681eaf{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6,[o.s.j.s.ServletContextHandler@4c59e45e{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2,[o.s.j.s.ServletContextHandler@30a7c98f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3c98781a
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-3f736a16 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-3f736a16=org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3c98781a
STARTED @15118ms org.spark_project.jetty.servlet.ServletHandler@3c98781a
starting org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @15118ms org.spark_project.jetty.servlet.DefaultServlet-3f736a16@42a3878e==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@4601203a for org.spark_project.jetty.servlet.DefaultServlet-3f736a16
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,AVAILABLE,@Spark}
STARTED @15119ms o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-a6ff2d3b-c456-4190-92b1-0eb7e555d4d8-1204902263-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-1, groupId=spark-kafka-source-a6ff2d3b-c456-4190-92b1-0eb7e555d4d8-1204902263-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599307234327
[Consumer clientId=consumer-1, groupId=spark-kafka-source-a6ff2d3b-c456-4190-92b1-0eb7e555d4d8-1204902263-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-1, groupId=spark-kafka-source-a6ff2d3b-c456-4190-92b1-0eb7e555d4d8-1204902263-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-a6ff2d3b-c456-4190-92b1-0eb7e555d4d8-1204902263-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Parsing command: CAST(value AS STRING)
Resolving 'value to value#8

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast('value as string), None)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@38811103, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c71c889,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@38811103, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c71c889,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Cleanup ===
 Project [cast(value#8 as string) AS value#21]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@38811103, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c71c889,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@38811103, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@7c71c889,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#24: java.lang.String   DeserializeToObject cast(value#21 as string).toString, obj#24: java.lang.String
 +- LocalRelation <empty>, [value#21]                                                                                                                                      +- LocalRelation <empty>, [value#21]
          
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Starting [id = 7e5a344d-e4a6-4f6a-b79b-345373e7038d, runId = dbaa2119-8696-42c4-82f1-a0b54bd5e23e]. Use file:///tmp/temporary-eff64292-7140-4e50-bf8f-36f0b1bba8ad to store the query checkpoint.
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599307239093
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Retrieved existing StateStoreCoordinator endpoint
Starting Trigger Calculation
Starting new streaming query.
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Unable to find batch file:/tmp/temporary-eff64292-7140-4e50-bf8f-36f0b1bba8ad/sources/0/0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending FindCoordinator request to broker localhost:9092 (id: -1 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initiating connection to node localhost:9092 (id: -1 rack: null) using address localhost/127.0.0.1
Added sensor with name node--1.bytes-sent
Added sensor with name node--1.bytes-received
Added sensor with name node--1.latency
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 124928, SO_TIMEOUT = 0 to node -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Completed connection to node -1. Fetching API versions.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initiating API versions fetch from node -1.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initiating API versions fetch from node -1.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send API_VERSIONS {} with correlation id 2 to node -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Recorded API versions for node -1: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], ListOffsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], FindCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0], DeleteRecords(21): UNSUPPORTED, InitProducerId(22): UNSUPPORTED, OffsetForLeaderEpoch(23): UNSUPPORTED, AddPartitionsToTxn(24): UNSUPPORTED, AddOffsetsToTxn(25): UNSUPPORTED, EndTxn(26): UNSUPPORTED, WriteTxnMarkers(27): UNSUPPORTED, TxnOffsetCommit(28): UNSUPPORTED, DescribeAcls(29): UNSUPPORTED, CreateAcls(30): UNSUPPORTED, DeleteAcls(31): UNSUPPORTED, DescribeConfigs(32): UNSUPPORTED, AlterConfigs(33): UNSUPPORTED, AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED, CreateDelegationToken(38): UNSUPPORTED, RenewDelegationToken(39): UNSUPPORTED, ExpireDelegationToken(40): UNSUPPORTED, DescribeDelegationToken(41): UNSUPPORTED, DeleteGroups(42): UNSUPPORTED, ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='invoice')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:9092 (id: -1 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v2 to send METADATA {topics=[{name=invoice}]} with correlation id 3 to node -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send FIND_COORDINATOR {key=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0} with correlation id 0 to node -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Cluster ID: P7fOl109TKedvsjS1Ecocg
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = P7fOl109TKedvsjS1Ecocg, nodes = [quickstart.cloudera:9092 (id: 0 rack: null)], partitions = [Partition(topic = invoice, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = quickstart.cloudera:9092 (id: 0 rack: null))}
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Received FindCoordinator response ClientResponse(receivedTimeMs=1599307240718, latencyMs=111, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=0, clientId=consumer-2, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='quickstart.cloudera', port=9092))
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Discovered group coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initiating connection to node quickstart.cloudera:9092 (id: 2147483647 rack: null) using address quickstart.cloudera/10.0.2.15
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Revoking previously assigned partitions []
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Disabling heartbeat thread
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] (Re-)joining group
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Joining group with current subscription: [invoice]
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Heartbeat thread started
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending JoinGroup (JoinGroupRequestData(groupId='spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0', sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 7, 105, 110, 118, 111, 105, 99, 101, 0, 0, 0, 0])])) to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
Added sensor with name node-2147483647.bytes-sent
Added sensor with name node-2147483647.bytes-received
Added sensor with name node-2147483647.latency
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 124928, SO_TIMEOUT = 0 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Completed connection to node 2147483647. Fetching API versions.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initiating API versions fetch from node 2147483647.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initiating API versions fetch from node 2147483647.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send API_VERSIONS {} with correlation id 6 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Recorded API versions for node 2147483647: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], ListOffsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], FindCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0], DeleteRecords(21): UNSUPPORTED, InitProducerId(22): UNSUPPORTED, OffsetForLeaderEpoch(23): UNSUPPORTED, AddPartitionsToTxn(24): UNSUPPORTED, AddOffsetsToTxn(25): UNSUPPORTED, EndTxn(26): UNSUPPORTED, WriteTxnMarkers(27): UNSUPPORTED, TxnOffsetCommit(28): UNSUPPORTED, DescribeAcls(29): UNSUPPORTED, CreateAcls(30): UNSUPPORTED, DeleteAcls(31): UNSUPPORTED, DescribeConfigs(32): UNSUPPORTED, AlterConfigs(33): UNSUPPORTED, AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED, CreateDelegationToken(38): UNSUPPORTED, RenewDelegationToken(39): UNSUPPORTED, ExpireDelegationToken(40): UNSUPPORTED, DescribeDelegationToken(41): UNSUPPORTED, DeleteGroups(42): UNSUPPORTED, ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send JOIN_GROUP {group_id=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0,session_timeout_ms=10000,rebalance_timeout_ms=300000,member_id=,protocol_type=consumer,protocols=[{name=range,metadata=java.nio.HeapByteBuffer[pos=0 lim=19 cap=19]}]} with correlation id 4 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=1, protocolName='range', leader='consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7', memberId='consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7', members=[JoinGroupResponseMember(memberId='consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 7, 105, 110, 118, 111, 105, 99, 101, 0, 0, 0, 0])])
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Performing assignment using strategy range with subscriptions {consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7=Subscription(topics=[invoice])}
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Finished assignment for group: {consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7=Assignment(partitions=[invoice-0])}
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending leader SyncGroup to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null): SyncGroupRequestData(groupId='spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0', generationId=1, memberId='consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7', groupInstanceId='null', assignments=[SyncGroupRequestAssignment(memberId='consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7', assignment=[0, 0, 0, 0, 0, 1, 0, 7, 105, 110, 118, 111, 105, 99, 101, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])])
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send SYNC_GROUP {group_id=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0,generation_id=1,member_id=consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7,assignments=[{member_id=consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7,assignment=java.nio.HeapByteBuffer[pos=0 lim=27 cap=27]}]} with correlation id 7 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Successfully joined group with generation 1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Enabling heartbeat thread
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Setting newly assigned partitions: invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Fetching committed offsets for partitions: [invoice-0]
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v2 to send OFFSET_FETCH {group_id=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0,topics=[{topic=invoice,partitions=[{partition=0}]}]} with correlation id 8 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Found no committed offset for partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -2, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initiating connection to node quickstart.cloudera:9092 (id: 0 rack: null) using address quickstart.cloudera/10.0.2.15
Added sensor with name node-0.bytes-sent
Added sensor with name node-0.bytes-received
Added sensor with name node-0.latency
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 124928, SO_TIMEOUT = 0 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Completed connection to node 0. Fetching API versions.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initiating API versions fetch from node 0.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the beginning
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to EARLIEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -2, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Initiating API versions fetch from node 0.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send API_VERSIONS {} with correlation id 12 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Recorded API versions for node 0: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], ListOffsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], FindCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0], DeleteRecords(21): UNSUPPORTED, InitProducerId(22): UNSUPPORTED, OffsetForLeaderEpoch(23): UNSUPPORTED, AddPartitionsToTxn(24): UNSUPPORTED, AddOffsetsToTxn(25): UNSUPPORTED, EndTxn(26): UNSUPPORTED, WriteTxnMarkers(27): UNSUPPORTED, TxnOffsetCommit(28): UNSUPPORTED, DescribeAcls(29): UNSUPPORTED, CreateAcls(30): UNSUPPORTED, DeleteAcls(31): UNSUPPORTED, DescribeConfigs(32): UNSUPPORTED, AlterConfigs(33): UNSUPPORTED, AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED, CreateDelegationToken(38): UNSUPPORTED, RenewDelegationToken(39): UNSUPPORTED, ExpireDelegationToken(40): UNSUPPORTED, DescribeDelegationToken(41): UNSUPPORTED, DeleteGroups(42): UNSUPPORTED, ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-2}]}]} with correlation id 9 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-2}]}]} with correlation id 11 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 0, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 0.
Got earliest offsets for partition : Map(invoice-0 -> 0)
Unable to find batch file:/tmp/temporary-eff64292-7140-4e50-bf8f-36f0b1bba8ad/sources/0/0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 0, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Skipping reset of partition invoice-0 since reset is no longer needed
Attempting to write log #file:/tmp/temporary-eff64292-7140-4e50-bf8f-36f0b1bba8ad/sources/0/0
Initial offsets: {"invoice":{"0":0}}
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 13 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 1853 ms
Unable to find batch file:/tmp/temporary-eff64292-7140-4e50-bf8f-36f0b1bba8ad/offsets/0
Attempting to write log #file:/tmp/temporary-eff64292-7140-4e50-bf8f-36f0b1bba8ad/offsets/0
Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1599307241189,Map(spark.sql.shuffle.partitions -> 200, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
walCommit took 99 ms
Stream running from {} to {KafkaSource[Subscribe[invoice]]: {"invoice":{"0":34}}}
GetBatch called with start = None, end = {"invoice":{"0":34}}
Partitions added: Map()
TopicPartitions: invoice-0
Sorted executors: 
+++ Cleaning closure <function1> (org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10) +++
 + declared fields: 1
     public static final long org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10.serialVersionUID
 + declared methods: 2
     public final java.lang.Object org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10.apply(java.lang.Object)
     public final org.apache.spark.sql.catalyst.InternalRow org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10.apply(org.apache.kafka.clients.consumer.ConsumerRecord)
 + inner classes: 0
 + outer classes: 0
 + outer objects: 0
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 0
 + there are no enclosing objects!
 +++ closure <function1> (org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10) is now cleaned +++
GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(invoice-0,0,34,None)
Retrieving data from KafkaSource[Subscribe[invoice]]: None -> {"invoice":{"0":34}}
getBatch took 1202 ms
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending Heartbeat request to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send HEARTBEAT {group_id=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0,generation_id=1,member_id=consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7} with correlation id 14 to node 2147483647
queryPlanning took 1282 ms
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Received successful Heartbeat response

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow()), obj#40: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(), obj#40: org.apache.spark.sql.Row
 +- LocalRelation <empty>                                                                             +- LocalRelation <empty>
          
code for createexternalrow():
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */
/* 024 */     Object[] values = new Object[0];
/* 025 */
/* 026 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 027 */     if (false) {
/* 028 */       mutableRow.setNullAt(0);
/* 029 */     } else {
/* 030 */
/* 031 */       mutableRow.update(0, value);
/* 032 */     }
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */
/* 037 */
/* 038 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */
/* 024 */     Object[] values = new Object[0];
/* 025 */
/* 026 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 027 */     if (false) {
/* 028 */       mutableRow.setNullAt(0);
/* 029 */     } else {
/* 030 */
/* 031 */       mutableRow.update(0, value);
/* 032 */     }
/* 033 */
/* 034 */     return mutableRow;
/* 035 */   }
/* 036 */
/* 037 */
/* 038 */ }

Code generated in 864.990836 ms

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private scala.collection.Iterator[] inputs;
/* 008 */   private scala.collection.Iterator inputadapter_input;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] project_mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */   private UnsafeRow[] project_mutableStateArray = new UnsafeRow[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     inputadapter_input = inputs[0];
/* 021 */     project_mutableStateArray[0] = new UnsafeRow(1);
/* 022 */     project_mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(project_mutableStateArray[0], 32);
/* 023 */     project_mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(project_mutableStateArray1[0], 1);
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   protected void processNext() throws java.io.IOException {
/* 028 */     while (inputadapter_input.hasNext() && !stopEarly()) {
/* 029 */       InternalRow inputadapter_row = (InternalRow) inputadapter_input.next();
/* 030 */       boolean inputadapter_isNull1 = inputadapter_row.isNullAt(1);
/* 031 */       byte[] inputadapter_value1 = inputadapter_isNull1 ? null : (inputadapter_row.getBinary(1));
/* 032 */       boolean project_isNull = inputadapter_isNull1;
/* 033 */       UTF8String project_value = null;
/* 034 */       if (!inputadapter_isNull1) {
/* 035 */         project_value = UTF8String.fromBytes(inputadapter_value1);
/* 036 */       }
/* 037 */       project_mutableStateArray1[0].reset();
/* 038 */
/* 039 */       project_mutableStateArray2[0].zeroOutNullBytes();
/* 040 */
/* 041 */       if (project_isNull) {
/* 042 */         project_mutableStateArray2[0].setNullAt(0);
/* 043 */       } else {
/* 044 */         project_mutableStateArray2[0].write(0, project_value);
/* 045 */       }
/* 046 */       project_mutableStateArray[0].setTotalSize(project_mutableStateArray1[0].totalSize());
/* 047 */       append(project_mutableStateArray[0]);
/* 048 */       if (shouldStop()) return;
/* 049 */     }
/* 050 */   }
/* 051 */
/* 052 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private scala.collection.Iterator[] inputs;
/* 008 */   private scala.collection.Iterator inputadapter_input;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] project_mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */   private UnsafeRow[] project_mutableStateArray = new UnsafeRow[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     inputadapter_input = inputs[0];
/* 021 */     project_mutableStateArray[0] = new UnsafeRow(1);
/* 022 */     project_mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(project_mutableStateArray[0], 32);
/* 023 */     project_mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(project_mutableStateArray1[0], 1);
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   protected void processNext() throws java.io.IOException {
/* 028 */     while (inputadapter_input.hasNext() && !stopEarly()) {
/* 029 */       InternalRow inputadapter_row = (InternalRow) inputadapter_input.next();
/* 030 */       boolean inputadapter_isNull1 = inputadapter_row.isNullAt(1);
/* 031 */       byte[] inputadapter_value1 = inputadapter_isNull1 ? null : (inputadapter_row.getBinary(1));
/* 032 */       boolean project_isNull = inputadapter_isNull1;
/* 033 */       UTF8String project_value = null;
/* 034 */       if (!inputadapter_isNull1) {
/* 035 */         project_value = UTF8String.fromBytes(inputadapter_value1);
/* 036 */       }
/* 037 */       project_mutableStateArray1[0].reset();
/* 038 */
/* 039 */       project_mutableStateArray2[0].zeroOutNullBytes();
/* 040 */
/* 041 */       if (project_isNull) {
/* 042 */         project_mutableStateArray2[0].setNullAt(0);
/* 043 */       } else {
/* 044 */         project_mutableStateArray2[0].write(0, project_value);
/* 045 */       }
/* 046 */       project_mutableStateArray[0].setTotalSize(project_mutableStateArray1[0].totalSize());
/* 047 */       append(project_mutableStateArray[0]);
/* 048 */       if (shouldStop()) return;
/* 049 */     }
/* 050 */   }
/* 051 */
/* 052 */ }

Code generated in 106.786835 ms
+++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10) +++
 + declared fields: 4
     public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.serialVersionUID
     private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.cleanedSource$2
     private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.references$1
     public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.durationMs$1
 + declared methods: 2
     public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.apply(java.lang.Object,java.lang.Object)
     public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.apply(int,scala.collection.Iterator)
 + inner classes: 1
     org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1
 + outer classes: 0
 + outer objects: 0
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 0
 + there are no enclosing objects!
 +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10) is now cleaned +++
Start processing data source writer: org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5fd48e31. The input RDD has 1 partitions.
+++ Cleaning closure <function2> (org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$2) +++
 + declared fields: 2
     public static final long org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$2.serialVersionUID
     private final org.apache.spark.sql.sources.v2.writer.DataWriterFactory org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$2.writeTask$1
 + declared methods: 2
     public final java.lang.Object org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$2.apply(java.lang.Object,java.lang.Object)
     public final org.apache.spark.sql.sources.v2.writer.WriterCommitMessage org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$2.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
 + inner classes: 0
 + outer classes: 0
 + outer objects: 0
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 0
 + there are no enclosing objects!
 +++ closure <function2> (org.apache.spark.sql.execution.datasources.v2.WriteToDataSourceV2Exec$$anonfun$2) is now cleaned +++
Starting job: start at MetricProcessMain.scala:62
Got job 0 (start at MetricProcessMain.scala:62) with 1 output partitions
Final stage: ResultStage 0 (start at MetricProcessMain.scala:62)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 0)
missing: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at start at MetricProcessMain.scala:62), which has no missing parents
submitMissingTasks(ResultStage 0)
Block broadcast_0 stored as values in memory (estimated size 9.2 KB, free 1206.9 MB)
Put block broadcast_0 locally took  173 ms
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending Heartbeat request to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send HEARTBEAT {group_id=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0,generation_id=1,member_id=consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7} with correlation id 15 to node 2147483647
Putting block broadcast_0 without replication took  184 ms
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Received successful Heartbeat response
Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 1206.9 MB)
Added broadcast_0_piece0 in memory on quickstart.cloudera:38057 (size: 4.9 KB, free: 1206.9 MB)
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Put block broadcast_0_piece0 locally took  18 ms
Putting block broadcast_0_piece0 without replication took  18 ms
Created broadcast 0 from broadcast at DAGScheduler.scala:1039
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at start at MetricProcessMain.scala:62) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks
Epoch for TaskSet 0.0: 0
Valid locality levels for TaskSet 0.0: NO_PREF, ANY
parentName: , name: TaskSet_0.0, runningTasks: 0
Valid locality levels for TaskSet 0.0: NO_PREF, ANY
Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8030 bytes)
Running task 0.0 in stage 0.0 (TID 0)
Getting local block broadcast_0
Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599307247890
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Kafka consumer initialized
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Subscribed to partition(s): invoice-0
code for input[0, binary, true],input[1, binary, true],input[2, string, true],input[3, int, true],input[4, bigint, true],input[5, timestamp, true],input[6, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private UnsafeRow[] mutableStateArray = new UnsafeRow[1];
/* 011 */
/* 012 */   public SpecificUnsafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableStateArray[0] = new UnsafeRow(7);
/* 015 */     mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(mutableStateArray[0], 96);
/* 016 */     mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray1[0], 7);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray1[0].reset();
/* 031 */
/* 032 */     mutableStateArray2[0].zeroOutNullBytes();
/* 033 */     writeFields_0(i);
/* 034 */     writeFields_1(i);
/* 035 */     mutableStateArray[0].setTotalSize(mutableStateArray1[0].totalSize());
/* 036 */     return mutableStateArray[0];
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_1(InternalRow i) {
/* 041 */
/* 042 */
/* 043 */     boolean isNull4 = i.isNullAt(4);
/* 044 */     long value4 = isNull4 ? -1L : (i.getLong(4));
/* 045 */     if (isNull4) {
/* 046 */       mutableStateArray2[0].setNullAt(4);
/* 047 */     } else {
/* 048 */       mutableStateArray2[0].write(4, value4);
/* 049 */     }
/* 050 */
/* 051 */
/* 052 */     boolean isNull5 = i.isNullAt(5);
/* 053 */     long value5 = isNull5 ? -1L : (i.getLong(5));
/* 054 */     if (isNull5) {
/* 055 */       mutableStateArray2[0].setNullAt(5);
/* 056 */     } else {
/* 057 */       mutableStateArray2[0].write(5, value5);
/* 058 */     }
/* 059 */
/* 060 */
/* 061 */     boolean isNull6 = i.isNullAt(6);
/* 062 */     int value6 = isNull6 ? -1 : (i.getInt(6));
/* 063 */     if (isNull6) {
/* 064 */       mutableStateArray2[0].setNullAt(6);
/* 065 */     } else {
/* 066 */       mutableStateArray2[0].write(6, value6);
/* 067 */     }
/* 068 */
/* 069 */   }
/* 070 */
/* 071 */
/* 072 */   private void writeFields_0(InternalRow i) {
/* 073 */
/* 074 */
/* 075 */     boolean isNull = i.isNullAt(0);
/* 076 */     byte[] value = isNull ? null : (i.getBinary(0));
/* 077 */     if (isNull) {
/* 078 */       mutableStateArray2[0].setNullAt(0);
/* 079 */     } else {
/* 080 */       mutableStateArray2[0].write(0, value);
/* 081 */     }
/* 082 */
/* 083 */
/* 084 */     boolean isNull1 = i.isNullAt(1);
/* 085 */     byte[] value1 = isNull1 ? null : (i.getBinary(1));
/* 086 */     if (isNull1) {
/* 087 */       mutableStateArray2[0].setNullAt(1);
/* 088 */     } else {
/* 089 */       mutableStateArray2[0].write(1, value1);
/* 090 */     }
/* 091 */
/* 092 */
/* 093 */     boolean isNull2 = i.isNullAt(2);
/* 094 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(2));
/* 095 */     if (isNull2) {
/* 096 */       mutableStateArray2[0].setNullAt(2);
/* 097 */     } else {
/* 098 */       mutableStateArray2[0].write(2, value2);
/* 099 */     }
/* 100 */
/* 101 */
/* 102 */     boolean isNull3 = i.isNullAt(3);
/* 103 */     int value3 = isNull3 ? -1 : (i.getInt(3));
/* 104 */     if (isNull3) {
/* 105 */       mutableStateArray2[0].setNullAt(3);
/* 106 */     } else {
/* 107 */       mutableStateArray2[0].write(3, value3);
/* 108 */     }
/* 109 */
/* 110 */   }
/* 111 */
/* 112 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private UnsafeRow[] mutableStateArray = new UnsafeRow[1];
/* 011 */
/* 012 */   public SpecificUnsafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableStateArray[0] = new UnsafeRow(7);
/* 015 */     mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(mutableStateArray[0], 96);
/* 016 */     mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray1[0], 7);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray1[0].reset();
/* 031 */
/* 032 */     mutableStateArray2[0].zeroOutNullBytes();
/* 033 */     writeFields_0(i);
/* 034 */     writeFields_1(i);
/* 035 */     mutableStateArray[0].setTotalSize(mutableStateArray1[0].totalSize());
/* 036 */     return mutableStateArray[0];
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_1(InternalRow i) {
/* 041 */
/* 042 */
/* 043 */     boolean isNull4 = i.isNullAt(4);
/* 044 */     long value4 = isNull4 ? -1L : (i.getLong(4));
/* 045 */     if (isNull4) {
/* 046 */       mutableStateArray2[0].setNullAt(4);
/* 047 */     } else {
/* 048 */       mutableStateArray2[0].write(4, value4);
/* 049 */     }
/* 050 */
/* 051 */
/* 052 */     boolean isNull5 = i.isNullAt(5);
/* 053 */     long value5 = isNull5 ? -1L : (i.getLong(5));
/* 054 */     if (isNull5) {
/* 055 */       mutableStateArray2[0].setNullAt(5);
/* 056 */     } else {
/* 057 */       mutableStateArray2[0].write(5, value5);
/* 058 */     }
/* 059 */
/* 060 */
/* 061 */     boolean isNull6 = i.isNullAt(6);
/* 062 */     int value6 = isNull6 ? -1 : (i.getInt(6));
/* 063 */     if (isNull6) {
/* 064 */       mutableStateArray2[0].setNullAt(6);
/* 065 */     } else {
/* 066 */       mutableStateArray2[0].write(6, value6);
/* 067 */     }
/* 068 */
/* 069 */   }
/* 070 */
/* 071 */
/* 072 */   private void writeFields_0(InternalRow i) {
/* 073 */
/* 074 */
/* 075 */     boolean isNull = i.isNullAt(0);
/* 076 */     byte[] value = isNull ? null : (i.getBinary(0));
/* 077 */     if (isNull) {
/* 078 */       mutableStateArray2[0].setNullAt(0);
/* 079 */     } else {
/* 080 */       mutableStateArray2[0].write(0, value);
/* 081 */     }
/* 082 */
/* 083 */
/* 084 */     boolean isNull1 = i.isNullAt(1);
/* 085 */     byte[] value1 = isNull1 ? null : (i.getBinary(1));
/* 086 */     if (isNull1) {
/* 087 */       mutableStateArray2[0].setNullAt(1);
/* 088 */     } else {
/* 089 */       mutableStateArray2[0].write(1, value1);
/* 090 */     }
/* 091 */
/* 092 */
/* 093 */     boolean isNull2 = i.isNullAt(2);
/* 094 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(2));
/* 095 */     if (isNull2) {
/* 096 */       mutableStateArray2[0].setNullAt(2);
/* 097 */     } else {
/* 098 */       mutableStateArray2[0].write(2, value2);
/* 099 */     }
/* 100 */
/* 101 */
/* 102 */     boolean isNull3 = i.isNullAt(3);
/* 103 */     int value3 = isNull3 ? -1 : (i.getInt(3));
/* 104 */     if (isNull3) {
/* 105 */       mutableStateArray2[0].setNullAt(3);
/* 106 */     } else {
/* 107 */       mutableStateArray2[0].write(3, value3);
/* 108 */     }
/* 109 */
/* 110 */   }
/* 111 */
/* 112 */ }

Code generated in 164.529856 ms

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, StructField(value,StringType,true))), obj#43: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(value#42.toString, StructField(value,StringType,true)), obj#43: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [value#42]                                                                                                                                               +- LocalRelation <empty>, [value#42]
          
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset -2 requested 0
Seeking to spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 0
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Seeking to offset 0 for partition invoice-0
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Initialize connection to node localhost:9092 (id: -1 rack: null) for sending metadata request
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Initiating connection to node localhost:9092 (id: -1 rack: null) using address localhost/127.0.0.1
Added sensor with name node--1.bytes-sent
Added sensor with name node--1.bytes-received
Added sensor with name node--1.latency
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 124928, SO_TIMEOUT = 0 to node -1
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Completed connection to node -1. Fetching API versions.
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Initiating API versions fetch from node -1.
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Initiating API versions fetch from node -1.
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Using older server API v0 to send API_VERSIONS {} with correlation id 1 to node -1
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Recorded API versions for node -1: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], ListOffsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], FindCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0], DeleteRecords(21): UNSUPPORTED, InitProducerId(22): UNSUPPORTED, OffsetForLeaderEpoch(23): UNSUPPORTED, AddPartitionsToTxn(24): UNSUPPORTED, AddOffsetsToTxn(25): UNSUPPORTED, EndTxn(26): UNSUPPORTED, WriteTxnMarkers(27): UNSUPPORTED, TxnOffsetCommit(28): UNSUPPORTED, DescribeAcls(29): UNSUPPORTED, CreateAcls(30): UNSUPPORTED, DeleteAcls(31): UNSUPPORTED, DescribeConfigs(32): UNSUPPORTED, AlterConfigs(33): UNSUPPORTED, AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED, CreateDelegationToken(38): UNSUPPORTED, RenewDelegationToken(39): UNSUPPORTED, ExpireDelegationToken(40): UNSUPPORTED, DescribeDelegationToken(41): UNSUPPORTED, DeleteGroups(42): UNSUPPORTED, ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='invoice')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:9092 (id: -1 rack: null)
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Using older server API v2 to send METADATA {topics=[{name=invoice}]} with correlation id 2 to node -1
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Cluster ID: P7fOl109TKedvsjS1Ecocg
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = P7fOl109TKedvsjS1Ecocg, nodes = [quickstart.cloudera:9092 (id: 0 rack: null)], partitions = [Partition(topic = invoice, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = quickstart.cloudera:9092 (id: 0 rack: null))}
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Added READ_UNCOMMITTED fetch request for partition invoice-0 at position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=quickstart.cloudera:9092 (id: 0 rack: null), epoch=-1}} to node quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 0 with 1 partition(s).
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Sending READ_UNCOMMITTED FullFetchRequest(invoice-0) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Initiating connection to node quickstart.cloudera:9092 (id: 0 rack: null) using address quickstart.cloudera/10.0.2.15
Added sensor with name node-0.bytes-sent
Added sensor with name node-0.bytes-received
Added sensor with name node-0.latency
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 124928, SO_TIMEOUT = 0 to node 0
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Completed connection to node 0. Fetching API versions.
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Initiating API versions fetch from node 0.
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Initiating API versions fetch from node 0.
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Using older server API v0 to send API_VERSIONS {} with correlation id 5 to node 0
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Recorded API versions for node 0: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], ListOffsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], FindCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0], DeleteRecords(21): UNSUPPORTED, InitProducerId(22): UNSUPPORTED, OffsetForLeaderEpoch(23): UNSUPPORTED, AddPartitionsToTxn(24): UNSUPPORTED, AddOffsetsToTxn(25): UNSUPPORTED, EndTxn(26): UNSUPPORTED, WriteTxnMarkers(27): UNSUPPORTED, TxnOffsetCommit(28): UNSUPPORTED, DescribeAcls(29): UNSUPPORTED, CreateAcls(30): UNSUPPORTED, DeleteAcls(31): UNSUPPORTED, DescribeConfigs(32): UNSUPPORTED, AlterConfigs(33): UNSUPPORTED, AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED, CreateDelegationToken(38): UNSUPPORTED, RenewDelegationToken(39): UNSUPPORTED, ExpireDelegationToken(40): UNSUPPORTED, DescribeDelegationToken(41): UNSUPPORTED, DeleteGroups(42): UNSUPPORTED, ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Using older server API v3 to send FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,topics=[{topic=invoice,partitions=[{partition=0,fetch_offset=0,partition_max_bytes=1048576}]}]} with correlation id 3 to node 0
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Node 0 sent a full fetch response with 1 response partition(s)
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Fetch READ_UNCOMMITTED at offset 0 for partition invoice-0 returned fetch data (error=NONE, highWaterMark=34, lastStableOffset = -1, logStartOffset = -1, preferredReadReplica = absent, abortedTransactions = null, recordsSizeInBytes=23447)
Added sensor with name topic.invoice.bytes-fetched
Added sensor with name topic.invoice.records-fetched
Added sensor with name invoice-0.records-lag
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Added READ_UNCOMMITTED fetch request for partition invoice-0 at position FetchPosition{offset=34, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=quickstart.cloudera:9092 (id: 0 rack: null), epoch=-1}} to node quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 0 with 1 partition(s).
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Sending READ_UNCOMMITTED FullFetchRequest(invoice-0) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-3, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor] Using older server API v3 to send FETCH {replica_id=-1,max_wait_time=500,min_bytes=1,max_bytes=52428800,topics=[{topic=invoice,partitions=[{partition=0,fetch_offset=34,partition_max_bytes=1048576}]}]} with correlation id 6 to node 0
Polled spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor [invoice-0]  34
code for createexternalrow(input[0, string, true].toString, StructField(value,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */
/* 024 */     Object[] values = new Object[1];
/* 025 */
/* 026 */
/* 027 */     boolean isNull2 = i.isNullAt(0);
/* 028 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 029 */     boolean isNull1 = true;
/* 030 */     java.lang.String value1 = null;
/* 031 */     if (!isNull2) {
/* 032 */
/* 033 */       isNull1 = false;
/* 034 */       if (!isNull1) {
/* 035 */
/* 036 */         Object funcResult = null;
/* 037 */         funcResult = value2.toString();
/* 038 */         value1 = (java.lang.String) funcResult;
/* 039 */
/* 040 */       }
/* 041 */     }
/* 042 */     if (isNull1) {
/* 043 */       values[0] = null;
/* 044 */     } else {
/* 045 */       values[0] = value1;
/* 046 */     }
/* 047 */
/* 048 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 049 */     if (false) {
/* 050 */       mutableRow.setNullAt(0);
/* 051 */     } else {
/* 052 */
/* 053 */       mutableRow.update(0, value);
/* 054 */     }
/* 055 */
/* 056 */     return mutableRow;
/* 057 */   }
/* 058 */
/* 059 */
/* 060 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */
/* 024 */     Object[] values = new Object[1];
/* 025 */
/* 026 */
/* 027 */     boolean isNull2 = i.isNullAt(0);
/* 028 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 029 */     boolean isNull1 = true;
/* 030 */     java.lang.String value1 = null;
/* 031 */     if (!isNull2) {
/* 032 */
/* 033 */       isNull1 = false;
/* 034 */       if (!isNull1) {
/* 035 */
/* 036 */         Object funcResult = null;
/* 037 */         funcResult = value2.toString();
/* 038 */         value1 = (java.lang.String) funcResult;
/* 039 */
/* 040 */       }
/* 041 */     }
/* 042 */     if (isNull1) {
/* 043 */       values[0] = null;
/* 044 */     } else {
/* 045 */       values[0] = value1;
/* 046 */     }
/* 047 */
/* 048 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 049 */     if (false) {
/* 050 */       mutableRow.setNullAt(0);
/* 051 */     } else {
/* 052 */
/* 053 */       mutableRow.update(0, value);
/* 054 */     }
/* 055 */
/* 056 */     return mutableRow;
/* 057 */   }
/* 058 */
/* 059 */
/* 060 */ }

Code generated in 59.633438 ms
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 1 requested 1
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 2 requested 2
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 3 requested 3
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 4 requested 4
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 5 requested 5
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 6 requested 6
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 7 requested 7
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 8 requested 8
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 9 requested 9
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 10 requested 10
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 11 requested 11
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 12 requested 12
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 13 requested 13
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 14 requested 14
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 15 requested 15
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 16 requested 16
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 17 requested 17
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 18 requested 18
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 19 requested 19
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 20 requested 20
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 21 requested 21
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 22 requested 22
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 23 requested 23
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 24 requested 24
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 25 requested 25
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 26 requested 26
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 27 requested 27
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 28 requested 28
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 29 requested 29
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 30 requested 30
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 31 requested 31
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 32 requested 32
Get spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-executor invoice-0 nextOffset 33 requested 33
Writer for partition 0 is committing.
Writer for partition 0 committed.
Finished task 0.0 in stage 0.0 (TID 0). 25346 bytes result sent to driver
parentName: , name: TaskSet_0.0, runningTasks: 0
No tasks for locality level NO_PREF, so moving to locality level ANY
Finished task 0.0 in stage 0.0 (TID 0) in 1278 ms on localhost (executor driver) (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
ResultStage 0 (start at MetricProcessMain.scala:62) finished in 2.348 s
After removal of stage 0, remaining stages = 0
Job 0 finished: start at MetricProcessMain.scala:62, took 2.672618 s
Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5fd48e31 is committing.

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast(value#44 as string), None)]   Project [cast(value#44 as string) AS value#47]
 +- AnalysisBarrier                                           +- AnalysisBarrier
       +- LocalRelation [value#44]                                  +- LocalRelation [value#44]
          

=== Result of Batch Cleanup ===
 Project [cast(value#44 as string) AS value#47]   Project [cast(value#44 as string) AS value#47]
 +- AnalysisBarrier                               +- AnalysisBarrier
       +- LocalRelation [value#44]                      +- LocalRelation [value#44]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, StructField(value,StringType,true))), obj#49: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(value#47.toString, StructField(value,StringType,true)), obj#49: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [value#47]                                                                                                                                               +- LocalRelation <empty>, [value#47]
          

=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 21                                         GlobalLimit 21
 +- LocalLimit 21                                       +- LocalLimit 21
!   +- Project [cast(value#44 as string) AS value#47]      +- LocalRelation [value#44]
!      +- LocalRelation [value#44]                      
          

=== Result of Batch LocalRelation ===
!GlobalLimit 21                   LocalRelation [value#44]
!+- LocalLimit 21                 
!   +- LocalRelation [value#44]   
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(createexternalrow(getcolumnbyordinal(0, StringType).toString, StructField(value,StringType,true))), obj#50: org.apache.spark.sql.Row   DeserializeToObject createexternalrow(value#47.toString, StructField(value,StringType,true)), obj#50: org.apache.spark.sql.Row
 +- LocalRelation <empty>, [value#47]                                                                                                                                               +- LocalRelation <empty>, [value#47]
          
code for createexternalrow(input[0, string, true].toString, StructField(value,StringType,true)):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */
/* 024 */     Object[] values = new Object[1];
/* 025 */
/* 026 */
/* 027 */     boolean isNull2 = i.isNullAt(0);
/* 028 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(0));
/* 029 */     boolean isNull1 = true;
/* 030 */     java.lang.String value1 = null;
/* 031 */     if (!isNull2) {
/* 032 */
/* 033 */       isNull1 = false;
/* 034 */       if (!isNull1) {
/* 035 */
/* 036 */         Object funcResult = null;
/* 037 */         funcResult = value2.toString();
/* 038 */         value1 = (java.lang.String) funcResult;
/* 039 */
/* 040 */       }
/* 041 */     }
/* 042 */     if (isNull1) {
/* 043 */       values[0] = null;
/* 044 */     } else {
/* 045 */       values[0] = value1;
/* 046 */     }
/* 047 */
/* 048 */     final org.apache.spark.sql.Row value = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(values, ((org.apache.spark.sql.types.StructType) references[0] /* schema */));
/* 049 */     if (false) {
/* 050 */       mutableRow.setNullAt(0);
/* 051 */     } else {
/* 052 */
/* 053 */       mutableRow.update(0, value);
/* 054 */     }
/* 055 */
/* 056 */     return mutableRow;
/* 057 */   }
/* 058 */
/* 059 */
/* 060 */ }

code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private UnsafeRow[] mutableStateArray = new UnsafeRow[1];
/* 011 */
/* 012 */   public SpecificUnsafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableStateArray[0] = new UnsafeRow(1);
/* 015 */     mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(mutableStateArray[0], 32);
/* 016 */     mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray1[0], 1);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray1[0].reset();
/* 031 */
/* 032 */     mutableStateArray2[0].zeroOutNullBytes();
/* 033 */
/* 034 */
/* 035 */     boolean isNull = i.isNullAt(0);
/* 036 */     UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 037 */     if (isNull) {
/* 038 */       mutableStateArray2[0].setNullAt(0);
/* 039 */     } else {
/* 040 */       mutableStateArray2[0].write(0, value);
/* 041 */     }
/* 042 */     mutableStateArray[0].setTotalSize(mutableStateArray1[0].totalSize());
/* 043 */     return mutableStateArray[0];
/* 044 */   }
/* 045 */
/* 046 */
/* 047 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private UnsafeRow[] mutableStateArray = new UnsafeRow[1];
/* 011 */
/* 012 */   public SpecificUnsafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableStateArray[0] = new UnsafeRow(1);
/* 015 */     mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(mutableStateArray[0], 32);
/* 016 */     mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray1[0], 1);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray1[0].reset();
/* 031 */
/* 032 */     mutableStateArray2[0].zeroOutNullBytes();
/* 033 */
/* 034 */
/* 035 */     boolean isNull = i.isNullAt(0);
/* 036 */     UTF8String value = isNull ? null : (i.getUTF8String(0));
/* 037 */     if (isNull) {
/* 038 */       mutableStateArray2[0].setNullAt(0);
/* 039 */     } else {
/* 040 */       mutableStateArray2[0].write(0, value);
/* 041 */     }
/* 042 */     mutableStateArray[0].setTotalSize(mutableStateArray1[0].totalSize());
/* 043 */     return mutableStateArray[0];
/* 044 */   }
/* 045 */
/* 046 */
/* 047 */ }

Code generated in 31.264783 ms
Data source writer org.apache.spark.sql.execution.streaming.sources.MicroBatchWriter@5fd48e31 committed.
+++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12) +++
 + declared fields: 2
     public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.serialVersionUID
     private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.$outer
 + declared methods: 2
     public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(java.lang.Object)
     public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12.apply(scala.collection.Iterator)
 + inner classes: 0
 + outer classes: 2
     org.apache.spark.rdd.RDD$$anonfun$collect$1
     org.apache.spark.rdd.RDD
 + outer objects: 2
     <function0>
     MapPartitionsRDD[5] at start at MetricProcessMain.scala:62
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 4
     (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
     (class java.lang.Object,Set())
     (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
     (class scala.runtime.AbstractFunction0,Set())
 + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[5] at start at MetricProcessMain.scala:62)
 + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
 + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
+++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
 + declared fields: 2
     public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
     private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
 + declared methods: 2
     public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
     public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
 + inner classes: 1
     org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12
 + outer classes: 1
     org.apache.spark.rdd.RDD
 + outer objects: 1
     MapPartitionsRDD[5] at start at MetricProcessMain.scala:62
 + fields accessed by starting closure: 4
     (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
     (class java.lang.Object,Set())
     (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
     (class scala.runtime.AbstractFunction0,Set())
 + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[5] at start at MetricProcessMain.scala:62)
 +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
 +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$12) is now cleaned +++
+++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
 + declared fields: 2
     public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
     private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
 + declared methods: 2
     public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
     public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
 + inner classes: 0
 + outer classes: 0
 + outer objects: 0
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 0
 + there are no enclosing objects!
 +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
Starting job: start at MetricProcessMain.scala:62
Job 1 finished: start at MetricProcessMain.scala:62, took 0.000115 s
addBatch took 5333 ms
triggerExecution took 10012 ms
Execution stats: ExecutionStats(Map(KafkaSource[Subscribe[invoice]] -> 34),ArrayBuffer(),Map())
Streaming query made progress: {
  "id" : "7e5a344d-e4a6-4f6a-b79b-345373e7038d",
  "runId" : "dbaa2119-8696-42c4-82f1-a0b54bd5e23e",
  "name" : null,
  "timestamp" : "2020-09-05T12:00:39.194Z",
  "batchId" : 0,
  "numInputRows" : 34,
  "processedRowsPerSecond" : 3.3949076385421866,
  "durationMs" : {
    "addBatch" : 5333,
    "getBatch" : 1202,
    "getOffset" : 1853,
    "queryPlanning" : 1282,
    "triggerExecution" : 10012,
    "walCommit" : 99
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[invoice]]",
    "startOffset" : null,
    "endOffset" : {
      "invoice" : {
        "0" : 34
      }
    },
    "numInputRows" : 34,
    "processedRowsPerSecond" : 3.3949076385421866
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@7394e39e"
  }
}
Unable to find batch file:/tmp/temporary-eff64292-7140-4e50-bf8f-36f0b1bba8ad/commits/0
Attempting to write log #file:/tmp/temporary-eff64292-7140-4e50-bf8f-36f0b1bba8ad/commits/0
batch 0 committed
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 16 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Streaming query made progress: {
  "id" : "7e5a344d-e4a6-4f6a-b79b-345373e7038d",
  "runId" : "dbaa2119-8696-42c4-82f1-a0b54bd5e23e",
  "name" : null,
  "timestamp" : "2020-09-05T12:00:49.443Z",
  "batchId" : 1,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "getOffset" : 6,
    "triggerExecution" : 7
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaSource[Subscribe[invoice]]",
    "startOffset" : {
      "invoice" : {
        "0" : 34
      }
    },
    "endOffset" : {
      "invoice" : {
        "0" : 34
      }
    },
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleSinkProvider@7394e39e"
  }
}
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 17 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 18 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 19 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 20 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 20 ms
triggerExecution took 21 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 21 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 22 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 23 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 24 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 25 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 26 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 27 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 21 ms
triggerExecution took 23 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 28 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 29 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 30 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 31 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 32 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 13 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 33 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 34 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 35 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 36 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 16 ms
triggerExecution took 17 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 37 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 38 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending Heartbeat request to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send HEARTBEAT {group_id=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0,generation_id=1,member_id=consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7} with correlation id 39 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 40 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Received successful Heartbeat response
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 41 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 42 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 43 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 44 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 45 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 46 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 19 ms
triggerExecution took 19 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 47 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 48 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 49 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 50 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 51 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 52 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 15 ms
triggerExecution took 15 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 53 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 54 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 55 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 22 ms
triggerExecution took 24 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 56 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 13 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 57 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 25 ms
triggerExecution took 29 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 58 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 59 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 15 ms
triggerExecution took 16 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 60 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 22 ms
triggerExecution took 22 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 61 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 11 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 62 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 13 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 63 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 64 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 65 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 66 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 67 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 68 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 69 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 70 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 71 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 72 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 73 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 74 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 75 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 76 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 77 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 78 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 15 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 79 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 17 ms
triggerExecution took 17 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 80 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 81 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 82 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 83 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 84 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 85 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 86 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 87 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 15 ms
triggerExecution took 17 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 88 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 89 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 90 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 91 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 92 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 93 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 22 ms
triggerExecution took 22 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 94 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 17 ms
triggerExecution took 18 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 95 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 96 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 13 ms
triggerExecution took 13 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 97 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 98 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 99 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 100 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 101 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 102 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 103 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 104 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 105 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 106 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 107 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 108 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 109 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 110 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 11 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 111 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 112 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 113 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 114 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 115 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 116 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 117 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 118 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 119 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 120 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 121 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 122 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 123 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 124 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 125 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 126 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 127 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 128 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 129 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 130 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 131 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 132 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 133 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 134 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 135 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 136 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 17 ms
triggerExecution took 17 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 137 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 138 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 139 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 140 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 141 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 142 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 143 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 144 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 145 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 146 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 147 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 148 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 149 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 150 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 151 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 18 ms
triggerExecution took 19 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 152 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 153 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 154 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 13 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 155 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 156 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 157 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 158 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 159 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 160 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 161 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 20 ms
triggerExecution took 20 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 162 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 163 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 164 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 165 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 166 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 167 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 168 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 169 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 170 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 171 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 172 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 173 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 174 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 175 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 176 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 177 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 178 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 11 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 179 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 15 ms
triggerExecution took 16 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 180 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 181 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 182 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 183 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 21 ms
triggerExecution took 21 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 184 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 185 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 186 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 187 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending Heartbeat request to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send HEARTBEAT {group_id=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0,generation_id=1,member_id=consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7} with correlation id 188 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 189 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Received successful Heartbeat response
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 190 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 191 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 192 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 193 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 194 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 22 ms
triggerExecution took 22 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 195 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 13 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 196 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 197 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 198 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 199 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 26 ms
triggerExecution took 26 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 200 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 201 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 202 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 203 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 204 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 17 ms
triggerExecution took 17 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 205 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 13 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 206 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 207 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 208 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 209 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 210 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 211 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 212 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 213 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 214 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 215 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 216 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 217 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 218 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 219 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 220 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 221 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 222 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 223 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 224 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 225 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 226 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 227 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 228 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 229 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 230 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 231 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 232 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 233 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 234 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 235 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 236 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 237 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 238 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 239 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 240 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 241 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 242 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 243 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 244 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 245 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 246 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 247 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 248 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 249 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 250 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 13 ms
triggerExecution took 13 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 251 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 15 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 252 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 253 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 254 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 255 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 256 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 257 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 258 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 259 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 260 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 261 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 11 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 262 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 13 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 263 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 264 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 11 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 265 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 21 ms
triggerExecution took 21 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 266 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 267 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 11 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 268 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 269 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 13 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 270 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 16 ms
triggerExecution took 16 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 271 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 32 ms
triggerExecution took 33 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 272 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 273 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 18 ms
triggerExecution took 19 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 274 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 275 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 276 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 19 ms
triggerExecution took 19 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 277 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 278 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 279 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 16 ms
triggerExecution took 16 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 280 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 281 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 282 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 283 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 284 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 285 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 286 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 287 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 288 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 289 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 20 ms
triggerExecution took 20 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 290 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 291 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 292 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 293 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 294 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 295 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 296 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 297 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 298 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 299 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 300 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 301 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 302 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 303 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 304 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 305 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 306 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 307 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 308 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 309 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 310 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 311 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 312 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 313 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 314 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 315 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 316 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 317 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 318 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 319 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 320 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 321 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 322 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 323 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 324 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 325 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 326 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 327 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 328 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 329 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 330 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 331 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 332 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 333 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 334 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 335 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 336 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 337 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 338 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 339 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 340 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 341 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 342 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 343 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 344 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 345 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 346 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending Heartbeat request to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send HEARTBEAT {group_id=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0,generation_id=1,member_id=consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7} with correlation id 347 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 348 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Received successful Heartbeat response
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 349 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 350 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 351 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 11 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 352 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 353 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 354 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 355 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 356 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 357 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 358 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 359 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 17 ms
triggerExecution took 19 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 360 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 13 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 361 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 362 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 11 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 363 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 364 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 365 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 366 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 367 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 368 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 369 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 370 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 371 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 372 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 373 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 374 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 375 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 376 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 377 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 378 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 11 ms
triggerExecution took 11 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 379 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 380 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 381 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 382 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 383 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 384 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 385 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 386 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 387 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 388 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 389 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 390 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 391 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 392 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 393 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 394 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 395 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 396 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 397 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 398 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 399 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 400 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 401 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 402 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 403 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 404 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 405 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 406 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 407 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 408 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 409 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 410 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 411 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 412 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 413 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 414 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 415 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 416 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 417 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 418 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 419 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 420 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 421 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 422 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 8 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 423 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 424 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 425 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 426 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 427 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 428 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 429 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 430 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 431 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 432 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 433 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 434 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 435 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 436 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 437 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 438 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 439 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 440 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 441 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 442 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 443 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 444 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 445 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 446 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 447 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 448 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 449 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 450 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 451 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 452 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 453 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 454 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 455 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 456 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 457 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 458 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 459 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 460 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 461 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 462 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 463 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 464 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 465 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 466 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 467 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 468 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 469 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 470 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 471 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 472 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 473 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 474 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 475 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 476 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 477 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 478 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 479 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 480 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 481 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 482 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 483 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 484 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 16 ms
triggerExecution took 17 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 485 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 486 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 487 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 488 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 7 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 489 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 490 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 7 ms
triggerExecution took 8 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 491 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 492 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 493 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 494 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 495 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 496 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 10 ms
triggerExecution took 10 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 497 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 498 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 499 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 500 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 17 ms
triggerExecution took 17 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 501 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 502 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 503 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 40 ms
triggerExecution took 41 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 504 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 13 ms
triggerExecution took 14 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 505 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 506 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 6 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 507 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 508 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 509 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 20 ms
triggerExecution took 20 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 510 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 14 ms
triggerExecution took 20 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 511 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 512 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 6 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 513 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 514 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 515 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 516 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 517 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 518 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 519 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 520 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 9 ms
triggerExecution took 9 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 521 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 522 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 523 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 524 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 525 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 526 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 16 ms
triggerExecution took 16 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 527 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending Heartbeat request to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v0 to send HEARTBEAT {group_id=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0,generation_id=1,member_id=consumer-2-566a25ee-03b6-4c1f-8db9-86f2a85c42c7} with correlation id 528 to node 2147483647
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Received successful Heartbeat response
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 529 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 530 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 531 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 532 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 533 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 534 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 535 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 536 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Invoking stop() from shutdown hook
stopping org.spark_project.jetty.server.Server@4bbb49b0
doStop org.spark_project.jetty.server.Server@4bbb49b0
ran SparkUI-28-acceptor-0@211febf3-ServerConnector@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 537 to node 0
Graceful shutdown org.spark_project.jetty.server.Server@4bbb49b0 by 
stopping Spark@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a
stopping org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4d28474e on org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 12 ms
triggerExecution took 12 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@4d28474e
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@6985fbfa on org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@6985fbfa
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@2d84671c produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@2d84671c produce exit
ran org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1
Stopped org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@50d951e7 id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@244e619a
stopping HttpConnectionFactory@7c129ef6[HTTP/1.1]
STOPPED HttpConnectionFactory@7c129ef6[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@5918c260
Stopped Spark@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@77e7246b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@4bbb49b0
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@390877d2[org.spark_project.jetty.server.handler.gzip.GzipHandler@444cc791, org.spark_project.jetty.server.handler.gzip.GzipHandler@3e48d38, org.spark_project.jetty.server.handler.gzip.GzipHandler@702c436b, org.spark_project.jetty.server.handler.gzip.GzipHandler@aa149ed, org.spark_project.jetty.server.handler.gzip.GzipHandler@165e389b, org.spark_project.jetty.server.handler.gzip.GzipHandler@e4b6f47, org.spark_project.jetty.server.handler.gzip.GzipHandler@3ed03652, org.spark_project.jetty.server.handler.gzip.GzipHandler@1dc76fa1, org.spark_project.jetty.server.handler.gzip.GzipHandler@7808f638, org.spark_project.jetty.server.handler.gzip.GzipHandler@46731692, org.spark_project.jetty.server.handler.gzip.GzipHandler@ad9e63e, org.spark_project.jetty.server.handler.gzip.GzipHandler@2cc03cd1, org.spark_project.jetty.server.handler.gzip.GzipHandler@3b9632d1, org.spark_project.jetty.server.handler.gzip.GzipHandler@26d96e5, org.spark_project.jetty.server.handler.gzip.GzipHandler@75fc1992, org.spark_project.jetty.server.handler.gzip.GzipHandler@3abfe845, org.spark_project.jetty.server.handler.gzip.GzipHandler@4defd42, org.spark_project.jetty.server.handler.gzip.GzipHandler@706eab5d, org.spark_project.jetty.server.handler.gzip.GzipHandler@5ac6c4f2, org.spark_project.jetty.server.handler.gzip.GzipHandler@53a665ad, org.spark_project.jetty.server.handler.gzip.GzipHandler@3bfc6a5e, org.spark_project.jetty.server.handler.gzip.GzipHandler@476e8796, org.spark_project.jetty.server.handler.gzip.GzipHandler@4339e0de, org.spark_project.jetty.server.handler.gzip.GzipHandler@27b2faa6, org.spark_project.jetty.server.handler.gzip.GzipHandler@c2e3264, o.s.j.s.ServletContextHandler@53cf9c99{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3ad85136{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@1d1cbd0f{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@ed91d8d{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@cda6019{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@fe34b86{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
stopping org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@41f4fe5
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 538 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@4bbb49b0
Stopped Spark web UI at http://quickstart.cloudera:4040
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 539 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 4 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 540 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 22 ms
triggerExecution took 22 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 541 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 19 ms
triggerExecution took 19 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 542 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 543 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
MapOutputTrackerMasterEndpoint stopped!
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 544 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 5 ms
triggerExecution took 5 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 545 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 546 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
MemoryStore cleared
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 547 to node 0
BlockManager stopped
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 4 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
BlockManagerMaster stopped
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 548 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
OutputCommitCoordinator stopped!
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 549 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 2 ms
triggerExecution took 2 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Successfully stopped SparkContext
Shutdown hook called
Deleting directory /tmp/spark-f4112699-0d80-4175-8379-4f322fe9c7b6
Deleting directory /tmp/temporary-eff64292-7140-4e50-bf8f-36f0b1bba8ad
Starting Trigger Calculation
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 550 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-4165db27-0fec-453d-a217-d9346d1c73c1--597276879-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 3 ms
triggerExecution took 3 ms
Execution stats: ExecutionStats(Map(),ArrayBuffer(),Map())
Deleting directory /tmp/temporaryReader-a6fe1e97-eda2-4cf8-add7-d196a1376262
2020-09-05 05:01:40.402 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 05:01:40.402 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 05:01:40.402 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 05:01:40.402 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
2020-09-05 05:01:40.402 : org.example.spark.POSmetricProcessing.Serde.JSONSerde - Started
Running Spark version 2.3.0
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[GetGroups])
UgiMetrics, User and group related metrics
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:610)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:277)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:265)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:810)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:780)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:653)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2464)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2464)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:292)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2486)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at org.example.spark.POSmetricProcessing.MetricProcessMain$.main(MetricProcessMain.scala:53)
	at org.example.spark.POSmetricProcessing.MetricProcessMain.main(MetricProcessMain.scala)
setsid exited with exit code 0
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
hadoop login
hadoop login commit
using local user:UnixPrincipal: cloudera
Using user: "UnixPrincipal: cloudera" with name cloudera
User entry: "cloudera"
Assuming keytab is managed externally since logged in from subject.
UGI loginUser:cloudera (auth:SIMPLE)
Submitted application: 8c147b89-a0e8-4fc5-8da1-a3f22ddc6e23
Changing view acls to: cloudera
Changing modify acls to: cloudera
Changing view acls groups to: 
Changing modify acls groups to: 
SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(cloudera); groups with view permissions: Set(); users  with modify permissions: Set(cloudera); groups with modify permissions: Set()
Created SSL options for fs: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Using SLF4J as the default logging framework
-Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
-Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
-Dio.netty.eventLoopThreads: 6
-Dio.netty.noUnsafe: false
Java version: 8
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Buffer.address: available
direct buffer constructor: available
java.nio.Bits.unaligned: available, true
jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
java.nio.DirectByteBuffer.<init>(long, int): available
sun.misc.Unsafe: available
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
-Dio.netty.maxDirectMemory: 2423783424 bytes
-Dio.netty.uninitializedArrayAllocationThreshold: -1
java.nio.ByteBuffer.cleaner(): available
-Dio.netty.noKeySetOptimization: false
-Dio.netty.selectorAutoRebuildThreshold: 512
org.jctools-core.MpscChunkedArrayQueue: available
-Dio.netty.leakDetection.level: simple
-Dio.netty.leakDetection.targetRecords: 4
-Dio.netty.allocator.numHeapArenas: 6
-Dio.netty.allocator.numDirectArenas: 6
-Dio.netty.allocator.pageSize: 8192
-Dio.netty.allocator.maxOrder: 11
-Dio.netty.allocator.chunkSize: 16777216
-Dio.netty.allocator.tinyCacheSize: 512
-Dio.netty.allocator.smallCacheSize: 256
-Dio.netty.allocator.normalCacheSize: 64
-Dio.netty.allocator.maxCachedBufferCapacity: 32768
-Dio.netty.allocator.cacheTrimInterval: 8192
-Dio.netty.allocator.useCacheForAllThreads: true
-Dio.netty.processId: 16926 (auto-detected)
-Djava.net.preferIPv4Stack: false
-Djava.net.preferIPv6Addresses: false
Loopback interface: lo (lo, 127.0.0.1)
/proc/sys/net/core/somaxconn: 128
-Dio.netty.machineId: 08:00:27:ff:fe:9e:c4:38 (auto-detected)
-Dio.netty.allocator.type: pooled
-Dio.netty.threadLocalDirectBufferSize: 65536
-Dio.netty.maxThreadLocalCharBufferSize: 16384
Shuffle server started on port: 33307
Successfully started service 'sparkDriver' on port 33307.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
init
Registering BlockManagerMaster
Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
BlockManagerMasterEndpoint up
Created local directory at /tmp/blockmgr-3b8d192e-589a-490c-9447-5d809362e5c9
Adding shutdown hook
Adding shutdown hook
MemoryStore started with capacity 1206.9 MB
Registering OutputCommitCoordinator
init
Created SSL options for ui: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
Logging initialized @11154ms
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2875b016
o.s.j.s.ServletContextHandler@23940f86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@66153688,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@66153688 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@87b5b49
o.s.j.s.ServletContextHandler@4a7a965d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@507b79f7,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@507b79f7 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@226eba67
o.s.j.s.ServletContextHandler@1cb7936c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@35342d2f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@35342d2f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-128c502c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@45667d98
o.s.j.s.ServletContextHandler@65eabaab{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7123be6c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7123be6c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1de9d54,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@70331432
o.s.j.s.ServletContextHandler@3bbf9027{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@10c2064a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@10c2064a added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-70e13fa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6ff415ad
o.s.j.s.ServletContextHandler@280d9edc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@28fd3dc1,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@28fd3dc1 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5432c277
o.s.j.s.ServletContextHandler@15e0fe05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1128620c,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1128620c added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6bf13698,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@299270eb
o.s.j.s.ServletContextHandler@3b90a30a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@69fa8e76,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@69fa8e76 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-bdd2027,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@f446158
o.s.j.s.ServletContextHandler@32f0c7f8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@504e1599,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@504e1599 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5d1b9c3d
o.s.j.s.ServletContextHandler@69e05f61{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@49a26d19,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@49a26d19 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-730e5763,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2babf189
o.s.j.s.ServletContextHandler@479f2dc2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@dab48d3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@dab48d3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7159a5cd
o.s.j.s.ServletContextHandler@4f966719{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@18ac53e8,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@18ac53e8 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c3177d5
o.s.j.s.ServletContextHandler@76f856a8{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7c853486,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7c853486 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-174e1b69,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@1046498a
o.s.j.s.ServletContextHandler@243f003c{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@71cb3139,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@71cb3139 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1639f93a,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@19b047fe
o.s.j.s.ServletContextHandler@22590e3e{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@53dad875,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@53dad875 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-5f780a86,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446c3920
o.s.j.s.ServletContextHandler@2eaef76d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@2b329bbd,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@2b329bbd added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34819867,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@72d0f2b4
o.s.j.s.ServletContextHandler@6d2dc9d2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@1da4b6b3,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@1da4b6b3 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7e1f584d
o.s.j.s.ServletContextHandler@7dff6d05{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@45d64d27,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@45d64d27 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-34fe326d,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36361ddb
o.s.j.s.ServletContextHandler@41fed14f{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4d6ee47,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4d6ee47 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c6da8bb
o.s.j.s.ServletContextHandler@3bae64d0{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@8b91134,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@8b91134 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1fba386c,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36b310aa
o.s.j.s.ServletContextHandler@76c387f9{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@3874b815,MANAGED}
HttpField encoders loaded: []
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@3874b815 added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-1a891add,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@d74bac4
o.s.j.s.ServletContextHandler@5ff90645{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@387bf2d9,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@387bf2d9 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c768ada
o.s.j.s.ServletContextHandler@c1fca2a{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@5533dc72,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-27ace0b1,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@58ec7116
o.s.j.s.ServletContextHandler@63bde6c2{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6ea04618,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6ea04618 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-6dd82486,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@36fcf6c0
o.s.j.s.ServletContextHandler@1aac188d{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@7026b7ee,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@7026b7ee added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-2d23faef,POJO}
org.spark_project.jetty.server.Server@3effd4f3 added {SparkUI{STOPPED,8<=0<=200,i=0,q=0},AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ErrorHandler@514cd540,AUTO}
org.spark_project.jetty.server.Server@3effd4f3 added {org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[],MANAGED}
starting org.spark_project.jetty.server.Server@3effd4f3
jetty-9.3.z-SNAPSHOT
starting org.spark_project.jetty.server.Server@3effd4f3
starting SparkUI{STOPPED,8<=0<=200,i=0,q=0}
STARTED @11761ms SparkUI{STARTED,8<=8<=200,i=7,q=0}
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STARTED @11762ms org.spark_project.jetty.server.handler.ErrorHandler@514cd540
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
starting org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
STARTED @11762ms org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[]
Started @11762ms
STARTED @11762ms org.spark_project.jetty.server.Server@3effd4f3
HttpConnectionFactory@5a8cbffe[HTTP/1.1] added {HttpConfiguration@96a75da{32768/8192,8192/8192,https://:0,[]},POJO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.server.Server@3effd4f3,UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {SparkUI{STARTED,8<=8<=200,i=8,q=0},UNMANAGED}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85,AUTO}
ServerConnector@3d7b1f1c{null,[]}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@1f44ddab,POJO}
ServerConnector@3d7b1f1c{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@5a8cbffe[HTTP/1.1],AUTO}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@5a8cbffe[HTTP/1.1]
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151,MANAGED}
starting ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0.0.0.0:4040],POJO}
starting org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STARTED @11808ms org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
starting HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STARTED @11809ms HttpConnectionFactory@5a8cbffe[HTTP/1.1]
starting org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151 added {org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1,AUTO}
starting org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
queue org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
run org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7f196f35 execute
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7f196f35 produce enter
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7f196f35 producing
Selector loop waiting on select
STARTED @11822ms org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
STARTED @11822ms org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@6aba5d30,POJO}
queue acceptor-0@6aba5d30
run acceptor-0@6aba5d30
Started ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STARTED @11833ms ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Successfully started service 'SparkUI' on port 4040.
org.spark_project.jetty.server.Server@3effd4f3 added {Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 mime types IncludeExclude@2eb917d0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c6b2dd9,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@73437222}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24 added {o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,UNMANAGED}
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@23940f86{/jobs,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e=org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@66153688
STARTED @11979ms org.spark_project.jetty.servlet.ServletHandler@66153688
starting org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @11987ms org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e@efd2d68f==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7c2b58c0 for org.apache.spark.ui.JettyUtils$$anon$3-537c8c7e
Started o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @11992ms o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}
STARTED @11992ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 mime types IncludeExclude@7bca6fac{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c60b0a0,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a2b1eb4}
org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5 added {o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c=org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@507b79f7
STARTED @12011ms org.spark_project.jetty.servlet.ServletHandler@507b79f7
starting org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12012ms org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c@d2093d9d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5833f5cd for org.apache.spark.ui.JettyUtils$$anon$3-64a9d48c
Started o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @12012ms o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}
STARTED @12013ms org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb mime types IncludeExclude@23f3dbf0{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@31d6f3fe,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@760cf594}
org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb added {o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-128c502c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-128c502c=org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@35342d2f
STARTED @12022ms org.spark_project.jetty.servlet.ServletHandler@35342d2f
starting org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12023ms org.apache.spark.ui.JettyUtils$$anon$3-128c502c@1d1aa344==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@aa149ed for org.apache.spark.ui.JettyUtils$$anon$3-128c502c
Started o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @12028ms o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}
STARTED @12028ms org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 mime types IncludeExclude@204e90f7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@20a05b32,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@165e389b}
org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309 added {o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1de9d54=org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7123be6c
STARTED @12036ms org.spark_project.jetty.servlet.ServletHandler@7123be6c
starting org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12036ms org.apache.spark.ui.JettyUtils$$anon$3-1de9d54@ab3f0730==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5c73f672 for org.apache.spark.ui.JettyUtils$$anon$3-1de9d54
Started o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @12041ms o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}
STARTED @12042ms org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 mime types IncludeExclude@2ab5afc7{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4dc8c0ea,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@e4b6f47}
org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23 added {o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-70e13fa=org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@10c2064a
STARTED @12052ms org.spark_project.jetty.servlet.ServletHandler@10c2064a
starting org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12052ms org.apache.spark.ui.JettyUtils$$anon$3-70e13fa@8fe4159d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@763cf5b9 for org.apache.spark.ui.JettyUtils$$anon$3-70e13fa
Started o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @12052ms o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}
STARTED @12053ms org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e mime types IncludeExclude@7a34f66a{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2f508f3c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3ed03652}
org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e added {o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7=org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
STARTED @12067ms org.spark_project.jetty.servlet.ServletHandler@28fd3dc1
starting org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12068ms org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7@7d0b5363==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4aedaf61 for org.apache.spark.ui.JettyUtils$$anon$3-5f9b6ae7
Started o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @12068ms o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}
STARTED @12068ms org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 mime types IncludeExclude@3c35c345{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3681037,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2459319c}
org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0 added {o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6bf13698=org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1128620c
STARTED @12071ms org.spark_project.jetty.servlet.ServletHandler@1128620c
starting org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12071ms org.apache.spark.ui.JettyUtils$$anon$3-6bf13698@5b6923a5==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ffaaaf0 for org.apache.spark.ui.JettyUtils$$anon$3-6bf13698
Started o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @12071ms o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}
STARTED @12071ms org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 mime types IncludeExclude@69a2b3b6{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4f3e7344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7808f638}
org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216 added {o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-bdd2027=org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@69fa8e76
STARTED @12087ms org.spark_project.jetty.servlet.ServletHandler@69fa8e76
starting org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12087ms org.apache.spark.ui.JettyUtils$$anon$3-bdd2027@cb3e54f9==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@62d73ead for org.apache.spark.ui.JettyUtils$$anon$3-bdd2027
Started o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @12087ms o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}
STARTED @12087ms org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 mime types IncludeExclude@228cea97{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@1d0a61c8,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@46731692}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42 added {o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb=org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@504e1599
STARTED @12099ms org.spark_project.jetty.servlet.ServletHandler@504e1599
starting org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12099ms org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb@a3abc483==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@782bf610 for org.apache.spark.ui.JettyUtils$$anon$3-71f96dfb
Started o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @12100ms o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}
STARTED @12100ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 mime types IncludeExclude@73fc518f{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2de50ee4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@ad9e63e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0 added {o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-730e5763 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-730e5763=org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@49a26d19
STARTED @12115ms org.spark_project.jetty.servlet.ServletHandler@49a26d19
starting org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12115ms org.apache.spark.ui.JettyUtils$$anon$3-730e5763@b3bd705c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@47fbc56 for org.apache.spark.ui.JettyUtils$$anon$3-730e5763
Started o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @12115ms o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}
STARTED @12115ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f mime types IncludeExclude@10895b16{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5524b72f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2cc03cd1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f added {o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c=org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@dab48d3
STARTED @12122ms org.spark_project.jetty.servlet.ServletHandler@dab48d3
starting org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12122ms org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c@338724d1==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e17913b for org.apache.spark.ui.JettyUtils$$anon$3-58a2b4c
Started o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @12123ms o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}
STARTED @12123ms org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 mime types IncludeExclude@64f16277{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@497aec8c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3b9632d1}
org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204 added {o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa=org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@18ac53e8
STARTED @12133ms org.spark_project.jetty.servlet.ServletHandler@18ac53e8
starting org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12134ms org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa@b87e5f8b==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4e6f2bb5 for org.apache.spark.ui.JettyUtils$$anon$3-4ca8dbfa
Started o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @12134ms o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}
STARTED @12134ms org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 mime types IncludeExclude@3f628ce9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@35e8316e,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@26d96e5}
org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5 added {o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-174e1b69=org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7c853486
STARTED @12142ms org.spark_project.jetty.servlet.ServletHandler@7c853486
starting org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12143ms org.apache.spark.ui.JettyUtils$$anon$3-174e1b69@1ee18297==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@336880df for org.apache.spark.ui.JettyUtils$$anon$3-174e1b69
Started o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @12143ms o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}
STARTED @12143ms org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f mime types IncludeExclude@6cd166b8{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2650f79,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@75fc1992}
org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f added {o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1639f93a=org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@71cb3139
STARTED @12152ms org.spark_project.jetty.servlet.ServletHandler@71cb3139
starting org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12153ms org.apache.spark.ui.JettyUtils$$anon$3-1639f93a@e5f1e218==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5fac521d for org.apache.spark.ui.JettyUtils$$anon$3-1639f93a
Started o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @12154ms o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}
STARTED @12154ms org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 mime types IncludeExclude@129bd55d{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7be7e15,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3abfe845}
org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6 added {o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@22590e3e{/environment,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-5f780a86=org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@53dad875
STARTED @12157ms org.spark_project.jetty.servlet.ServletHandler@53dad875
starting org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12157ms org.apache.spark.ui.JettyUtils$$anon$3-5f780a86@774f074d==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@7a0f244f for org.apache.spark.ui.JettyUtils$$anon$3-5f780a86
Started o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @12157ms o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}
STARTED @12157ms org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e mime types IncludeExclude@4248b963{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7f08caf,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4defd42}
org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e added {o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34819867 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34819867=org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@2b329bbd
STARTED @12163ms org.spark_project.jetty.servlet.ServletHandler@2b329bbd
starting org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12163ms org.apache.spark.ui.JettyUtils$$anon$3-34819867@53eacc26==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2330e3e0 for org.apache.spark.ui.JettyUtils$$anon$3-34819867
Started o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @12163ms o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}
STARTED @12164ms org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 mime types IncludeExclude@27a2a089{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@54657dd2,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@706eab5d}
org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544 added {o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece=org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
STARTED @12174ms org.spark_project.jetty.servlet.ServletHandler@1da4b6b3
starting org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12174ms org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece@7609eabd==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@72725ee1 for org.apache.spark.ui.JettyUtils$$anon$3-b2f4ece
Started o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @12174ms o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}
STARTED @12174ms org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece mime types IncludeExclude@3f9270ed{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3a230001,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@5ac6c4f2}
org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece added {o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-34fe326d=org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@45d64d27
STARTED @12180ms org.spark_project.jetty.servlet.ServletHandler@45d64d27
starting org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12180ms org.apache.spark.ui.JettyUtils$$anon$3-34fe326d@a543ae59==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2aa6311a for org.apache.spark.ui.JettyUtils$$anon$3-34fe326d
Started o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @12180ms o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}
STARTED @12180ms org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb mime types IncludeExclude@249e0271{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4893b344,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@53a665ad}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb added {o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3=org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4d6ee47
STARTED @12189ms org.spark_project.jetty.servlet.ServletHandler@4d6ee47
starting org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12191ms org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3@401e0a95==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@2c0b4c83 for org.apache.spark.ui.JettyUtils$$anon$3-a33b4e3
Started o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @12191ms o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}
STARTED @12191ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 mime types IncludeExclude@2d0ecb24{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4d654825,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@3bfc6a5e}
org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9 added {o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1fba386c=org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@8b91134
STARTED @12199ms org.spark_project.jetty.servlet.ServletHandler@8b91134
starting org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @12200ms org.apache.spark.ui.JettyUtils$$anon$3-1fba386c@236d3d52==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@51b35e4e for org.apache.spark.ui.JettyUtils$$anon$3-1fba386c
Started o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @12200ms o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}
STARTED @12200ms org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 mime types IncludeExclude@6d7cada5{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@350a94ce,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@7e00ed0f}
org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7 added {o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,UNMANAGED}
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@76c387f9{/static,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-1a891add from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-1a891add=org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@3874b815
STARTED @12204ms org.spark_project.jetty.servlet.ServletHandler@3874b815
starting org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @12204ms org.spark_project.jetty.servlet.DefaultServlet-1a891add@6c692bb0==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@b0fc838 for org.spark_project.jetty.servlet.DefaultServlet-1a891add
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar!/org/apache/spark/ui/static
Started o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @12225ms o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}
STARTED @12225ms org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff mime types IncludeExclude@57c47a9e{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@642505c7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@4339e0de}
org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff added {o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@5ff90645{/,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72=org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@387bf2d9
STARTED @12239ms org.spark_project.jetty.servlet.ServletHandler@387bf2d9
starting org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @12239ms org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72@3054abed==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@153cd6bb for org.apache.spark.ui.JettyUtils$$anon$4-74aa9c72
Started o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @12239ms o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}
STARTED @12239ms org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 mime types IncludeExclude@2d9f64c9{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@21ac5eb4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@52d6cd34}
org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08 added {o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@c1fca2a{/api,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false}
Adding Default404Servlet to org.spark_project.jetty.servlet.ServletHandler@5533dc72
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,AUTO}
org.spark_project.jetty.servlet.ServletHandler@5533dc72 added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a,POJO}
Chose path=/* mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-27ace0b1 from default=false
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/*=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, /=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
servletNameMap={org.glassfish.jersey.servlet.ServletContainer-27ace0b1=org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false}
starting org.spark_project.jetty.servlet.ServletHandler@5533dc72
STARTED @12255ms org.spark_project.jetty.servlet.ServletHandler@5533dc72
starting org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
STARTED @12255ms org.glassfish.jersey.servlet.ServletContainer-27ace0b1@2b93dfef==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false
starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
STARTED @12255ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6428591a@9440c9fc==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false
Started o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @12255ms o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}
STARTED @12255ms org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 mime types IncludeExclude@1abfe081{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@2a685eba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@c2e3264}
org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6 added {o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-6dd82486=org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6ea04618
STARTED @12261ms org.spark_project.jetty.servlet.ServletHandler@6ea04618
starting org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @12262ms org.apache.spark.ui.JettyUtils$$anon$4-6dd82486@b677828d==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@107f4980 for org.apache.spark.ui.JettyUtils$$anon$4-6dd82486
Started o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @12262ms o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}
STARTED @12262ms org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 mime types IncludeExclude@1d540566{i=[],ip=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@6014a9ba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/basic, audio/x-pn-realaudio, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime],ep=org.spark_project.jetty.util.IncludeExcludeSet$SetContainsPredicate@acdcf71}
org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6 added {o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark},MANAGED}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6] added {org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-2d23faef=org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@7026b7ee
STARTED @12268ms org.spark_project.jetty.servlet.ServletHandler@7026b7ee
starting org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
STARTED @12268ms org.apache.spark.ui.JettyUtils$$anon$4-2d23faef@c1725c5a==org.apache.spark.ui.JettyUtils$$anon$4,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$4@77d680e6 for org.apache.spark.ui.JettyUtils$$anon$4-2d23faef
Started o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @12269ms o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}
STARTED @12269ms org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6
Bound SparkUI to 0.0.0.0, and started at http://quickstart.cloudera:4040
Starting executor ID driver on host localhost
Shuffle server started on port: 46277
Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46277.
Server created on quickstart.cloudera:46277
Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
Registering BlockManager BlockManagerId(driver, quickstart.cloudera, 46277, None)
Got a request for quickstart.cloudera
Registering block manager quickstart.cloudera:46277 with 1206.9 MB RAM, BlockManagerId(driver, quickstart.cloudera, 46277, None)
Registered BlockManager BlockManagerId(driver, quickstart.cloudera, 46277, None)
Initialized BlockManager: BlockManagerId(driver, quickstart.cloudera, 46277, None)
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7b306b9f
o.s.j.s.ServletContextHandler@142213d5{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@934b52f,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@934b52f added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4=org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@934b52f
STARTED @14508ms org.spark_project.jetty.servlet.ServletHandler@934b52f
starting org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @14509ms org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4@4d53f23c==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@ff23ae7 for org.apache.spark.ui.JettyUtils$$anon$3-2630dbc4
Started o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
STARTED @14509ms o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}
Adding shutdown hook
Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/').
Warehouse path is 'file:/home/cloudera/IdeaProjects/POSmetricProcessing/spark-warehouse/'.
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@737d100a
o.s.j.s.ServletContextHandler@12e5da86{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@6535117e,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@6535117e added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6fa13e6
o.s.j.s.ServletContextHandler@3af7d855{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@77049094,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@77049094 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f=org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@6535117e
STARTED @15017ms org.spark_project.jetty.servlet.ServletHandler@6535117e
starting org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15017ms org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f@66358149==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@59bbe88a for org.apache.spark.ui.JettyUtils$$anon$3-1d1cbd0f
Started o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
STARTED @15017ms o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe=org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@77049094
STARTED @15036ms org.spark_project.jetty.servlet.ServletHandler@77049094
starting org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15036ms org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe@516c9f01==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@5d8ab698 for org.apache.spark.ui.JettyUtils$$anon$3-f88bfbe
Started o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
STARTED @15036ms o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@446626a7
o.s.j.s.ServletContextHandler@429f7919{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4a2929a4,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4a2929a4 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-cda6019,POJO}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@797c3c3b
o.s.j.s.ServletContextHandler@4012d5bc{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4375b013,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4375b013 added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-cda6019 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-cda6019=org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4a2929a4
STARTED @15040ms org.spark_project.jetty.servlet.ServletHandler@4a2929a4
starting org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15041ms org.apache.spark.ui.JettyUtils$$anon$3-cda6019@fffc1b16==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@4f5b08d for org.apache.spark.ui.JettyUtils$$anon$3-cda6019
Started o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
STARTED @15041ms o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
Chose path=/ mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc=org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4375b013
STARTED @15043ms org.spark_project.jetty.servlet.ServletHandler@4375b013
starting org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
STARTED @15043ms org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc@88f1df86==org.apache.spark.ui.JettyUtils$$anon$3,jsp=null,order=-1,inst=true
Servlet.init org.apache.spark.ui.JettyUtils$$anon$3@529c2a9a for org.apache.spark.ui.JettyUtils$$anon$3-1cf0cacc
Started o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
STARTED @15047ms o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}
Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@3c98781a
o.s.j.s.ServletContextHandler@3f736a16{/,null,null} added {org.spark_project.jetty.servlet.ServletHandler@4601203a,MANAGED}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,AUTO}
org.spark_project.jetty.servlet.ServletHandler@4601203a added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-53abfc07,POJO}
org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}] added {o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},UNMANAGED}
->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff,[o.s.j.s.ServletContextHandler@5ff90645{/,null,AVAILABLE,@Spark}]}]
storage/rdd->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5,[o.s.j.s.ServletContextHandler@76f856a8{/storage/rdd,null,AVAILABLE,@Spark}]}]
storage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f,[o.s.j.s.ServletContextHandler@479f2dc2{/storage,null,AVAILABLE,@Spark}]}]
storage/rdd/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f,[o.s.j.s.ServletContextHandler@243f003c{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
SQL/execution/json->[{o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
api->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08,[o.s.j.s.ServletContextHandler@c1fca2a{/api,null,AVAILABLE,@Spark}]}]
stages/pool/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0,[o.s.j.s.ServletContextHandler@69e05f61{/stages/pool/json,null,AVAILABLE,@Spark}]}]
stages/pool->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42,[o.s.j.s.ServletContextHandler@32f0c7f8{/stages/pool,null,AVAILABLE,@Spark}]}]
jobs/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5,[o.s.j.s.ServletContextHandler@4a7a965d{/jobs/json,null,AVAILABLE,@Spark}]}]
static->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7,[o.s.j.s.ServletContextHandler@76c387f9{/static,null,AVAILABLE,@Spark}]}]
executors/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece,[o.s.j.s.ServletContextHandler@7dff6d05{/executors/json,null,AVAILABLE,@Spark}]}]
stages/stage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216,[o.s.j.s.ServletContextHandler@3b90a30a{/stages/stage/json,null,AVAILABLE,@Spark}]}]
executors/threadDump/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9,[o.s.j.s.ServletContextHandler@3bae64d0{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
environment/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e,[o.s.j.s.ServletContextHandler@2eaef76d{/environment/json,null,AVAILABLE,@Spark}]}]
jobs/job/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309,[o.s.j.s.ServletContextHandler@65eabaab{/jobs/job/json,null,AVAILABLE,@Spark}]}]
jobs->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24,[o.s.j.s.ServletContextHandler@23940f86{/jobs,null,AVAILABLE,@Spark}]}]
stages/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e,[o.s.j.s.ServletContextHandler@280d9edc{/stages/json,null,AVAILABLE,@Spark}]}]
stages/stage->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0,[o.s.j.s.ServletContextHandler@15e0fe05{/stages/stage,null,AVAILABLE,@Spark}]}]
storage/json->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204,[o.s.j.s.ServletContextHandler@4f966719{/storage/json,null,AVAILABLE,@Spark}]}]
SQL->[{o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,AVAILABLE,@Spark}]}]
static/sql->[{o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark},[o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}]}]
stages/stage/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6,[o.s.j.s.ServletContextHandler@1aac188d{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
jobs/job->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb,[o.s.j.s.ServletContextHandler@1cb7936c{/jobs/job,null,AVAILABLE,@Spark}]}]
environment->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6,[o.s.j.s.ServletContextHandler@22590e3e{/environment,null,AVAILABLE,@Spark}]}]
stages->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23,[o.s.j.s.ServletContextHandler@3bbf9027{/stages,null,AVAILABLE,@Spark}]}]
executors->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544,[o.s.j.s.ServletContextHandler@6d2dc9d2{/executors,null,AVAILABLE,@Spark}]}]
SQL/json->[{o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,AVAILABLE,@Spark}]}]
jobs/job/kill->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6,[o.s.j.s.ServletContextHandler@63bde6c2{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
metrics/json->[{o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,AVAILABLE,@Spark}]}]
SQL/execution->[{o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,AVAILABLE,@Spark}]}]
executors/threadDump->[{org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb,[o.s.j.s.ServletContextHandler@41fed14f{/executors/threadDump,null,AVAILABLE,@Spark}]}]
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,null,@Spark}
starting o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,STARTING,@Spark}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
Chose path=/ mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-53abfc07 from default=false
filterNameMap={}
pathFilters=null
servletFilterMap=null
servletPathMap={/=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-53abfc07=org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true}
starting org.spark_project.jetty.servlet.ServletHandler@4601203a
STARTED @15054ms org.spark_project.jetty.servlet.ServletHandler@4601203a
starting org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
STARTED @15054ms org.spark_project.jetty.servlet.DefaultServlet-53abfc07@d2dfc752==org.spark_project.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true
Servlet.init org.spark_project.jetty.servlet.DefaultServlet@2c8c16c0 for org.spark_project.jetty.servlet.DefaultServlet-53abfc07
resource base = jar:file:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar!/org/apache/spark/sql/execution/ui/static
Started o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
STARTED @15055ms o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,AVAILABLE,@Spark}
Registered StateStoreCoordinator endpoint
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-a041dfda-d1ce-425f-a355-b9c7c2bd3164--2035041817-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-1, groupId=spark-kafka-source-a041dfda-d1ce-425f-a355-b9c7c2bd3164--2035041817-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599307308957
[Consumer clientId=consumer-1, groupId=spark-kafka-source-a041dfda-d1ce-425f-a355-b9c7c2bd3164--2035041817-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-1, groupId=spark-kafka-source-a041dfda-d1ce-425f-a355-b9c7c2bd3164--2035041817-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-a041dfda-d1ce-425f-a355-b9c7c2bd3164--2035041817-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Parsing command: CAST(value AS STRING)
Resolving 'value to value#8

=== Result of Batch Resolution ===
!'Project [unresolvedalias(cast('value as string), None)]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Cleanup ===
 Project [cast(value#8 as string) AS value#21]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Project [cast(value#8 as string) AS value#21]
 +- AnalysisBarrier                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              +- AnalysisBarrier
       +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]         +- StreamingRelationV2 org.apache.spark.sql.kafka010.KafkaSourceProvider@2becfd4c, kafka, Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092), [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], StreamingRelation DataSource(org.apache.spark.sql.SparkSession@5c59a0f7,kafka,List(),None,List(),None,Map(startingOffsets -> earliest, subscribe -> invoice, kafka.bootstrap.servers -> localhost:9092),None), kafka, [key#0, value#1, topic#2, partition#3, offset#4L, timestamp#5, timestampType#6]
          

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#24: java.lang.String   DeserializeToObject cast(value#21 as string).toString, obj#24: java.lang.String
 +- LocalRelation <empty>, [value#21]                                                                                                                                      +- LocalRelation <empty>, [value#21]
          
Expected a closure; got org.example.spark.POSmetricProcessing.hbaseUtils.invoiceWriter
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Starting [id = 096dc621-dfc3-4bf3-a839-0f0799fc8c54, runId = 84c76b9c-c8e4-4caf-8acc-29e3a10a96c1]. Use file:///tmp/temporary-73a6bc36-6f05-438c-8e20-c7e98335609e to store the query checkpoint.
source: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
source: Set auto.offset.reset to earliest, earlier value: 
source: Set enable.auto.commit to false, earlier value: 
source: Set max.poll.records to 1, earlier value: 
source: Set receive.buffer.bytes to 65536
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599307312837
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Kafka consumer initialized
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Subscribed to topic(s): invoice
executor: Set key.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set value.deserializer to org.apache.kafka.common.serialization.ByteArrayDeserializer, earlier value: 
executor: Set auto.offset.reset to none, earlier value: 
executor: Set group.id to spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-executor, earlier value: 
executor: Set enable.auto.commit to false, earlier value: 
executor: Set receive.buffer.bytes to 65536
Retrieved existing StateStoreCoordinator endpoint
Starting Trigger Calculation
Starting new streaming query.
PrivilegedAction as:cloudera (auth:SIMPLE) from:org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:331)
Unable to find batch file:/tmp/temporary-73a6bc36-6f05-438c-8e20-c7e98335609e/sources/0/0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Sending FindCoordinator request to broker localhost:9092 (id: -1 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initiating connection to node localhost:9092 (id: -1 rack: null) using address localhost/127.0.0.1
Added sensor with name node--1.bytes-sent
Added sensor with name node--1.bytes-received
Added sensor with name node--1.latency
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 124928, SO_TIMEOUT = 0 to node -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Completed connection to node -1. Fetching API versions.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initiating API versions fetch from node -1.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initiating API versions fetch from node -1.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v0 to send API_VERSIONS {} with correlation id 2 to node -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Recorded API versions for node -1: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], ListOffsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], FindCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0], DeleteRecords(21): UNSUPPORTED, InitProducerId(22): UNSUPPORTED, OffsetForLeaderEpoch(23): UNSUPPORTED, AddPartitionsToTxn(24): UNSUPPORTED, AddOffsetsToTxn(25): UNSUPPORTED, EndTxn(26): UNSUPPORTED, WriteTxnMarkers(27): UNSUPPORTED, TxnOffsetCommit(28): UNSUPPORTED, DescribeAcls(29): UNSUPPORTED, CreateAcls(30): UNSUPPORTED, DeleteAcls(31): UNSUPPORTED, DescribeConfigs(32): UNSUPPORTED, AlterConfigs(33): UNSUPPORTED, AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED, CreateDelegationToken(38): UNSUPPORTED, RenewDelegationToken(39): UNSUPPORTED, ExpireDelegationToken(40): UNSUPPORTED, DescribeDelegationToken(41): UNSUPPORTED, DeleteGroups(42): UNSUPPORTED, ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Sending metadata request MetadataRequestData(topics=[MetadataRequestTopic(name='invoice')], allowAutoTopicCreation=true, includeClusterAuthorizedOperations=false, includeTopicAuthorizedOperations=false) to node localhost:9092 (id: -1 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v2 to send METADATA {topics=[{name=invoice}]} with correlation id 3 to node -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v0 to send FIND_COORDINATOR {key=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0} with correlation id 0 to node -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Cluster ID: P7fOl109TKedvsjS1Ecocg
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Updated cluster metadata updateVersion 2 to MetadataCache{cluster=Cluster(id = P7fOl109TKedvsjS1Ecocg, nodes = [quickstart.cloudera:9092 (id: 0 rack: null)], partitions = [Partition(topic = invoice, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = quickstart.cloudera:9092 (id: 0 rack: null))}
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Received FindCoordinator response ClientResponse(receivedTimeMs=1599307314046, latencyMs=128, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=0, clientId=consumer-2, correlationId=0), responseBody=FindCoordinatorResponseData(throttleTimeMs=0, errorCode=0, errorMessage='', nodeId=0, host='quickstart.cloudera', port=9092))
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Discovered group coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initiating connection to node quickstart.cloudera:9092 (id: 2147483647 rack: null) using address quickstart.cloudera/10.0.2.15
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Revoking previously assigned partitions []
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Disabling heartbeat thread
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] (Re-)joining group
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Joining group with current subscription: [invoice]
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Heartbeat thread started
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Sending JoinGroup (JoinGroupRequestData(groupId='spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0', sessionTimeoutMs=10000, rebalanceTimeoutMs=300000, memberId='', groupInstanceId='null', protocolType='consumer', protocols=[JoinGroupRequestProtocol(name='range', metadata=[0, 0, 0, 0, 0, 1, 0, 7, 105, 110, 118, 111, 105, 99, 101, 0, 0, 0, 0])])) to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
Added sensor with name node-2147483647.bytes-sent
Added sensor with name node-2147483647.bytes-received
Added sensor with name node-2147483647.latency
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 124928, SO_TIMEOUT = 0 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Completed connection to node 2147483647. Fetching API versions.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initiating API versions fetch from node 2147483647.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initiating API versions fetch from node 2147483647.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v0 to send API_VERSIONS {} with correlation id 6 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Recorded API versions for node 2147483647: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], ListOffsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], FindCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0], DeleteRecords(21): UNSUPPORTED, InitProducerId(22): UNSUPPORTED, OffsetForLeaderEpoch(23): UNSUPPORTED, AddPartitionsToTxn(24): UNSUPPORTED, AddOffsetsToTxn(25): UNSUPPORTED, EndTxn(26): UNSUPPORTED, WriteTxnMarkers(27): UNSUPPORTED, TxnOffsetCommit(28): UNSUPPORTED, DescribeAcls(29): UNSUPPORTED, CreateAcls(30): UNSUPPORTED, DeleteAcls(31): UNSUPPORTED, DescribeConfigs(32): UNSUPPORTED, AlterConfigs(33): UNSUPPORTED, AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED, CreateDelegationToken(38): UNSUPPORTED, RenewDelegationToken(39): UNSUPPORTED, ExpireDelegationToken(40): UNSUPPORTED, DescribeDelegationToken(41): UNSUPPORTED, DeleteGroups(42): UNSUPPORTED, ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v1 to send JOIN_GROUP {group_id=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0,session_timeout_ms=10000,rebalance_timeout_ms=300000,member_id=,protocol_type=consumer,protocols=[{name=range,metadata=java.nio.HeapByteBuffer[pos=0 lim=19 cap=19]}]} with correlation id 4 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Received successful JoinGroup response: JoinGroupResponseData(throttleTimeMs=0, errorCode=0, generationId=1, protocolName='range', leader='consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d', memberId='consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d', members=[JoinGroupResponseMember(memberId='consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d', groupInstanceId='null', metadata=[0, 0, 0, 0, 0, 1, 0, 7, 105, 110, 118, 111, 105, 99, 101, 0, 0, 0, 0])])
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Performing assignment using strategy range with subscriptions {consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d=Subscription(topics=[invoice])}
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Finished assignment for group: {consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d=Assignment(partitions=[invoice-0])}
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Sending leader SyncGroup to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null): SyncGroupRequestData(groupId='spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0', generationId=1, memberId='consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d', groupInstanceId='null', assignments=[SyncGroupRequestAssignment(memberId='consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d', assignment=[0, 0, 0, 0, 0, 1, 0, 7, 105, 110, 118, 111, 105, 99, 101, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])])
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v0 to send SYNC_GROUP {group_id=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0,generation_id=1,member_id=consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d,assignments=[{member_id=consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d,assignment=java.nio.HeapByteBuffer[pos=0 lim=27 cap=27]}]} with correlation id 7 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Successfully joined group with generation 1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Enabling heartbeat thread
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Setting newly assigned partitions: invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Fetching committed offsets for partitions: [invoice-0]
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v2 to send OFFSET_FETCH {group_id=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0,topics=[{topic=invoice,partitions=[{partition=0}]}]} with correlation id 8 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Found no committed offset for partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -2, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initiating connection to node quickstart.cloudera:9092 (id: 0 rack: null) using address quickstart.cloudera/10.0.2.15
Added sensor with name node-0.bytes-sent
Added sensor with name node-0.bytes-received
Added sensor with name node-0.latency
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Created socket with SO_RCVBUF = 65536, SO_SNDBUF = 124928, SO_TIMEOUT = 0 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Completed connection to node 0. Fetching API versions.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initiating API versions fetch from node 0.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the beginning
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Seeking to EARLIEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -2, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Initiating API versions fetch from node 0.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v0 to send API_VERSIONS {} with correlation id 12 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Recorded API versions for node 0: (Produce(0): 0 to 2 [usable: 2], Fetch(1): 0 to 3 [usable: 3], ListOffsets(2): 0 to 1 [usable: 1], Metadata(3): 0 to 2 [usable: 2], LeaderAndIsr(4): 0 [usable: 0], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 3 [usable: 3], ControlledShutdown(7): 1 [usable: 1], OffsetCommit(8): 0 to 2 [usable: 2], OffsetFetch(9): 0 to 2 [usable: 2], FindCoordinator(10): 0 [usable: 0], JoinGroup(11): 0 to 1 [usable: 1], Heartbeat(12): 0 [usable: 0], LeaveGroup(13): 0 [usable: 0], SyncGroup(14): 0 [usable: 0], DescribeGroups(15): 0 [usable: 0], ListGroups(16): 0 [usable: 0], SaslHandshake(17): 0 [usable: 0], ApiVersions(18): 0 [usable: 0], CreateTopics(19): 0 to 1 [usable: 1], DeleteTopics(20): 0 [usable: 0], DeleteRecords(21): UNSUPPORTED, InitProducerId(22): UNSUPPORTED, OffsetForLeaderEpoch(23): UNSUPPORTED, AddPartitionsToTxn(24): UNSUPPORTED, AddOffsetsToTxn(25): UNSUPPORTED, EndTxn(26): UNSUPPORTED, WriteTxnMarkers(27): UNSUPPORTED, TxnOffsetCommit(28): UNSUPPORTED, DescribeAcls(29): UNSUPPORTED, CreateAcls(30): UNSUPPORTED, DeleteAcls(31): UNSUPPORTED, DescribeConfigs(32): UNSUPPORTED, AlterConfigs(33): UNSUPPORTED, AlterReplicaLogDirs(34): UNSUPPORTED, DescribeLogDirs(35): UNSUPPORTED, SaslAuthenticate(36): UNSUPPORTED, CreatePartitions(37): UNSUPPORTED, CreateDelegationToken(38): UNSUPPORTED, RenewDelegationToken(39): UNSUPPORTED, ExpireDelegationToken(40): UNSUPPORTED, DescribeDelegationToken(41): UNSUPPORTED, DeleteGroups(42): UNSUPPORTED, ElectPreferredLeaders(43): UNSUPPORTED, IncrementalAlterConfigs(44): UNSUPPORTED)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-2}]}]} with correlation id 9 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-2}]}]} with correlation id 11 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 0, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Resetting offset for partition invoice-0 to offset 0.
Got earliest offsets for partition : Map(invoice-0 -> 0)
Unable to find batch file:/tmp/temporary-73a6bc36-6f05-438c-8e20-c7e98335609e/sources/0/0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 0, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Skipping reset of partition invoice-0 since reset is no longer needed
Attempting to write log #file:/tmp/temporary-73a6bc36-6f05-438c-8e20-c7e98335609e/sources/0/0
Initial offsets: {"invoice":{"0":0}}
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Pausing partitions [invoice-0]
Partitions assigned to consumer: [invoice-0]. Seeking to the end.
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Seeking to LATEST offset of partition invoice-0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={invoice-0={timestamp: -1, maxNumOffsets: 1, currentLeaderEpoch: Optional[-1]}}, isolationLevel=READ_UNCOMMITTED) to broker quickstart.cloudera:9092 (id: 0 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v1 to send LIST_OFFSETS {replica_id=-1,topics=[{topic=invoice,partitions=[{partition=0,timestamp=-1}]}]} with correlation id 13 to node 0
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Handling ListOffsetResponse response for invoice-0. Fetched offset 34, timestamp -1
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Resetting offset for partition invoice-0 to offset 34.
Got latest offsets for partition : Map(invoice-0 -> 34)
GetOffset: ArrayBuffer((invoice-0,34))
getOffset took 1506 ms
Unable to find batch file:/tmp/temporary-73a6bc36-6f05-438c-8e20-c7e98335609e/offsets/0
Attempting to write log #file:/tmp/temporary-73a6bc36-6f05-438c-8e20-c7e98335609e/offsets/0
Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1599307314457,Map(spark.sql.shuffle.partitions -> 200, spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider))
walCommit took 112 ms
Stream running from {} to {KafkaSource[Subscribe[invoice]]: {"invoice":{"0":34}}}
GetBatch called with start = None, end = {"invoice":{"0":34}}
Partitions added: Map()
TopicPartitions: invoice-0
Sorted executors: 
+++ Cleaning closure <function1> (org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10) +++
 + declared fields: 1
     public static final long org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10.serialVersionUID
 + declared methods: 2
     public final java.lang.Object org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10.apply(java.lang.Object)
     public final org.apache.spark.sql.catalyst.InternalRow org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10.apply(org.apache.kafka.clients.consumer.ConsumerRecord)
 + inner classes: 0
 + outer classes: 0
 + outer objects: 0
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 0
 + there are no enclosing objects!
 +++ closure <function1> (org.apache.spark.sql.kafka010.KafkaSource$$anonfun$10) is now cleaned +++
GetBatch generating RDD of offset range: KafkaSourceRDDOffsetRange(invoice-0,0,34,None)
Retrieving data from KafkaSource[Subscribe[invoice]]: None -> {"invoice":{"0":34}}
getBatch took 712 ms
queryPlanning took 487 ms

=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#41: java.lang.String   DeserializeToObject cast(value#21 as string).toString, obj#41: java.lang.String
 +- LocalRelation <empty>, [value#21]                                                                                                                                      +- LocalRelation <empty>, [value#21]
          

/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private scala.collection.Iterator[] inputs;
/* 008 */   private scala.collection.Iterator inputadapter_input;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] project_mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */   private UnsafeRow[] project_mutableStateArray = new UnsafeRow[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     inputadapter_input = inputs[0];
/* 021 */     project_mutableStateArray[0] = new UnsafeRow(1);
/* 022 */     project_mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(project_mutableStateArray[0], 32);
/* 023 */     project_mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(project_mutableStateArray1[0], 1);
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   protected void processNext() throws java.io.IOException {
/* 028 */     while (inputadapter_input.hasNext() && !stopEarly()) {
/* 029 */       InternalRow inputadapter_row = (InternalRow) inputadapter_input.next();
/* 030 */       boolean inputadapter_isNull1 = inputadapter_row.isNullAt(1);
/* 031 */       byte[] inputadapter_value1 = inputadapter_isNull1 ? null : (inputadapter_row.getBinary(1));
/* 032 */       boolean project_isNull = inputadapter_isNull1;
/* 033 */       UTF8String project_value = null;
/* 034 */       if (!inputadapter_isNull1) {
/* 035 */         project_value = UTF8String.fromBytes(inputadapter_value1);
/* 036 */       }
/* 037 */       project_mutableStateArray1[0].reset();
/* 038 */
/* 039 */       project_mutableStateArray2[0].zeroOutNullBytes();
/* 040 */
/* 041 */       if (project_isNull) {
/* 042 */         project_mutableStateArray2[0].setNullAt(0);
/* 043 */       } else {
/* 044 */         project_mutableStateArray2[0].write(0, project_value);
/* 045 */       }
/* 046 */       project_mutableStateArray[0].setTotalSize(project_mutableStateArray1[0].totalSize());
/* 047 */       append(project_mutableStateArray[0]);
/* 048 */       if (shouldStop()) return;
/* 049 */     }
/* 050 */   }
/* 051 */
/* 052 */ }


/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
/* 007 */   private scala.collection.Iterator[] inputs;
/* 008 */   private scala.collection.Iterator inputadapter_input;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] project_mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] project_mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */   private UnsafeRow[] project_mutableStateArray = new UnsafeRow[1];
/* 012 */
/* 013 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 014 */     this.references = references;
/* 015 */   }
/* 016 */
/* 017 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 018 */     partitionIndex = index;
/* 019 */     this.inputs = inputs;
/* 020 */     inputadapter_input = inputs[0];
/* 021 */     project_mutableStateArray[0] = new UnsafeRow(1);
/* 022 */     project_mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(project_mutableStateArray[0], 32);
/* 023 */     project_mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(project_mutableStateArray1[0], 1);
/* 024 */
/* 025 */   }
/* 026 */
/* 027 */   protected void processNext() throws java.io.IOException {
/* 028 */     while (inputadapter_input.hasNext() && !stopEarly()) {
/* 029 */       InternalRow inputadapter_row = (InternalRow) inputadapter_input.next();
/* 030 */       boolean inputadapter_isNull1 = inputadapter_row.isNullAt(1);
/* 031 */       byte[] inputadapter_value1 = inputadapter_isNull1 ? null : (inputadapter_row.getBinary(1));
/* 032 */       boolean project_isNull = inputadapter_isNull1;
/* 033 */       UTF8String project_value = null;
/* 034 */       if (!inputadapter_isNull1) {
/* 035 */         project_value = UTF8String.fromBytes(inputadapter_value1);
/* 036 */       }
/* 037 */       project_mutableStateArray1[0].reset();
/* 038 */
/* 039 */       project_mutableStateArray2[0].zeroOutNullBytes();
/* 040 */
/* 041 */       if (project_isNull) {
/* 042 */         project_mutableStateArray2[0].setNullAt(0);
/* 043 */       } else {
/* 044 */         project_mutableStateArray2[0].write(0, project_value);
/* 045 */       }
/* 046 */       project_mutableStateArray[0].setTotalSize(project_mutableStateArray1[0].totalSize());
/* 047 */       append(project_mutableStateArray[0]);
/* 048 */       if (shouldStop()) return;
/* 049 */     }
/* 050 */   }
/* 051 */
/* 052 */ }

Code generated in 587.556214 ms
+++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10) +++
 + declared fields: 4
     public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.serialVersionUID
     private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.cleanedSource$2
     private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.references$1
     public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.durationMs$1
 + declared methods: 2
     public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.apply(java.lang.Object,java.lang.Object)
     public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10.apply(int,scala.collection.Iterator)
 + inner classes: 1
     org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10$$anon$1
 + outer classes: 0
 + outer objects: 0
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 0
 + there are no enclosing objects!
 +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$10) is now cleaned +++
+++ Cleaning closure <function1> (org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1) +++
 + declared fields: 4
     public static final long org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.serialVersionUID
     private final org.apache.spark.sql.execution.streaming.ForeachSink org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.$outer
     private final long org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.batchId$1
     private final org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.encoder$1
 + declared methods: 2
     public final java.lang.Object org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(java.lang.Object)
     public final void org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(scala.collection.Iterator)
 + inner classes: 0
 + outer classes: 1
     org.apache.spark.sql.execution.streaming.ForeachSink
 + outer objects: 1
     ForeachSink
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 2
     (class org.apache.spark.sql.execution.streaming.ForeachSink,Set(org$apache$spark$sql$execution$streaming$ForeachSink$$writer))
     (class java.lang.Object,Set())
 + outermost object is not a closure or REPL line object, so do not clone it: (class org.apache.spark.sql.execution.streaming.ForeachSink,ForeachSink)
 +++ closure <function1> (org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1) is now cleaned +++
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Sending Heartbeat request to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v0 to send HEARTBEAT {group_id=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0,generation_id=1,member_id=consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d} with correlation id 14 to node 2147483647
+++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29) +++
 + declared fields: 2
     public static final long org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.serialVersionUID
     private final scala.Function1 org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.cleanF$6
 + declared methods: 2
     public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(java.lang.Object)
     public final void org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(scala.collection.Iterator)
 + inner classes: 0
 + outer classes: 0
 + outer objects: 0
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 0
 + there are no enclosing objects!
 +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29) is now cleaned +++
+++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
 + declared fields: 2
     public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
     private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
 + declared methods: 2
     public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
     public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
 + inner classes: 0
 + outer classes: 0
 + outer objects: 0
 + populating accessed fields because this is the starting closure
 + fields accessed by starting closure: 0
 + there are no enclosing objects!
 +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
Starting job: start at MetricProcessMain.scala:63
Got job 0 (start at MetricProcessMain.scala:63) with 1 output partitions
Final stage: ResultStage 0 (start at MetricProcessMain.scala:63)
Parents of final stage: List()
Missing parents: List()
submitStage(ResultStage 0)
missing: List()
Submitting ResultStage 0 (MapPartitionsRDD[3] at start at MetricProcessMain.scala:63), which has no missing parents
submitMissingTasks(ResultStage 0)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Received successful Heartbeat response
Block broadcast_0 stored as values in memory (estimated size 11.5 KB, free 1206.9 MB)
Put block broadcast_0 locally took  114 ms
Putting block broadcast_0 without replication took  122 ms
Block broadcast_0_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1206.9 MB)
Added broadcast_0_piece0 in memory on quickstart.cloudera:46277 (size: 6.0 KB, free: 1206.9 MB)
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Put block broadcast_0_piece0 locally took  34 ms
Putting block broadcast_0_piece0 without replication took  35 ms
Created broadcast 0 from broadcast at DAGScheduler.scala:1039
Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at start at MetricProcessMain.scala:63) (first 15 tasks are for partitions Vector(0))
Adding task set 0.0 with 1 tasks
Epoch for TaskSet 0.0: 0
Valid locality levels for TaskSet 0.0: NO_PREF, ANY
parentName: , name: TaskSet_0.0, runningTasks: 0
Valid locality levels for TaskSet 0.0: NO_PREF, ANY
Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8030 bytes)
Running task 0.0 in stage 0.0 (TID 0)
Getting local block broadcast_0
Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-executor
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[Consumer clientId=consumer-3, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-executor] Initializing the Kafka consumer
Added sensor with name fetch-throttle-time
Added sensor with name connections-closed:
Added sensor with name connections-created:
Added sensor with name successful-authentication:
Added sensor with name successful-reauthentication:
Added sensor with name successful-authentication-no-reauth:
Added sensor with name failed-authentication:
Added sensor with name failed-reauthentication:
Added sensor with name reauthentication-latency:
Added sensor with name bytes-sent-received:
Added sensor with name bytes-sent:
Added sensor with name bytes-received:
Added sensor with name select-time:
Added sensor with name io-time:
Added sensor with name heartbeat-latency
Added sensor with name join-latency
Added sensor with name sync-latency
Added sensor with name commit-latency
Added sensor with name bytes-fetched
Added sensor with name records-fetched
Added sensor with name fetch-latency
Added sensor with name records-lag
Added sensor with name records-lead
Kafka version: 2.3.0
Kafka commitId: fc1aaa116b661c8a
Kafka startTimeMs: 1599307318264
[Consumer clientId=consumer-3, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-executor] Kafka consumer initialized
[Consumer clientId=consumer-3, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-executor] Subscribed to partition(s): invoice-0
code for input[0, binary, true],input[1, binary, true],input[2, string, true],input[3, int, true],input[4, bigint, true],input[5, timestamp, true],input[6, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private UnsafeRow[] mutableStateArray = new UnsafeRow[1];
/* 011 */
/* 012 */   public SpecificUnsafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableStateArray[0] = new UnsafeRow(7);
/* 015 */     mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(mutableStateArray[0], 96);
/* 016 */     mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray1[0], 7);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray1[0].reset();
/* 031 */
/* 032 */     mutableStateArray2[0].zeroOutNullBytes();
/* 033 */     writeFields_0(i);
/* 034 */     writeFields_1(i);
/* 035 */     mutableStateArray[0].setTotalSize(mutableStateArray1[0].totalSize());
/* 036 */     return mutableStateArray[0];
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_1(InternalRow i) {
/* 041 */
/* 042 */
/* 043 */     boolean isNull4 = i.isNullAt(4);
/* 044 */     long value4 = isNull4 ? -1L : (i.getLong(4));
/* 045 */     if (isNull4) {
/* 046 */       mutableStateArray2[0].setNullAt(4);
/* 047 */     } else {
/* 048 */       mutableStateArray2[0].write(4, value4);
/* 049 */     }
/* 050 */
/* 051 */
/* 052 */     boolean isNull5 = i.isNullAt(5);
/* 053 */     long value5 = isNull5 ? -1L : (i.getLong(5));
/* 054 */     if (isNull5) {
/* 055 */       mutableStateArray2[0].setNullAt(5);
/* 056 */     } else {
/* 057 */       mutableStateArray2[0].write(5, value5);
/* 058 */     }
/* 059 */
/* 060 */
/* 061 */     boolean isNull6 = i.isNullAt(6);
/* 062 */     int value6 = isNull6 ? -1 : (i.getInt(6));
/* 063 */     if (isNull6) {
/* 064 */       mutableStateArray2[0].setNullAt(6);
/* 065 */     } else {
/* 066 */       mutableStateArray2[0].write(6, value6);
/* 067 */     }
/* 068 */
/* 069 */   }
/* 070 */
/* 071 */
/* 072 */   private void writeFields_0(InternalRow i) {
/* 073 */
/* 074 */
/* 075 */     boolean isNull = i.isNullAt(0);
/* 076 */     byte[] value = isNull ? null : (i.getBinary(0));
/* 077 */     if (isNull) {
/* 078 */       mutableStateArray2[0].setNullAt(0);
/* 079 */     } else {
/* 080 */       mutableStateArray2[0].write(0, value);
/* 081 */     }
/* 082 */
/* 083 */
/* 084 */     boolean isNull1 = i.isNullAt(1);
/* 085 */     byte[] value1 = isNull1 ? null : (i.getBinary(1));
/* 086 */     if (isNull1) {
/* 087 */       mutableStateArray2[0].setNullAt(1);
/* 088 */     } else {
/* 089 */       mutableStateArray2[0].write(1, value1);
/* 090 */     }
/* 091 */
/* 092 */
/* 093 */     boolean isNull2 = i.isNullAt(2);
/* 094 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(2));
/* 095 */     if (isNull2) {
/* 096 */       mutableStateArray2[0].setNullAt(2);
/* 097 */     } else {
/* 098 */       mutableStateArray2[0].write(2, value2);
/* 099 */     }
/* 100 */
/* 101 */
/* 102 */     boolean isNull3 = i.isNullAt(3);
/* 103 */     int value3 = isNull3 ? -1 : (i.getInt(3));
/* 104 */     if (isNull3) {
/* 105 */       mutableStateArray2[0].setNullAt(3);
/* 106 */     } else {
/* 107 */       mutableStateArray2[0].write(3, value3);
/* 108 */     }
/* 109 */
/* 110 */   }
/* 111 */
/* 112 */ }


/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[] mutableStateArray1 = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder[1];
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray2 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private UnsafeRow[] mutableStateArray = new UnsafeRow[1];
/* 011 */
/* 012 */   public SpecificUnsafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */     mutableStateArray[0] = new UnsafeRow(7);
/* 015 */     mutableStateArray1[0] = new org.apache.spark.sql.catalyst.expressions.codegen.BufferHolder(mutableStateArray[0], 96);
/* 016 */     mutableStateArray2[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(mutableStateArray1[0], 7);
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   public void initialize(int partitionIndex) {
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   // Scala.Function1 need this
/* 025 */   public java.lang.Object apply(java.lang.Object row) {
/* 026 */     return apply((InternalRow) row);
/* 027 */   }
/* 028 */
/* 029 */   public UnsafeRow apply(InternalRow i) {
/* 030 */     mutableStateArray1[0].reset();
/* 031 */
/* 032 */     mutableStateArray2[0].zeroOutNullBytes();
/* 033 */     writeFields_0(i);
/* 034 */     writeFields_1(i);
/* 035 */     mutableStateArray[0].setTotalSize(mutableStateArray1[0].totalSize());
/* 036 */     return mutableStateArray[0];
/* 037 */   }
/* 038 */
/* 039 */
/* 040 */   private void writeFields_1(InternalRow i) {
/* 041 */
/* 042 */
/* 043 */     boolean isNull4 = i.isNullAt(4);
/* 044 */     long value4 = isNull4 ? -1L : (i.getLong(4));
/* 045 */     if (isNull4) {
/* 046 */       mutableStateArray2[0].setNullAt(4);
/* 047 */     } else {
/* 048 */       mutableStateArray2[0].write(4, value4);
/* 049 */     }
/* 050 */
/* 051 */
/* 052 */     boolean isNull5 = i.isNullAt(5);
/* 053 */     long value5 = isNull5 ? -1L : (i.getLong(5));
/* 054 */     if (isNull5) {
/* 055 */       mutableStateArray2[0].setNullAt(5);
/* 056 */     } else {
/* 057 */       mutableStateArray2[0].write(5, value5);
/* 058 */     }
/* 059 */
/* 060 */
/* 061 */     boolean isNull6 = i.isNullAt(6);
/* 062 */     int value6 = isNull6 ? -1 : (i.getInt(6));
/* 063 */     if (isNull6) {
/* 064 */       mutableStateArray2[0].setNullAt(6);
/* 065 */     } else {
/* 066 */       mutableStateArray2[0].write(6, value6);
/* 067 */     }
/* 068 */
/* 069 */   }
/* 070 */
/* 071 */
/* 072 */   private void writeFields_0(InternalRow i) {
/* 073 */
/* 074 */
/* 075 */     boolean isNull = i.isNullAt(0);
/* 076 */     byte[] value = isNull ? null : (i.getBinary(0));
/* 077 */     if (isNull) {
/* 078 */       mutableStateArray2[0].setNullAt(0);
/* 079 */     } else {
/* 080 */       mutableStateArray2[0].write(0, value);
/* 081 */     }
/* 082 */
/* 083 */
/* 084 */     boolean isNull1 = i.isNullAt(1);
/* 085 */     byte[] value1 = isNull1 ? null : (i.getBinary(1));
/* 086 */     if (isNull1) {
/* 087 */       mutableStateArray2[0].setNullAt(1);
/* 088 */     } else {
/* 089 */       mutableStateArray2[0].write(1, value1);
/* 090 */     }
/* 091 */
/* 092 */
/* 093 */     boolean isNull2 = i.isNullAt(2);
/* 094 */     UTF8String value2 = isNull2 ? null : (i.getUTF8String(2));
/* 095 */     if (isNull2) {
/* 096 */       mutableStateArray2[0].setNullAt(2);
/* 097 */     } else {
/* 098 */       mutableStateArray2[0].write(2, value2);
/* 099 */     }
/* 100 */
/* 101 */
/* 102 */     boolean isNull3 = i.isNullAt(3);
/* 103 */     int value3 = isNull3 ? -1 : (i.getInt(3));
/* 104 */     if (isNull3) {
/* 105 */       mutableStateArray2[0].setNullAt(3);
/* 106 */     } else {
/* 107 */       mutableStateArray2[0].write(3, value3);
/* 108 */     }
/* 109 */
/* 110 */   }
/* 111 */
/* 112 */ }

Code generated in 103.965249 ms
Process identifier=hconnection-0x1ee3034b connecting to ZooKeeper ensemble=localhost:2181
Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
Client environment:host.name=quickstart.cloudera
Client environment:java.version=1.8.0_60
Client environment:java.vendor=Oracle Corporation
Client environment:java.home=/usr/java/jdk1.8.0_60/jre
Client environment:java.class.path=/usr/java/jdk1.8.0_60/jre/lib/charsets.jar:/usr/java/jdk1.8.0_60/jre/lib/deploy.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/cldrdata.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/dnsns.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/jaccess.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/jfxrt.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/localedata.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/nashorn.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/sunec.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/sunjce_provider.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/sunpkcs11.jar:/usr/java/jdk1.8.0_60/jre/lib/ext/zipfs.jar:/usr/java/jdk1.8.0_60/jre/lib/javaws.jar:/usr/java/jdk1.8.0_60/jre/lib/jce.jar:/usr/java/jdk1.8.0_60/jre/lib/jfr.jar:/usr/java/jdk1.8.0_60/jre/lib/jfxswt.jar:/usr/java/jdk1.8.0_60/jre/lib/jsse.jar:/usr/java/jdk1.8.0_60/jre/lib/management-agent.jar:/usr/java/jdk1.8.0_60/jre/lib/plugin.jar:/usr/java/jdk1.8.0_60/jre/lib/resources.jar:/usr/java/jdk1.8.0_60/jre/lib/rt.jar:/home/cloudera/IdeaProjects/POSmetricProcessing/target/classes:/home/cloudera/.m2/repository/com/google/guava/guava/19.0/guava-19.0.jar:/home/cloudera/.m2/repository/io/netty/netty-all/4.1.17.Final/netty-all-4.1.17.Final.jar:/home/cloudera/.m2/repository/org/scala-lang/scala-library/2.11.8/scala-library-2.11.8.jar:/home/cloudera/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/cloudera/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.11/2.9.8/jackson-module-scala_2.11-2.9.8.jar:/home/cloudera/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.9.8/jackson-core-2.9.8.jar:/home/cloudera/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.9.8/jackson-annotations-2.9.8.jar:/home/cloudera/.m2/repository/com/fasterxml/jackson/module/jackson-module-paranamer/2.9.8/jackson-module-paranamer-2.9.8.jar:/home/cloudera/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar:/home/cloudera/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.9.10.4/jackson-databind-2.9.10.4.jar:/home/cloudera/.m2/repository/sc/ala/kafka-utils_2.11/0.1.1/kafka-utils_2.11-0.1.1.jar:/home/cloudera/.m2/repository/org/apache/kafka/kafka_2.11/0.8.2.1/kafka_2.11-0.8.2.1.jar:/home/cloudera/.m2/repository/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar:/home/cloudera/.m2/repository/net/sf/jopt-simple/jopt-simple/3.2/jopt-simple-3.2.jar:/home/cloudera/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar:/home/cloudera/.m2/repository/com/101tec/zkclient/0.3/zkclient-0.3.jar:/home/cloudera/.m2/repository/sc/ala/rubyist_2.11/0.2.6/rubyist_2.11-0.2.6.jar:/home/cloudera/.m2/repository/org/scala-lang/scala-compiler/2.11.7/scala-compiler-2.11.7.jar:/home/cloudera/.m2/repository/pl/project13/scala/rainbow_2.11/0.2/rainbow_2.11-0.2.jar:/home/cloudera/.m2/repository/org/apache/kafka/kafka-clients/2.3.0/kafka-clients-2.3.0.jar:/home/cloudera/.m2/repository/com/github/luben/zstd-jni/1.4.0-1/zstd-jni-1.4.0-1.jar:/home/cloudera/.m2/repository/org/lz4/lz4-java/1.6.0/lz4-java-1.6.0.jar:/home/cloudera/.m2/repository/org/xerial/snappy/snappy-java/1.1.7.3/snappy-java-1.1.7.3.jar:/home/cloudera/.m2/repository/org/slf4j/slf4j-api/1.7.26/slf4j-api-1.7.26.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-client/2.7.7/hadoop-client-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-common/2.7.7/hadoop-common-2.7.7.jar:/home/cloudera/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/cloudera/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/cloudera/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/home/cloudera/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/cloudera/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26/jetty-sslengine-6.1.26.jar:/home/cloudera/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/home/cloudera/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/cloudera/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/cloudera/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/cloudera/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/cloudera/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/cloudera/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar:/home/cloudera/.m2/repository/org/apache/curator/curator-client/2.7.1/curator-client-2.7.1.jar:/home/cloudera/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/home/cloudera/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.7.7/hadoop-hdfs-2.7.7.jar:/home/cloudera/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/cloudera/.m2/repository/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar:/home/cloudera/.m2/repository/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar:/home/cloudera/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.7.7/hadoop-mapreduce-client-app-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.7.7/hadoop-mapreduce-client-common-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.7.7/hadoop-yarn-client-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.7.7/hadoop-yarn-server-common-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.7.7/hadoop-mapreduce-client-shuffle-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.7.7/hadoop-yarn-api-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.7.7/hadoop-mapreduce-client-core-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.7.7/hadoop-yarn-common-2.7.7.jar:/home/cloudera/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/home/cloudera/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/home/cloudera/.m2/repository/javax/servlet/servlet-api/2.5/servlet-api-2.5.jar:/home/cloudera/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/home/cloudera/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/home/cloudera/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/cloudera/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.7.7/hadoop-mapreduce-client-jobclient-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-annotations/2.7.7/hadoop-annotations-2.7.7.jar:/home/cloudera/.m2/repository/org/apache/hbase/hbase-client/1.2.0/hbase-client-1.2.0.jar:/home/cloudera/.m2/repository/org/apache/hbase/hbase-annotations/1.2.0/hbase-annotations-1.2.0.jar:/home/cloudera/.m2/repository/org/apache/hbase/hbase-common/1.2.0/hbase-common-1.2.0.jar:/home/cloudera/.m2/repository/org/apache/hbase/hbase-protocol/1.2.0/hbase-protocol-1.2.0.jar:/home/cloudera/.m2/repository/commons-codec/commons-codec/1.9/commons-codec-1.9.jar:/home/cloudera/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/home/cloudera/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/cloudera/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/cloudera/.m2/repository/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar:/home/cloudera/.m2/repository/org/apache/htrace/htrace-core/3.1.0-incubating/htrace-core-3.1.0-incubating.jar:/home/cloudera/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/cloudera/.m2/repository/org/jruby/jcodings/jcodings/1.0.8/jcodings-1.0.8.jar:/home/cloudera/.m2/repository/org/jruby/joni/joni/2.1.2/joni-2.1.2.jar:/home/cloudera/.m2/repository/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar:/home/cloudera/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.1/hadoop-auth-2.5.1.jar:/home/cloudera/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/home/cloudera/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/home/cloudera/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/home/cloudera/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/home/cloudera/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/home/cloudera/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/home/cloudera/.m2/repository/junit/junit/4.12/junit-4.12.jar:/home/cloudera/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-core_2.11/2.3.0/spark-core_2.11-2.3.0.jar:/home/cloudera/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/cloudera/.m2/repository/org/apache/avro/avro-mapred/1.7.7/avro-mapred-1.7.7-hadoop2.jar:/home/cloudera/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7.jar:/home/cloudera/.m2/repository/org/apache/avro/avro-ipc/1.7.7/avro-ipc-1.7.7-tests.jar:/home/cloudera/.m2/repository/com/twitter/chill_2.11/0.8.4/chill_2.11-0.8.4.jar:/home/cloudera/.m2/repository/com/esotericsoftware/kryo-shaded/3.0.3/kryo-shaded-3.0.3.jar:/home/cloudera/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar:/home/cloudera/.m2/repository/org/objenesis/objenesis/2.1/objenesis-2.1.jar:/home/cloudera/.m2/repository/com/twitter/chill-java/0.8.4/chill-java-0.8.4.jar:/home/cloudera/.m2/repository/org/apache/xbean/xbean-asm5-shaded/4.4/xbean-asm5-shaded-4.4.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-launcher_2.11/2.3.0/spark-launcher_2.11-2.3.0.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-kvstore_2.11/2.3.0/spark-kvstore_2.11-2.3.0.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-network-common_2.11/2.3.0/spark-network-common_2.11-2.3.0.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-network-shuffle_2.11/2.3.0/spark-network-shuffle_2.11-2.3.0.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-unsafe_2.11/2.3.0/spark-unsafe_2.11-2.3.0.jar:/home/cloudera/.m2/repository/net/java/dev/jets3t/jets3t/0.9.4/jets3t-0.9.4.jar:/home/cloudera/.m2/repository/org/apache/httpcomponents/httpcore/4.4.1/httpcore-4.4.1.jar:/home/cloudera/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/cloudera/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.52/bcprov-jdk15on-1.52.jar:/home/cloudera/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/1.1/java-xmlbuilder-1.1.jar:/home/cloudera/.m2/repository/net/iharder/base64/2.3.8/base64-2.3.8.jar:/home/cloudera/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/home/cloudera/.m2/repository/org/apache/curator/curator-framework/2.6.0/curator-framework-2.6.0.jar:/home/cloudera/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/cloudera/.m2/repository/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.jar:/home/cloudera/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar:/home/cloudera/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/cloudera/.m2/repository/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar:/home/cloudera/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar:/home/cloudera/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/home/cloudera/.m2/repository/org/slf4j/slf4j-log4j12/1.7.16/slf4j-log4j12-1.7.16.jar:/home/cloudera/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar:/home/cloudera/.m2/repository/org/roaringbitmap/RoaringBitmap/0.5.11/RoaringBitmap-0.5.11.jar:/home/cloudera/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/home/cloudera/.m2/repository/org/json4s/json4s-jackson_2.11/3.2.11/json4s-jackson_2.11-3.2.11.jar:/home/cloudera/.m2/repository/org/json4s/json4s-core_2.11/3.2.11/json4s-core_2.11-3.2.11.jar:/home/cloudera/.m2/repository/org/json4s/json4s-ast_2.11/3.2.11/json4s-ast_2.11-3.2.11.jar:/home/cloudera/.m2/repository/org/scala-lang/scalap/2.11.0/scalap-2.11.0.jar:/home/cloudera/.m2/repository/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar:/home/cloudera/.m2/repository/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar:/home/cloudera/.m2/repository/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar:/home/cloudera/.m2/repository/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar:/home/cloudera/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar:/home/cloudera/.m2/repository/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar:/home/cloudera/.m2/repository/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar:/home/cloudera/.m2/repository/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar:/home/cloudera/.m2/repository/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar:/home/cloudera/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/cloudera/.m2/repository/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar:/home/cloudera/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar:/home/cloudera/.m2/repository/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar:/home/cloudera/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar:/home/cloudera/.m2/repository/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar:/home/cloudera/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.22.2/jersey-container-servlet-2.22.2.jar:/home/cloudera/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar:/home/cloudera/.m2/repository/io/netty/netty/3.9.9.Final/netty-3.9.9.Final.jar:/home/cloudera/.m2/repository/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar:/home/cloudera/.m2/repository/io/dropwizard/metrics/metrics-core/3.1.5/metrics-core-3.1.5.jar:/home/cloudera/.m2/repository/io/dropwizard/metrics/metrics-jvm/3.1.5/metrics-jvm-3.1.5.jar:/home/cloudera/.m2/repository/io/dropwizard/metrics/metrics-json/3.1.5/metrics-json-3.1.5.jar:/home/cloudera/.m2/repository/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar:/home/cloudera/.m2/repository/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar:/home/cloudera/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/cloudera/.m2/repository/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar:/home/cloudera/.m2/repository/net/sf/py4j/py4j/0.10.6/py4j-0.10.6.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-tags_2.11/2.3.0/spark-tags_2.11-2.3.0.jar:/home/cloudera/.m2/repository/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar:/home/cloudera/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-sql_2.11/2.3.0/spark-sql_2.11-2.3.0.jar:/home/cloudera/.m2/repository/com/univocity/univocity-parsers/2.5.9/univocity-parsers-2.5.9.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-sketch_2.11/2.3.0/spark-sketch_2.11-2.3.0.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-catalyst_2.11/2.3.0/spark-catalyst_2.11-2.3.0.jar:/home/cloudera/.m2/repository/org/scala-lang/scala-reflect/2.11.8/scala-reflect-2.11.8.jar:/home/cloudera/.m2/repository/org/codehaus/janino/janino/3.0.8/janino-3.0.8.jar:/home/cloudera/.m2/repository/org/codehaus/janino/commons-compiler/3.0.8/commons-compiler-3.0.8.jar:/home/cloudera/.m2/repository/org/antlr/antlr4-runtime/4.7/antlr4-runtime-4.7.jar:/home/cloudera/.m2/repository/org/apache/orc/orc-core/1.4.1/orc-core-1.4.1-nohive.jar:/home/cloudera/.m2/repository/io/airlift/aircompressor/0.8/aircompressor-0.8.jar:/home/cloudera/.m2/repository/org/apache/orc/orc-mapreduce/1.4.1/orc-mapreduce-1.4.1-nohive.jar:/home/cloudera/.m2/repository/org/apache/parquet/parquet-column/1.8.2/parquet-column-1.8.2.jar:/home/cloudera/.m2/repository/org/apache/parquet/parquet-common/1.8.2/parquet-common-1.8.2.jar:/home/cloudera/.m2/repository/org/apache/parquet/parquet-encoding/1.8.2/parquet-encoding-1.8.2.jar:/home/cloudera/.m2/repository/org/apache/parquet/parquet-hadoop/1.8.2/parquet-hadoop-1.8.2.jar:/home/cloudera/.m2/repository/org/apache/parquet/parquet-format/2.3.1/parquet-format-2.3.1.jar:/home/cloudera/.m2/repository/org/apache/parquet/parquet-jackson/1.8.2/parquet-jackson-1.8.2.jar:/home/cloudera/.m2/repository/org/apache/arrow/arrow-vector/0.8.0/arrow-vector-0.8.0.jar:/home/cloudera/.m2/repository/org/apache/arrow/arrow-format/0.8.0/arrow-format-0.8.0.jar:/home/cloudera/.m2/repository/org/apache/arrow/arrow-memory/0.8.0/arrow-memory-0.8.0.jar:/home/cloudera/.m2/repository/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar:/home/cloudera/.m2/repository/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar:/home/cloudera/.m2/repository/com/vlkan/flatbuffers/1.2.0-3f79e055/flatbuffers-1.2.0-3f79e055.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-streaming_2.11/2.3.0/spark-streaming_2.11-2.3.0.jar:/home/cloudera/.m2/repository/org/apache/spark/spark-sql-kafka-0-10_2.11/2.3.0/spark-sql-kafka-0-10_2.11-2.3.0.jar:/home/cloudera/ideaIC/lib/idea_rt.jar
Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
Client environment:java.io.tmpdir=/tmp
Client environment:java.compiler=<NA>
Client environment:os.name=Linux
Client environment:os.arch=amd64
Client environment:os.version=2.6.32-754.33.1.el6.x86_64
Client environment:user.name=cloudera
Client environment:user.home=/home/cloudera
Client environment:user.dir=/home/cloudera/IdeaProjects/POSmetricProcessing
Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x1ee3034b0x0, quorum=localhost:2181, baseZNode=/hbase
zookeeper.disableAutoWatchReset is false
Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
Socket connection established to localhost/127.0.0.1:2181, initiating session
Session establishment request sent on localhost/127.0.0.1:2181
Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1745d829f43000c, negotiated timeout = 40000
hconnection-0x1ee3034b0x0, quorum=localhost:2181, baseZNode=/hbase Received ZooKeeper Event, type=None, state=SyncConnected, path=null
hconnection-0x1ee3034b-0x1745d829f43000c connected
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Sending Heartbeat request to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v0 to send HEARTBEAT {group_id=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0,generation_id=1,member_id=consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d} with correlation id 15 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Received successful Heartbeat response
Reading reply sessionid:0x1745d829f43000c, packet:: clientPath:null serverPath:null finished:false header:: 1,3  replyHeader:: 1,3256,0  request:: '/hbase/hbaseid,F  response:: s{702,3114,1598381475385,1599296765616,16,0,0,0,67,0,702} 
Reading reply sessionid:0x1745d829f43000c, packet:: clientPath:null serverPath:null finished:false header:: 2,4  replyHeader:: 2,3256,0  request:: '/hbase/hbaseid,F  response:: #ffffffff000146d61737465723a3630303030ffffffa87fffffffeeffffff9affffffa961ffffffc26550425546a2466353166323831362d396362612d346264312d623939662d303365396464306638623563,s{702,3114,1598381475385,1599296765616,16,0,0,0,67,0,702} 
Codec=org.apache.hadoop.hbase.codec.KeyValueCodec@6d48941b, compressor=null, tcpKeepAlive=true, tcpNoDelay=true, connectTO=10000, readTO=20000, writeTO=60000, minIdleTimeBeforeClose=120000, maxRetries=0, fallbackAllowed=false, bind address=null
Reading reply sessionid:0x1745d829f43000c, packet:: clientPath:null serverPath:null finished:false header:: 3,8  replyHeader:: 3,3256,0  request:: '/hbase,F  response:: v{'replication,'meta-region-server,'rs,'splitWAL,'backup-masters,'table-lock,'flush-table-proc,'master-maintenance,'region-in-transition,'online-snapshot,'switch,'master,'running,'recovering-regions,'draining,'namespace,'hbaseid,'table} 
Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.translateException(RpcRetryingCaller.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:202)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:320)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:295)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:160)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:155)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:802)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:396)
	at org.example.spark.POSmetricProcessing.hbaseUtils.hbaseOps$.getOrCreateTbl(hbaseOps.scala:52)
	at org.example.spark.POSmetricProcessing.hbaseUtils.invoiceWriter.open(invoiceWriter.scala:15)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:50)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:49)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:593)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:577)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:556)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1211)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1178)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
	... 22 more
parentName: , name: TaskSet_0.0, runningTasks: 0
No tasks for locality level NO_PREF, so moving to locality level ANY
Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.translateException(RpcRetryingCaller.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:202)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:320)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:295)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:160)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:155)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:802)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:396)
	at org.example.spark.POSmetricProcessing.hbaseUtils.hbaseOps$.getOrCreateTbl(hbaseOps.scala:52)
	at org.example.spark.POSmetricProcessing.hbaseUtils.invoiceWriter.open(invoiceWriter.scala:15)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:50)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:49)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:593)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:577)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:556)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1211)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1178)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
	... 22 more

Task 0 in stage 0.0 failed 1 times; aborting job
Removed TaskSet 0.0, whose tasks have all completed, from pool 
Cancelling stage 0
ResultStage 0 (start at MetricProcessMain.scala:63) failed in 5.483 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.translateException(RpcRetryingCaller.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:202)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:320)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:295)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:160)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:155)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:802)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:396)
	at org.example.spark.POSmetricProcessing.hbaseUtils.hbaseOps$.getOrCreateTbl(hbaseOps.scala:52)
	at org.example.spark.POSmetricProcessing.hbaseUtils.invoiceWriter.open(invoiceWriter.scala:15)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:50)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:49)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:593)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:577)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:556)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1211)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1178)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
	... 22 more

Driver stacktrace:
After removal of stage 0, remaining stages = 0
Job 0 failed: start at MetricProcessMain.scala:63, took 5.651829 s
Query [id = 096dc621-dfc3-4bf3-a839-0f0799fc8c54, runId = 84c76b9c-c8e4-4caf-8acc-29e3a10a96c1] terminated with error
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, localhost, executor driver): org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.translateException(RpcRetryingCaller.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:202)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:320)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:295)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:160)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:155)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:802)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:396)
	at org.example.spark.POSmetricProcessing.hbaseUtils.hbaseOps$.getOrCreateTbl(hbaseOps.scala:52)
	at org.example.spark.POSmetricProcessing.hbaseUtils.invoiceWriter.open(invoiceWriter.scala:15)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:50)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:49)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:593)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:577)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:556)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1211)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1178)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
	... 22 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:929)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:927)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:927)
	at org.apache.spark.sql.execution.streaming.ForeachSink.addBatch(ForeachSink.scala:49)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$3$$anonfun$apply$16.apply(MicroBatchExecution.scala:477)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch$3.apply(MicroBatchExecution.scala:475)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:271)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.org$apache$spark$sql$execution$streaming$MicroBatchExecution$$runBatch(MicroBatchExecution.scala:474)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply$mcV$sp(MicroBatchExecution.scala:133)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:121)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1$$anonfun$apply$mcZ$sp$1.apply(MicroBatchExecution.scala:121)
	at org.apache.spark.sql.execution.streaming.ProgressReporter$class.reportTimeTaken(ProgressReporter.scala:271)
	at org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:58)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution$$anonfun$runActivatedStream$1.apply$mcZ$sp(MicroBatchExecution.scala:121)
	at org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:56)
	at org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:117)
	at org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:279)
	at org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:189)
Caused by: org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.translateException(RpcRetryingCaller.java:229)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:202)
	at org.apache.hadoop.hbase.client.ClientScanner.call(ClientScanner.java:320)
	at org.apache.hadoop.hbase.client.ClientScanner.nextScanner(ClientScanner.java:295)
	at org.apache.hadoop.hbase.client.ClientScanner.initializeScannerInConstruction(ClientScanner.java:160)
	at org.apache.hadoop.hbase.client.ClientScanner.<init>(ClientScanner.java:155)
	at org.apache.hadoop.hbase.client.HTable.getScanner(HTable.java:802)
	at org.apache.hadoop.hbase.MetaTableAccessor.fullScan(MetaTableAccessor.java:602)
	at org.apache.hadoop.hbase.MetaTableAccessor.tableExists(MetaTableAccessor.java:366)
	at org.apache.hadoop.hbase.client.HBaseAdmin.tableExists(HBaseAdmin.java:396)
	at org.example.spark.POSmetricProcessing.hbaseUtils.hbaseOps$.getOrCreateTbl(hbaseOps.scala:52)
	at org.example.spark.POSmetricProcessing.hbaseUtils.invoiceWriter.open(invoiceWriter.scala:15)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:50)
	at org.apache.spark.sql.execution.streaming.ForeachSink$$anonfun$addBatch$1.apply(ForeachSink.scala:49)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1$$anonfun$apply$29.apply(RDD.scala:929)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:109)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.<init>()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:593)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:577)
	at org.apache.hadoop.hbase.zookeeper.MetaTableLocator.blockUntilAvailable(MetaTableLocator.java:556)
	at org.apache.hadoop.hbase.client.ZooKeeperRegistry.getMetaRegionLocation(ZooKeeperRegistry.java:61)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateMeta(ConnectionManager.java:1211)
	at org.apache.hadoop.hbase.client.ConnectionManager$HConnectionImplementation.locateRegion(ConnectionManager.java:1178)
	at org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:305)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:156)
	at org.apache.hadoop.hbase.client.ScannerCallableWithReplicas.call(ScannerCallableWithReplicas.java:60)
	at org.apache.hadoop.hbase.client.RpcRetryingCaller.callWithoutRetries(RpcRetryingCaller.java:200)
	... 22 more
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Heartbeat thread has closed
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Member consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d sending LeaveGroup request to coordinator quickstart.cloudera:9092 (id: 2147483647 rack: null)
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Using older server API v0 to send LEAVE_GROUP {group_id=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0,member_id=consumer-2-e5f6c1fc-6e41-489c-be4c-74a99d39fe6d} with correlation id 16 to node 2147483647
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] LeaveGroup request returned successfully
Removed sensor with name connections-closed:
Removed sensor with name connections-created:
Removed sensor with name successful-authentication:
Removed sensor with name successful-reauthentication:
Removed sensor with name successful-authentication-no-reauth:
Removed sensor with name failed-authentication:
Removed sensor with name failed-reauthentication:
Removed sensor with name reauthentication-latency:
Removed sensor with name bytes-sent-received:
Removed sensor with name bytes-sent:
Removed sensor with name bytes-received:
Removed sensor with name select-time:
Removed sensor with name io-time:
Removed sensor with name node--1.bytes-sent
Removed sensor with name node--1.bytes-received
Removed sensor with name node--1.latency
Removed sensor with name node-2147483647.bytes-sent
Removed sensor with name node-2147483647.bytes-received
Removed sensor with name node-2147483647.latency
Removed sensor with name node-0.bytes-sent
Removed sensor with name node-0.bytes-received
Removed sensor with name node-0.latency
[Consumer clientId=consumer-2, groupId=spark-kafka-source-0e011e9e-1ed0-420b-86c4-0673263d1523-382905049-driver-0] Kafka consumer has been closed
Deactivating instances related to checkpoint location 84c76b9c-c8e4-4caf-8acc-29e3a10a96c1: 
Invoking stop() from shutdown hook
stopping org.spark_project.jetty.server.Server@3effd4f3
doStop org.spark_project.jetty.server.Server@3effd4f3
ran SparkUI-28-acceptor-0@6aba5d30-ServerConnector@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
Graceful shutdown org.spark_project.jetty.server.Server@3effd4f3 by 
stopping Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Stopping org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Queued change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@1e15b3ba on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseEndPoints@1e15b3ba
Closing 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Closed 0 endPoints on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop waiting on select
Queued change org.spark_project.jetty.io.ManagedSelector$CloseSelector@6429e4d8 on org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=0 selected=0
Selector loop woken up from select, 0/0 selected
Running change org.spark_project.jetty.io.ManagedSelector$CloseSelector@6429e4d8
EPC Prod/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7f196f35 produced null
EPC Idle/org.spark_project.jetty.io.ManagedSelector$SelectorProducer@7f196f35 produce exit
ran org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
Stopped org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.io.ManagedSelector@4eb45fec id=0 keys=-1 selected=-1
STOPPED org.spark_project.jetty.server.ServerConnector$ServerConnectorManager@61dde151
stopping HttpConnectionFactory@5a8cbffe[HTTP/1.1]
STOPPED HttpConnectionFactory@5a8cbffe[HTTP/1.1]
stopping org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
STOPPED org.spark_project.jetty.util.thread.ScheduledExecutorScheduler@51ce6f85
Stopped Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
STOPPED Spark@3d7b1f1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
stopping org.spark_project.jetty.server.Server@3effd4f3
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
STOPPED org.spark_project.jetty.server.handler.ContextHandlerCollection@186cb891[org.spark_project.jetty.server.handler.gzip.GzipHandler@1c6c6f24, org.spark_project.jetty.server.handler.gzip.GzipHandler@11b377c5, org.spark_project.jetty.server.handler.gzip.GzipHandler@10fbbdb, org.spark_project.jetty.server.handler.gzip.GzipHandler@31ff6309, org.spark_project.jetty.server.handler.gzip.GzipHandler@8ee0c23, org.spark_project.jetty.server.handler.gzip.GzipHandler@71f0b72e, org.spark_project.jetty.server.handler.gzip.GzipHandler@173797f0, org.spark_project.jetty.server.handler.gzip.GzipHandler@33d53216, org.spark_project.jetty.server.handler.gzip.GzipHandler@1e141e42, org.spark_project.jetty.server.handler.gzip.GzipHandler@3db663d0, org.spark_project.jetty.server.handler.gzip.GzipHandler@151ef57f, org.spark_project.jetty.server.handler.gzip.GzipHandler@149c3204, org.spark_project.jetty.server.handler.gzip.GzipHandler@21e20ad5, org.spark_project.jetty.server.handler.gzip.GzipHandler@1846579f, org.spark_project.jetty.server.handler.gzip.GzipHandler@38af1bf6, org.spark_project.jetty.server.handler.gzip.GzipHandler@3672276e, org.spark_project.jetty.server.handler.gzip.GzipHandler@24b4d544, org.spark_project.jetty.server.handler.gzip.GzipHandler@40e60ece, org.spark_project.jetty.server.handler.gzip.GzipHandler@61f39bb, org.spark_project.jetty.server.handler.gzip.GzipHandler@78525ef9, org.spark_project.jetty.server.handler.gzip.GzipHandler@abff8b7, org.spark_project.jetty.server.handler.gzip.GzipHandler@36fc05ff, org.spark_project.jetty.server.handler.gzip.GzipHandler@61d84e08, org.spark_project.jetty.server.handler.gzip.GzipHandler@7397c6, org.spark_project.jetty.server.handler.gzip.GzipHandler@75a118e6, o.s.j.s.ServletContextHandler@142213d5{/metrics/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@12e5da86{/SQL,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3af7d855{/SQL/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@429f7919{/SQL/execution,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@4012d5bc{/SQL/execution/json,null,SHUTDOWN,@Spark}, o.s.j.s.ServletContextHandler@3f736a16{/static/sql,null,SHUTDOWN,@Spark}]
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping org.spark_project.jetty.server.handler.ErrorHandler@514cd540
STOPPED org.spark_project.jetty.server.handler.ErrorHandler@514cd540
stopping SparkUI{STARTED,8<=8<=200,i=8,q=0}
STOPPED SparkUI{STOPPED,8<=8<=200,i=0,q=0}
STOPPED org.spark_project.jetty.server.Server@3effd4f3
Stopped Spark web UI at http://quickstart.cloudera:4040
MapOutputTrackerMasterEndpoint stopped!
MemoryStore cleared
BlockManager stopped
BlockManagerMaster stopped
OutputCommitCoordinator stopped!
Successfully stopped SparkContext
Shutdown hook called
Deleting directory /tmp/temporary-73a6bc36-6f05-438c-8e20-c7e98335609e
Deleting directory /tmp/temporaryReader-f2f8e38e-ed68-4650-a36c-0e4b3e424f7c
Deleting directory /tmp/spark-810e7741-c9dc-4846-b110-124aeb186a08
